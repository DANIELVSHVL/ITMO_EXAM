{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOdcKxCU20w3l+RyXczUNbC",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/DANIELVSHVL/ITMO_EXAM/blob/main/QA_BOT_ITMO.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        " # Установим необходимые библиотеки и зависимости"
      ],
      "metadata": {
        "id": "xkNNNMQ-lUiM"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "764dc829",
        "outputId": "3d7b646e-27b0-427f-8589-5e3ccca578e5"
      },
      "source": [
        "%pip install PyPDF2"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting PyPDF2\n",
            "  Downloading pypdf2-3.0.1-py3-none-any.whl.metadata (6.8 kB)\n",
            "Downloading pypdf2-3.0.1-py3-none-any.whl (232 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m232.6/232.6 kB\u001b[0m \u001b[31m2.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: PyPDF2\n",
            "Successfully installed PyPDF2-3.0.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5fa5d5ae",
        "outputId": "894754c7-424c-4b07-a2d3-c5aaa27c1915"
      },
      "source": [
        "%pip install python-telegram-bot"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: python-telegram-bot in /usr/local/lib/python3.11/dist-packages (22.3)\n",
            "Requirement already satisfied: httpx<0.29,>=0.27 in /usr/local/lib/python3.11/dist-packages (from python-telegram-bot) (0.28.1)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.11/dist-packages (from httpx<0.29,>=0.27->python-telegram-bot) (4.10.0)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.11/dist-packages (from httpx<0.29,>=0.27->python-telegram-bot) (2025.8.3)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx<0.29,>=0.27->python-telegram-bot) (1.0.9)\n",
            "Requirement already satisfied: idna in /usr/local/lib/python3.11/dist-packages (from httpx<0.29,>=0.27->python-telegram-bot) (3.10)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx<0.29,>=0.27->python-telegram-bot) (0.16.0)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.11/dist-packages (from anyio->httpx<0.29,>=0.27->python-telegram-bot) (1.3.1)\n",
            "Requirement already satisfied: typing_extensions>=4.5 in /usr/local/lib/python3.11/dist-packages (from anyio->httpx<0.29,>=0.27->python-telegram-bot) (4.14.1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q playwright nest_asyncio\n",
        "!playwright install --with-deps # Install browsers and dependencies\n",
        "import nest_asyncio\n",
        "nest_asyncio.apply()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NBnmo9IlkPd9",
        "outputId": "11f387fc-2cb6-49a1-83c4-69cd648a65b5"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m45.9/45.9 MB\u001b[0m \u001b[31m19.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling dependencies...\n",
            "Get:1 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64  InRelease [1,581 B]\n",
            "Get:2 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64  Packages [1,929 kB]\n",
            "Get:3 https://cloud.r-project.org/bin/linux/ubuntu jammy-cran40/ InRelease [3,632 B]\n",
            "Get:4 http://security.ubuntu.com/ubuntu jammy-security InRelease [129 kB]\n",
            "Hit:5 http://archive.ubuntu.com/ubuntu jammy InRelease\n",
            "Get:6 http://archive.ubuntu.com/ubuntu jammy-updates InRelease [128 kB]\n",
            "Hit:7 https://ppa.launchpadcontent.net/deadsnakes/ppa/ubuntu jammy InRelease\n",
            "Hit:8 https://r2u.stat.illinois.edu/ubuntu jammy InRelease\n",
            "Hit:9 https://ppa.launchpadcontent.net/graphics-drivers/ppa/ubuntu jammy InRelease\n",
            "Hit:10 https://ppa.launchpadcontent.net/ubuntugis/ppa/ubuntu jammy InRelease\n",
            "Get:11 http://security.ubuntu.com/ubuntu jammy-security/main amd64 Packages [3,209 kB]\n",
            "Get:12 http://archive.ubuntu.com/ubuntu jammy-backports InRelease [127 kB]\n",
            "Get:13 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 Packages [3,520 kB]\n",
            "Get:14 http://security.ubuntu.com/ubuntu jammy-security/universe amd64 Packages [1,270 kB]\n",
            "Get:15 http://security.ubuntu.com/ubuntu jammy-security/restricted amd64 Packages [5,111 kB]\n",
            "Get:16 http://archive.ubuntu.com/ubuntu jammy-updates/universe amd64 Packages [1,575 kB]\n",
            "Fetched 17.0 MB in 3s (4,898 kB/s)\n",
            "Reading package lists... Done\n",
            "W: Skipping acquire of configured file 'main/source/Sources' as repository 'https://r2u.stat.illinois.edu/ubuntu jammy InRelease' does not seem to provide it (sources.list entry misspelt?)\n",
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "fonts-liberation is already the newest version (1:1.07.4-11).\n",
            "libasound2 is already the newest version (1.2.6.1-1ubuntu1).\n",
            "libasound2 set to manually installed.\n",
            "libatk-bridge2.0-0 is already the newest version (2.38.0-3).\n",
            "libatk-bridge2.0-0 set to manually installed.\n",
            "libatk1.0-0 is already the newest version (2.36.0-3build1).\n",
            "libatk1.0-0 set to manually installed.\n",
            "libatspi2.0-0 is already the newest version (2.44.0-3).\n",
            "libatspi2.0-0 set to manually installed.\n",
            "libcairo-gobject2 is already the newest version (1.16.0-5ubuntu2).\n",
            "libcairo-gobject2 set to manually installed.\n",
            "libcairo2 is already the newest version (1.16.0-5ubuntu2).\n",
            "libcairo2 set to manually installed.\n",
            "libegl1 is already the newest version (1.4.0-1).\n",
            "libepoxy0 is already the newest version (1.5.10-1).\n",
            "libepoxy0 set to manually installed.\n",
            "libevent-2.1-7 is already the newest version (2.1.12-stable-1build3).\n",
            "libevent-2.1-7 set to manually installed.\n",
            "libfontconfig1 is already the newest version (2.13.1-4.2ubuntu5).\n",
            "libgles2 is already the newest version (1.4.0-1).\n",
            "libglx0 is already the newest version (1.4.0-1).\n",
            "libglx0 set to manually installed.\n",
            "libicu70 is already the newest version (70.1-2).\n",
            "libicu70 set to manually installed.\n",
            "libjpeg-turbo8 is already the newest version (2.1.2-0ubuntu1).\n",
            "libjpeg-turbo8 set to manually installed.\n",
            "liblcms2-2 is already the newest version (2.12~rc1-2build2).\n",
            "liblcms2-2 set to manually installed.\n",
            "libopengl0 is already the newest version (1.4.0-1).\n",
            "libopus0 is already the newest version (1.3.1-0.1build2).\n",
            "libopus0 set to manually installed.\n",
            "libpng16-16 is already the newest version (1.6.37-3build5).\n",
            "libpng16-16 set to manually installed.\n",
            "libxcb-shm0 is already the newest version (1.14-3ubuntu3).\n",
            "libxcb-shm0 set to manually installed.\n",
            "libxcb1 is already the newest version (1.14-3ubuntu3).\n",
            "libxcb1 set to manually installed.\n",
            "libxcomposite1 is already the newest version (1:0.4.5-1build2).\n",
            "libxcomposite1 set to manually installed.\n",
            "libxcursor1 is already the newest version (1:1.2.0-2build4).\n",
            "libxcursor1 set to manually installed.\n",
            "libxdamage1 is already the newest version (1:1.1.5-2build2).\n",
            "libxdamage1 set to manually installed.\n",
            "libxext6 is already the newest version (2:1.3.4-1build1).\n",
            "libxfixes3 is already the newest version (1:6.0.0-1).\n",
            "libxfixes3 set to manually installed.\n",
            "libxi6 is already the newest version (2:1.8-1build1).\n",
            "libxi6 set to manually installed.\n",
            "libxkbcommon0 is already the newest version (1.4.0-1).\n",
            "libxkbcommon0 set to manually installed.\n",
            "libxrandr2 is already the newest version (2:1.5.2-1build1).\n",
            "libxrandr2 set to manually installed.\n",
            "libxrender1 is already the newest version (1:0.9.10-1build4).\n",
            "libx264-163 is already the newest version (2:0.163.3060+git5db6aa6-2build1).\n",
            "libx264-163 set to manually installed.\n",
            "libatomic1 is already the newest version (12.3.0-1ubuntu1~22.04).\n",
            "libatomic1 set to manually installed.\n",
            "libcups2 is already the newest version (2.4.1op1-1ubuntu4.11).\n",
            "libcups2 set to manually installed.\n",
            "libdbus-1-3 is already the newest version (1.12.20-2ubuntu4.1).\n",
            "libdbus-1-3 set to manually installed.\n",
            "libdrm2 is already the newest version (2.4.113-2~ubuntu0.22.04.1).\n",
            "libdrm2 set to manually installed.\n",
            "libfreetype6 is already the newest version (2.11.1+dfsg-1ubuntu0.3).\n",
            "libfreetype6 set to manually installed.\n",
            "libgbm1 is already the newest version (23.2.1-1ubuntu3.1~22.04.3).\n",
            "libgbm1 set to manually installed.\n",
            "libgdk-pixbuf-2.0-0 is already the newest version (2.42.8+dfsg-1ubuntu0.4).\n",
            "libgdk-pixbuf-2.0-0 set to manually installed.\n",
            "libglib2.0-0 is already the newest version (2.72.4-0ubuntu2.5).\n",
            "libgstreamer-plugins-base1.0-0 is already the newest version (1.20.1-1ubuntu0.4).\n",
            "libgstreamer-plugins-base1.0-0 set to manually installed.\n",
            "libgstreamer1.0-0 is already the newest version (1.20.3-0ubuntu1.1).\n",
            "libgstreamer1.0-0 set to manually installed.\n",
            "libgtk-3-0 is already the newest version (3.24.33-1ubuntu2.2).\n",
            "libgtk-3-0 set to manually installed.\n",
            "libgtk-4-1 is already the newest version (4.6.9+ds-0ubuntu0.22.04.2).\n",
            "libgtk-4-1 set to manually installed.\n",
            "libharfbuzz0b is already the newest version (2.7.4-1ubuntu3.2).\n",
            "libharfbuzz0b set to manually installed.\n",
            "libnspr4 is already the newest version (2:4.35-0ubuntu0.22.04.1).\n",
            "libnspr4 set to manually installed.\n",
            "libnss3 is already the newest version (2:3.98-0ubuntu0.22.04.2).\n",
            "libnss3 set to manually installed.\n",
            "libopenjp2-7 is already the newest version (2.4.0-6ubuntu0.3).\n",
            "libopenjp2-7 set to manually installed.\n",
            "libpango-1.0-0 is already the newest version (1.50.6+ds-2ubuntu1).\n",
            "libpango-1.0-0 set to manually installed.\n",
            "libpangocairo-1.0-0 is already the newest version (1.50.6+ds-2ubuntu1).\n",
            "libpangocairo-1.0-0 set to manually installed.\n",
            "libwayland-client0 is already the newest version (1.20.0-1ubuntu0.1).\n",
            "libwayland-client0 set to manually installed.\n",
            "libwayland-egl1 is already the newest version (1.20.0-1ubuntu0.1).\n",
            "libwayland-egl1 set to manually installed.\n",
            "libwayland-server0 is already the newest version (1.20.0-1ubuntu0.1).\n",
            "libwayland-server0 set to manually installed.\n",
            "libwebpdemux2 is already the newest version (1.2.2-2ubuntu0.22.04.2).\n",
            "libx11-6 is already the newest version (2:1.7.5-1ubuntu0.3).\n",
            "libx11-6 set to manually installed.\n",
            "libx11-xcb1 is already the newest version (2:1.7.5-1ubuntu0.3).\n",
            "libx11-xcb1 set to manually installed.\n",
            "libxml2 is already the newest version (2.9.13+dfsg-1ubuntu0.7).\n",
            "libxml2 set to manually installed.\n",
            "libxslt1.1 is already the newest version (1.1.34-4ubuntu0.22.04.4).\n",
            "ffmpeg is already the newest version (7:4.4.2-0ubuntu0.22.04.1).\n",
            "xvfb is already the newest version (2:21.1.4-2ubuntu1.7~22.04.15).\n",
            "The following additional packages will be installed:\n",
            "  dictionaries-common glib-networking glib-networking-common\n",
            "  glib-networking-services gsettings-desktop-schemas hunspell-en-us libaa1\n",
            "  libabsl20210324 libaspell15 libcdparanoia0 libdca0 libdv4 libdvdnav4\n",
            "  libdvdread8 libfaad2 libfluidsynth3 libfreeaptx0 libgav1-0 libgssdp-1.2-0\n",
            "  libgstreamer-plugins-bad1.0-0 libgstreamer-plugins-good1.0-0 libgupnp-1.2-1\n",
            "  libgupnp-igd-1.0-4 libhunspell-1.7-0 libinstpatch-1.0-2 libjson-glib-1.0-0\n",
            "  libjson-glib-1.0-common libkate1 libldacbt-enc2 libltc11 libmjpegutils-2.1-0\n",
            "  libmodplug1 libmpcdec6 libmpeg2encpp-2.1-0 libmplex2-2.1-0 libnice10\n",
            "  libopenh264-6 libopenni2-0 libqrencode4 libsbc1 libsecret-common libshout3\n",
            "  libsoundtouch1 libsoup-3.0-common libsoup2.4-1 libsoup2.4-common libspandsp2\n",
            "  libsrtp2-1 libtag1v5 libtag1v5-vanilla libtext-iconv-perl libv4l-0\n",
            "  libv4lconvert0 libvisual-0.4-0 libvo-aacenc0 libvo-amrwbenc0 libwavpack1\n",
            "  libwebrtc-audio-processing1 libwildmidi2 libyuv0 libzbar0 libzxingcore1\n",
            "  session-migration timgm6mb-soundfont xfonts-encodings xfonts-utils\n",
            "Suggested packages:\n",
            "  ispell | aspell | hunspell wordlist frei0r-plugins gvfs hunspell\n",
            "  openoffice.org-hunspell | openoffice.org-core aspell libdv-bin oss-compat\n",
            "  libdvdcss2 libenchant-2-voikko gnome-shell | notification-daemon\n",
            "  libvisual-0.4-plugins libwildmidi-config fluid-soundfont-gm\n",
            "Recommended packages:\n",
            "  fonts-ipafont-mincho fonts-tlwg-loma gstreamer1.0-x aspell-en\n",
            "  | aspell-dictionary | aspell6a-dictionary enchant-2 gstreamer1.0-gl\n",
            "  libmagickcore-6.q16-6-extra\n",
            "The following NEW packages will be installed:\n",
            "  dictionaries-common fonts-freefont-ttf fonts-ipafont-gothic\n",
            "  fonts-noto-color-emoji fonts-tlwg-loma-otf fonts-unifont fonts-wqy-zenhei\n",
            "  glib-networking glib-networking-common glib-networking-services\n",
            "  gsettings-desktop-schemas gstreamer1.0-libav gstreamer1.0-plugins-bad\n",
            "  gstreamer1.0-plugins-base gstreamer1.0-plugins-good hunspell-en-us libaa1\n",
            "  libabsl20210324 libaspell15 libavif13 libcdparanoia0 libdbus-glib-1-2\n",
            "  libdca0 libdv4 libdvdnav4 libdvdread8 libenchant-2-2 libevdev2 libfaad2\n",
            "  libffi7 libfluidsynth3 libfreeaptx0 libgav1-0 libgssdp-1.2-0\n",
            "  libgstreamer-gl1.0-0 libgstreamer-plugins-bad1.0-0\n",
            "  libgstreamer-plugins-good1.0-0 libgudev-1.0-0 libgupnp-1.2-1\n",
            "  libgupnp-igd-1.0-4 libharfbuzz-icu0 libhunspell-1.7-0 libhyphen0\n",
            "  libinstpatch-1.0-2 libjson-glib-1.0-0 libjson-glib-1.0-common libkate1\n",
            "  libldacbt-enc2 libltc11 libmanette-0.2-0 libmjpegutils-2.1-0 libmodplug1\n",
            "  libmpcdec6 libmpeg2encpp-2.1-0 libmplex2-2.1-0 libnice10 libnotify4\n",
            "  libopenh264-6 libopenni2-0 libproxy1v5 libqrencode4 libsbc1 libsecret-1-0\n",
            "  libsecret-common libshout3 libsoundtouch1 libsoup-3.0-0 libsoup-3.0-common\n",
            "  libsoup2.4-1 libsoup2.4-common libspandsp2 libsrtp2-1 libtag1v5\n",
            "  libtag1v5-vanilla libtext-iconv-perl libv4l-0 libv4lconvert0 libvisual-0.4-0\n",
            "  libvo-aacenc0 libvo-amrwbenc0 libwavpack1 libwebrtc-audio-processing1\n",
            "  libwildmidi2 libwoff1 libxtst6 libyuv0 libzbar0 libzxingcore1\n",
            "  session-migration timgm6mb-soundfont xfonts-cyrillic xfonts-encodings\n",
            "  xfonts-scalable xfonts-utils\n",
            "0 upgraded, 94 newly installed, 0 to remove and 35 not upgraded.\n",
            "Need to get 48.2 MB of archives.\n",
            "After this operation, 123 MB of additional disk space will be used.\n",
            "Get:1 http://archive.ubuntu.com/ubuntu jammy/universe amd64 fonts-ipafont-gothic all 00303-21ubuntu1 [3,513 kB]\n",
            "Get:2 http://archive.ubuntu.com/ubuntu jammy/main amd64 libtext-iconv-perl amd64 1.7-7build3 [14.3 kB]\n",
            "Get:3 http://archive.ubuntu.com/ubuntu jammy/main amd64 dictionaries-common all 1.28.14 [185 kB]\n",
            "Get:4 http://archive.ubuntu.com/ubuntu jammy/main amd64 fonts-freefont-ttf all 20120503-10build1 [2,388 kB]\n",
            "Get:5 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 fonts-noto-color-emoji all 2.047-0ubuntu0.22.04.1 [10.0 MB]\n",
            "Get:6 http://archive.ubuntu.com/ubuntu jammy/universe amd64 fonts-tlwg-loma-otf all 1:0.7.3-1 [107 kB]\n",
            "Get:7 http://archive.ubuntu.com/ubuntu jammy/universe amd64 fonts-unifont all 1:14.0.01-1 [3,551 kB]\n",
            "Get:8 http://archive.ubuntu.com/ubuntu jammy/universe amd64 fonts-wqy-zenhei all 0.9.45-8 [7,472 kB]\n",
            "Get:9 http://archive.ubuntu.com/ubuntu jammy/main amd64 libproxy1v5 amd64 0.4.17-2 [51.9 kB]\n",
            "Get:10 http://archive.ubuntu.com/ubuntu jammy/main amd64 glib-networking-common all 2.72.0-1 [3,718 B]\n",
            "Get:11 http://archive.ubuntu.com/ubuntu jammy/main amd64 glib-networking-services amd64 2.72.0-1 [9,982 B]\n",
            "Get:12 http://archive.ubuntu.com/ubuntu jammy/main amd64 session-migration amd64 0.3.6 [9,774 B]\n",
            "Get:13 http://archive.ubuntu.com/ubuntu jammy/main amd64 gsettings-desktop-schemas all 42.0-1ubuntu1 [31.1 kB]\n",
            "Get:14 http://archive.ubuntu.com/ubuntu jammy/main amd64 glib-networking amd64 2.72.0-1 [69.8 kB]\n",
            "Get:15 http://archive.ubuntu.com/ubuntu jammy-updates/universe amd64 gstreamer1.0-libav amd64 1.20.3-0ubuntu1 [103 kB]\n",
            "Get:16 http://archive.ubuntu.com/ubuntu jammy/main amd64 libcdparanoia0 amd64 3.10.2+debian-14build2 [49.3 kB]\n",
            "Get:17 http://archive.ubuntu.com/ubuntu jammy/main amd64 libvisual-0.4-0 amd64 0.4.0-17build2 [108 kB]\n",
            "Get:18 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 gstreamer1.0-plugins-base amd64 1.20.1-1ubuntu0.4 [712 kB]\n",
            "Get:19 http://archive.ubuntu.com/ubuntu jammy/main amd64 libaa1 amd64 1.4p5-50build1 [51.9 kB]\n",
            "Get:20 http://archive.ubuntu.com/ubuntu jammy/main amd64 libdv4 amd64 1.0.0-14build1 [61.9 kB]\n",
            "Get:21 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 libgstreamer-plugins-good1.0-0 amd64 1.20.3-0ubuntu1.3 [30.1 kB]\n",
            "Get:22 http://archive.ubuntu.com/ubuntu jammy/main amd64 libgudev-1.0-0 amd64 1:237-2build1 [16.3 kB]\n",
            "Get:23 http://archive.ubuntu.com/ubuntu jammy/main amd64 libshout3 amd64 2.4.5-1build3 [54.5 kB]\n",
            "Get:24 http://archive.ubuntu.com/ubuntu jammy/main amd64 libtag1v5-vanilla amd64 1.11.1+dfsg.1-3ubuntu3 [304 kB]\n",
            "Get:25 http://archive.ubuntu.com/ubuntu jammy/main amd64 libtag1v5 amd64 1.11.1+dfsg.1-3ubuntu3 [11.5 kB]\n",
            "Get:26 http://archive.ubuntu.com/ubuntu jammy/main amd64 libv4lconvert0 amd64 1.22.1-2build1 [82.4 kB]\n",
            "Get:27 http://archive.ubuntu.com/ubuntu jammy/main amd64 libv4l-0 amd64 1.22.1-2build1 [44.9 kB]\n",
            "Get:28 http://archive.ubuntu.com/ubuntu jammy/main amd64 libwavpack1 amd64 5.4.0-1build2 [83.7 kB]\n",
            "Get:29 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 libsoup2.4-common all 2.74.2-3ubuntu0.6 [4,778 B]\n",
            "Get:30 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 libsoup2.4-1 amd64 2.74.2-3ubuntu0.6 [288 kB]\n",
            "Get:31 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 gstreamer1.0-plugins-good amd64 1.20.3-0ubuntu1.3 [2,010 kB]\n",
            "Get:32 http://archive.ubuntu.com/ubuntu jammy/main amd64 hunspell-en-us all 1:2020.12.07-2 [280 kB]\n",
            "Get:33 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 libabsl20210324 amd64 0~20210324.2-2ubuntu0.2 [386 kB]\n",
            "Get:34 http://archive.ubuntu.com/ubuntu jammy/main amd64 libaspell15 amd64 0.60.8-4build1 [325 kB]\n",
            "Get:35 http://archive.ubuntu.com/ubuntu jammy/universe amd64 libgav1-0 amd64 0.17.0-1build1 [336 kB]\n",
            "Get:36 http://archive.ubuntu.com/ubuntu jammy/universe amd64 libyuv0 amd64 0.0~git20220104.b91df1a-2 [154 kB]\n",
            "Get:37 http://archive.ubuntu.com/ubuntu jammy/universe amd64 libavif13 amd64 0.9.3-3 [69.5 kB]\n",
            "Get:38 http://archive.ubuntu.com/ubuntu jammy/main amd64 libdbus-glib-1-2 amd64 0.112-2build1 [65.4 kB]\n",
            "Get:39 http://archive.ubuntu.com/ubuntu jammy/universe amd64 libdvdread8 amd64 6.1.2-1 [55.7 kB]\n",
            "Get:40 http://archive.ubuntu.com/ubuntu jammy/universe amd64 libdvdnav4 amd64 6.1.1-1 [39.3 kB]\n",
            "Get:41 http://archive.ubuntu.com/ubuntu jammy/main amd64 libhunspell-1.7-0 amd64 1.7.0-4build1 [175 kB]\n",
            "Get:42 http://archive.ubuntu.com/ubuntu jammy/main amd64 libenchant-2-2 amd64 2.3.2-1ubuntu2 [50.9 kB]\n",
            "Get:43 http://archive.ubuntu.com/ubuntu jammy/universe amd64 libfaad2 amd64 2.10.0-2 [197 kB]\n",
            "Get:44 http://archive.ubuntu.com/ubuntu jammy/universe amd64 libffi7 amd64 3.3-5ubuntu1 [19.9 kB]\n",
            "Get:45 http://archive.ubuntu.com/ubuntu jammy/universe amd64 libinstpatch-1.0-2 amd64 1.1.6-1 [240 kB]\n",
            "Get:46 http://archive.ubuntu.com/ubuntu jammy/universe amd64 timgm6mb-soundfont all 1.3-5 [5,427 kB]\n",
            "Get:47 http://archive.ubuntu.com/ubuntu jammy/universe amd64 libfluidsynth3 amd64 2.2.5-1 [246 kB]\n",
            "Get:48 http://archive.ubuntu.com/ubuntu jammy/universe amd64 libfreeaptx0 amd64 0.1.1-1 [12.9 kB]\n",
            "Get:49 http://archive.ubuntu.com/ubuntu jammy/main amd64 libgssdp-1.2-0 amd64 1.4.0.1-2build1 [48.9 kB]\n",
            "Get:50 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 libgstreamer-gl1.0-0 amd64 1.20.1-1ubuntu0.4 [204 kB]\n",
            "Get:51 http://archive.ubuntu.com/ubuntu jammy/main amd64 libgupnp-1.2-1 amd64 1.4.3-1 [93.3 kB]\n",
            "Get:52 http://archive.ubuntu.com/ubuntu jammy/universe amd64 libgupnp-igd-1.0-4 amd64 1.2.0-1build1 [16.8 kB]\n",
            "Get:53 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 libharfbuzz-icu0 amd64 2.7.4-1ubuntu3.2 [5,890 B]\n",
            "Get:54 http://archive.ubuntu.com/ubuntu jammy/main amd64 libhyphen0 amd64 2.8.8-7build2 [28.2 kB]\n",
            "Get:55 http://archive.ubuntu.com/ubuntu jammy/main amd64 libjson-glib-1.0-common all 1.6.6-1build1 [4,432 B]\n",
            "Get:56 http://archive.ubuntu.com/ubuntu jammy/main amd64 libjson-glib-1.0-0 amd64 1.6.6-1build1 [69.9 kB]\n",
            "Get:57 http://archive.ubuntu.com/ubuntu jammy/universe amd64 libkate1 amd64 0.4.1-11build1 [39.4 kB]\n",
            "Get:58 http://archive.ubuntu.com/ubuntu jammy/universe amd64 libldacbt-enc2 amd64 2.0.2.3+git20200429+ed310a0-4 [24.6 kB]\n",
            "Get:59 http://archive.ubuntu.com/ubuntu jammy/universe amd64 libltc11 amd64 1.3.1-1 [12.3 kB]\n",
            "Get:60 http://archive.ubuntu.com/ubuntu jammy/main amd64 libevdev2 amd64 1.12.1+dfsg-1 [39.5 kB]\n",
            "Get:61 http://archive.ubuntu.com/ubuntu jammy/main amd64 libmanette-0.2-0 amd64 0.2.6-3build1 [30.4 kB]\n",
            "Get:62 http://archive.ubuntu.com/ubuntu jammy/universe amd64 libmjpegutils-2.1-0 amd64 1:2.1.0+debian-6build1 [24.1 kB]\n",
            "Get:63 http://archive.ubuntu.com/ubuntu jammy/universe amd64 libmodplug1 amd64 1:0.8.9.0-3 [153 kB]\n",
            "Get:64 http://archive.ubuntu.com/ubuntu jammy/universe amd64 libmpcdec6 amd64 2:0.1~r495-2 [32.4 kB]\n",
            "Get:65 http://archive.ubuntu.com/ubuntu jammy/universe amd64 libmpeg2encpp-2.1-0 amd64 1:2.1.0+debian-6build1 [69.4 kB]\n",
            "Get:66 http://archive.ubuntu.com/ubuntu jammy/universe amd64 libmplex2-2.1-0 amd64 1:2.1.0+debian-6build1 [44.4 kB]\n",
            "Get:67 http://archive.ubuntu.com/ubuntu jammy/universe amd64 libnice10 amd64 0.1.18-2 [156 kB]\n",
            "Get:68 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 libnotify4 amd64 0.7.9-3ubuntu5.22.04.1 [20.3 kB]\n",
            "Get:69 http://archive.ubuntu.com/ubuntu jammy/universe amd64 libopenh264-6 amd64 2.2.0+dfsg-2 [407 kB]\n",
            "Get:70 http://archive.ubuntu.com/ubuntu jammy/universe amd64 libopenni2-0 amd64 2.2.0.33+dfsg-15 [389 kB]\n",
            "Get:71 http://archive.ubuntu.com/ubuntu jammy/universe amd64 libqrencode4 amd64 4.1.1-1 [24.0 kB]\n",
            "Get:72 http://archive.ubuntu.com/ubuntu jammy/main amd64 libsecret-common all 0.20.5-2 [4,278 B]\n",
            "Get:73 http://archive.ubuntu.com/ubuntu jammy/main amd64 libsecret-1-0 amd64 0.20.5-2 [124 kB]\n",
            "Get:74 http://archive.ubuntu.com/ubuntu jammy/universe amd64 libsoundtouch1 amd64 2.3.1+ds1-1 [38.3 kB]\n",
            "Get:75 http://archive.ubuntu.com/ubuntu jammy-updates/universe amd64 libsoup-3.0-common all 3.0.7-0ubuntu1 [62.1 kB]\n",
            "Get:76 http://archive.ubuntu.com/ubuntu jammy-updates/universe amd64 libsoup-3.0-0 amd64 3.0.7-0ubuntu1 [278 kB]\n",
            "Get:77 http://archive.ubuntu.com/ubuntu jammy/universe amd64 libspandsp2 amd64 0.0.6+dfsg-2 [272 kB]\n",
            "Get:78 http://archive.ubuntu.com/ubuntu jammy/universe amd64 libsrtp2-1 amd64 2.4.2-2 [40.7 kB]\n",
            "Get:79 http://archive.ubuntu.com/ubuntu jammy/main amd64 libwebrtc-audio-processing1 amd64 0.3.1-0ubuntu5 [291 kB]\n",
            "Get:80 http://archive.ubuntu.com/ubuntu jammy/universe amd64 libwildmidi2 amd64 0.4.3-1 [59.9 kB]\n",
            "Get:81 http://archive.ubuntu.com/ubuntu jammy/main amd64 libwoff1 amd64 1.0.2-1build4 [45.2 kB]\n",
            "Get:82 http://archive.ubuntu.com/ubuntu jammy/main amd64 libxtst6 amd64 2:1.2.3-1build4 [13.4 kB]\n",
            "Get:83 http://archive.ubuntu.com/ubuntu jammy/universe amd64 libzbar0 amd64 0.23.92-4build2 [121 kB]\n",
            "Get:84 http://archive.ubuntu.com/ubuntu jammy/universe amd64 libzxingcore1 amd64 1.2.0-1 [619 kB]\n",
            "Get:85 http://archive.ubuntu.com/ubuntu jammy/main amd64 xfonts-encodings all 1:1.0.5-0ubuntu2 [578 kB]\n",
            "Get:86 http://archive.ubuntu.com/ubuntu jammy/main amd64 xfonts-utils amd64 1:7.7+6build2 [94.6 kB]\n",
            "Get:87 http://archive.ubuntu.com/ubuntu jammy/universe amd64 xfonts-cyrillic all 1:1.0.5 [386 kB]\n",
            "Get:88 http://archive.ubuntu.com/ubuntu jammy/main amd64 xfonts-scalable all 1:1.0.3-1.2ubuntu1 [306 kB]\n",
            "Get:89 http://archive.ubuntu.com/ubuntu jammy/universe amd64 libdca0 amd64 0.0.7-2 [88.2 kB]\n",
            "Get:90 http://archive.ubuntu.com/ubuntu jammy-updates/universe amd64 libgstreamer-plugins-bad1.0-0 amd64 1.20.3-0ubuntu1.1 [489 kB]\n",
            "Get:91 http://archive.ubuntu.com/ubuntu jammy/main amd64 libsbc1 amd64 1.5-3build2 [34.4 kB]\n",
            "Get:92 http://archive.ubuntu.com/ubuntu jammy/universe amd64 libvo-aacenc0 amd64 0.1.3-2 [69.4 kB]\n",
            "Get:93 http://archive.ubuntu.com/ubuntu jammy/universe amd64 libvo-amrwbenc0 amd64 0.1.3-2 [68.2 kB]\n",
            "Get:94 http://archive.ubuntu.com/ubuntu jammy-updates/universe amd64 gstreamer1.0-plugins-bad amd64 1.20.3-0ubuntu1.1 [2,602 kB]\n",
            "Fetched 48.2 MB in 7s (6,972 kB/s)\n",
            "Extracting templates from packages: 100%\n",
            "Preconfiguring packages ...\n",
            "Selecting previously unselected package fonts-ipafont-gothic.\n",
            "(Reading database ... 126284 files and directories currently installed.)\n",
            "Preparing to unpack .../00-fonts-ipafont-gothic_00303-21ubuntu1_all.deb ...\n",
            "Unpacking fonts-ipafont-gothic (00303-21ubuntu1) ...\n",
            "Selecting previously unselected package libtext-iconv-perl.\n",
            "Preparing to unpack .../01-libtext-iconv-perl_1.7-7build3_amd64.deb ...\n",
            "Unpacking libtext-iconv-perl (1.7-7build3) ...\n",
            "Selecting previously unselected package dictionaries-common.\n",
            "Preparing to unpack .../02-dictionaries-common_1.28.14_all.deb ...\n",
            "Adding 'diversion of /usr/share/dict/words to /usr/share/dict/words.pre-dictionaries-common by dictionaries-common'\n",
            "Unpacking dictionaries-common (1.28.14) ...\n",
            "Selecting previously unselected package fonts-freefont-ttf.\n",
            "Preparing to unpack .../03-fonts-freefont-ttf_20120503-10build1_all.deb ...\n",
            "Unpacking fonts-freefont-ttf (20120503-10build1) ...\n",
            "Selecting previously unselected package fonts-noto-color-emoji.\n",
            "Preparing to unpack .../04-fonts-noto-color-emoji_2.047-0ubuntu0.22.04.1_all.deb ...\n",
            "Unpacking fonts-noto-color-emoji (2.047-0ubuntu0.22.04.1) ...\n",
            "Selecting previously unselected package fonts-tlwg-loma-otf.\n",
            "Preparing to unpack .../05-fonts-tlwg-loma-otf_1%3a0.7.3-1_all.deb ...\n",
            "Unpacking fonts-tlwg-loma-otf (1:0.7.3-1) ...\n",
            "Selecting previously unselected package fonts-unifont.\n",
            "Preparing to unpack .../06-fonts-unifont_1%3a14.0.01-1_all.deb ...\n",
            "Unpacking fonts-unifont (1:14.0.01-1) ...\n",
            "Selecting previously unselected package fonts-wqy-zenhei.\n",
            "Preparing to unpack .../07-fonts-wqy-zenhei_0.9.45-8_all.deb ...\n",
            "Unpacking fonts-wqy-zenhei (0.9.45-8) ...\n",
            "Selecting previously unselected package libproxy1v5:amd64.\n",
            "Preparing to unpack .../08-libproxy1v5_0.4.17-2_amd64.deb ...\n",
            "Unpacking libproxy1v5:amd64 (0.4.17-2) ...\n",
            "Selecting previously unselected package glib-networking-common.\n",
            "Preparing to unpack .../09-glib-networking-common_2.72.0-1_all.deb ...\n",
            "Unpacking glib-networking-common (2.72.0-1) ...\n",
            "Selecting previously unselected package glib-networking-services.\n",
            "Preparing to unpack .../10-glib-networking-services_2.72.0-1_amd64.deb ...\n",
            "Unpacking glib-networking-services (2.72.0-1) ...\n",
            "Selecting previously unselected package session-migration.\n",
            "Preparing to unpack .../11-session-migration_0.3.6_amd64.deb ...\n",
            "Unpacking session-migration (0.3.6) ...\n",
            "Selecting previously unselected package gsettings-desktop-schemas.\n",
            "Preparing to unpack .../12-gsettings-desktop-schemas_42.0-1ubuntu1_all.deb ...\n",
            "Unpacking gsettings-desktop-schemas (42.0-1ubuntu1) ...\n",
            "Selecting previously unselected package glib-networking:amd64.\n",
            "Preparing to unpack .../13-glib-networking_2.72.0-1_amd64.deb ...\n",
            "Unpacking glib-networking:amd64 (2.72.0-1) ...\n",
            "Selecting previously unselected package gstreamer1.0-libav:amd64.\n",
            "Preparing to unpack .../14-gstreamer1.0-libav_1.20.3-0ubuntu1_amd64.deb ...\n",
            "Unpacking gstreamer1.0-libav:amd64 (1.20.3-0ubuntu1) ...\n",
            "Selecting previously unselected package libcdparanoia0:amd64.\n",
            "Preparing to unpack .../15-libcdparanoia0_3.10.2+debian-14build2_amd64.deb ...\n",
            "Unpacking libcdparanoia0:amd64 (3.10.2+debian-14build2) ...\n",
            "Selecting previously unselected package libvisual-0.4-0:amd64.\n",
            "Preparing to unpack .../16-libvisual-0.4-0_0.4.0-17build2_amd64.deb ...\n",
            "Unpacking libvisual-0.4-0:amd64 (0.4.0-17build2) ...\n",
            "Selecting previously unselected package gstreamer1.0-plugins-base:amd64.\n",
            "Preparing to unpack .../17-gstreamer1.0-plugins-base_1.20.1-1ubuntu0.4_amd64.deb ...\n",
            "Unpacking gstreamer1.0-plugins-base:amd64 (1.20.1-1ubuntu0.4) ...\n",
            "Selecting previously unselected package libaa1:amd64.\n",
            "Preparing to unpack .../18-libaa1_1.4p5-50build1_amd64.deb ...\n",
            "Unpacking libaa1:amd64 (1.4p5-50build1) ...\n",
            "Selecting previously unselected package libdv4:amd64.\n",
            "Preparing to unpack .../19-libdv4_1.0.0-14build1_amd64.deb ...\n",
            "Unpacking libdv4:amd64 (1.0.0-14build1) ...\n",
            "Selecting previously unselected package libgstreamer-plugins-good1.0-0:amd64.\n",
            "Preparing to unpack .../20-libgstreamer-plugins-good1.0-0_1.20.3-0ubuntu1.3_amd64.deb ...\n",
            "Unpacking libgstreamer-plugins-good1.0-0:amd64 (1.20.3-0ubuntu1.3) ...\n",
            "Selecting previously unselected package libgudev-1.0-0:amd64.\n",
            "Preparing to unpack .../21-libgudev-1.0-0_1%3a237-2build1_amd64.deb ...\n",
            "Unpacking libgudev-1.0-0:amd64 (1:237-2build1) ...\n",
            "Selecting previously unselected package libshout3:amd64.\n",
            "Preparing to unpack .../22-libshout3_2.4.5-1build3_amd64.deb ...\n",
            "Unpacking libshout3:amd64 (2.4.5-1build3) ...\n",
            "Selecting previously unselected package libtag1v5-vanilla:amd64.\n",
            "Preparing to unpack .../23-libtag1v5-vanilla_1.11.1+dfsg.1-3ubuntu3_amd64.deb ...\n",
            "Unpacking libtag1v5-vanilla:amd64 (1.11.1+dfsg.1-3ubuntu3) ...\n",
            "Selecting previously unselected package libtag1v5:amd64.\n",
            "Preparing to unpack .../24-libtag1v5_1.11.1+dfsg.1-3ubuntu3_amd64.deb ...\n",
            "Unpacking libtag1v5:amd64 (1.11.1+dfsg.1-3ubuntu3) ...\n",
            "Selecting previously unselected package libv4lconvert0:amd64.\n",
            "Preparing to unpack .../25-libv4lconvert0_1.22.1-2build1_amd64.deb ...\n",
            "Unpacking libv4lconvert0:amd64 (1.22.1-2build1) ...\n",
            "Selecting previously unselected package libv4l-0:amd64.\n",
            "Preparing to unpack .../26-libv4l-0_1.22.1-2build1_amd64.deb ...\n",
            "Unpacking libv4l-0:amd64 (1.22.1-2build1) ...\n",
            "Selecting previously unselected package libwavpack1:amd64.\n",
            "Preparing to unpack .../27-libwavpack1_5.4.0-1build2_amd64.deb ...\n",
            "Unpacking libwavpack1:amd64 (5.4.0-1build2) ...\n",
            "Selecting previously unselected package libsoup2.4-common.\n",
            "Preparing to unpack .../28-libsoup2.4-common_2.74.2-3ubuntu0.6_all.deb ...\n",
            "Unpacking libsoup2.4-common (2.74.2-3ubuntu0.6) ...\n",
            "Selecting previously unselected package libsoup2.4-1:amd64.\n",
            "Preparing to unpack .../29-libsoup2.4-1_2.74.2-3ubuntu0.6_amd64.deb ...\n",
            "Unpacking libsoup2.4-1:amd64 (2.74.2-3ubuntu0.6) ...\n",
            "Selecting previously unselected package gstreamer1.0-plugins-good:amd64.\n",
            "Preparing to unpack .../30-gstreamer1.0-plugins-good_1.20.3-0ubuntu1.3_amd64.deb ...\n",
            "Unpacking gstreamer1.0-plugins-good:amd64 (1.20.3-0ubuntu1.3) ...\n",
            "Selecting previously unselected package hunspell-en-us.\n",
            "Preparing to unpack .../31-hunspell-en-us_1%3a2020.12.07-2_all.deb ...\n",
            "Unpacking hunspell-en-us (1:2020.12.07-2) ...\n",
            "Selecting previously unselected package libabsl20210324:amd64.\n",
            "Preparing to unpack .../32-libabsl20210324_0~20210324.2-2ubuntu0.2_amd64.deb ...\n",
            "Unpacking libabsl20210324:amd64 (0~20210324.2-2ubuntu0.2) ...\n",
            "Selecting previously unselected package libaspell15:amd64.\n",
            "Preparing to unpack .../33-libaspell15_0.60.8-4build1_amd64.deb ...\n",
            "Unpacking libaspell15:amd64 (0.60.8-4build1) ...\n",
            "Selecting previously unselected package libgav1-0:amd64.\n",
            "Preparing to unpack .../34-libgav1-0_0.17.0-1build1_amd64.deb ...\n",
            "Unpacking libgav1-0:amd64 (0.17.0-1build1) ...\n",
            "Selecting previously unselected package libyuv0:amd64.\n",
            "Preparing to unpack .../35-libyuv0_0.0~git20220104.b91df1a-2_amd64.deb ...\n",
            "Unpacking libyuv0:amd64 (0.0~git20220104.b91df1a-2) ...\n",
            "Selecting previously unselected package libavif13:amd64.\n",
            "Preparing to unpack .../36-libavif13_0.9.3-3_amd64.deb ...\n",
            "Unpacking libavif13:amd64 (0.9.3-3) ...\n",
            "Selecting previously unselected package libdbus-glib-1-2:amd64.\n",
            "Preparing to unpack .../37-libdbus-glib-1-2_0.112-2build1_amd64.deb ...\n",
            "Unpacking libdbus-glib-1-2:amd64 (0.112-2build1) ...\n",
            "Selecting previously unselected package libdvdread8:amd64.\n",
            "Preparing to unpack .../38-libdvdread8_6.1.2-1_amd64.deb ...\n",
            "Unpacking libdvdread8:amd64 (6.1.2-1) ...\n",
            "Selecting previously unselected package libdvdnav4:amd64.\n",
            "Preparing to unpack .../39-libdvdnav4_6.1.1-1_amd64.deb ...\n",
            "Unpacking libdvdnav4:amd64 (6.1.1-1) ...\n",
            "Selecting previously unselected package libhunspell-1.7-0:amd64.\n",
            "Preparing to unpack .../40-libhunspell-1.7-0_1.7.0-4build1_amd64.deb ...\n",
            "Unpacking libhunspell-1.7-0:amd64 (1.7.0-4build1) ...\n",
            "Selecting previously unselected package libenchant-2-2:amd64.\n",
            "Preparing to unpack .../41-libenchant-2-2_2.3.2-1ubuntu2_amd64.deb ...\n",
            "Unpacking libenchant-2-2:amd64 (2.3.2-1ubuntu2) ...\n",
            "Selecting previously unselected package libfaad2:amd64.\n",
            "Preparing to unpack .../42-libfaad2_2.10.0-2_amd64.deb ...\n",
            "Unpacking libfaad2:amd64 (2.10.0-2) ...\n",
            "Selecting previously unselected package libffi7:amd64.\n",
            "Preparing to unpack .../43-libffi7_3.3-5ubuntu1_amd64.deb ...\n",
            "Unpacking libffi7:amd64 (3.3-5ubuntu1) ...\n",
            "Selecting previously unselected package libinstpatch-1.0-2:amd64.\n",
            "Preparing to unpack .../44-libinstpatch-1.0-2_1.1.6-1_amd64.deb ...\n",
            "Unpacking libinstpatch-1.0-2:amd64 (1.1.6-1) ...\n",
            "Selecting previously unselected package timgm6mb-soundfont.\n",
            "Preparing to unpack .../45-timgm6mb-soundfont_1.3-5_all.deb ...\n",
            "Unpacking timgm6mb-soundfont (1.3-5) ...\n",
            "Selecting previously unselected package libfluidsynth3:amd64.\n",
            "Preparing to unpack .../46-libfluidsynth3_2.2.5-1_amd64.deb ...\n",
            "Unpacking libfluidsynth3:amd64 (2.2.5-1) ...\n",
            "Selecting previously unselected package libfreeaptx0:amd64.\n",
            "Preparing to unpack .../47-libfreeaptx0_0.1.1-1_amd64.deb ...\n",
            "Unpacking libfreeaptx0:amd64 (0.1.1-1) ...\n",
            "Selecting previously unselected package libgssdp-1.2-0:amd64.\n",
            "Preparing to unpack .../48-libgssdp-1.2-0_1.4.0.1-2build1_amd64.deb ...\n",
            "Unpacking libgssdp-1.2-0:amd64 (1.4.0.1-2build1) ...\n",
            "Selecting previously unselected package libgstreamer-gl1.0-0:amd64.\n",
            "Preparing to unpack .../49-libgstreamer-gl1.0-0_1.20.1-1ubuntu0.4_amd64.deb ...\n",
            "Unpacking libgstreamer-gl1.0-0:amd64 (1.20.1-1ubuntu0.4) ...\n",
            "Selecting previously unselected package libgupnp-1.2-1:amd64.\n",
            "Preparing to unpack .../50-libgupnp-1.2-1_1.4.3-1_amd64.deb ...\n",
            "Unpacking libgupnp-1.2-1:amd64 (1.4.3-1) ...\n",
            "Selecting previously unselected package libgupnp-igd-1.0-4:amd64.\n",
            "Preparing to unpack .../51-libgupnp-igd-1.0-4_1.2.0-1build1_amd64.deb ...\n",
            "Unpacking libgupnp-igd-1.0-4:amd64 (1.2.0-1build1) ...\n",
            "Selecting previously unselected package libharfbuzz-icu0:amd64.\n",
            "Preparing to unpack .../52-libharfbuzz-icu0_2.7.4-1ubuntu3.2_amd64.deb ...\n",
            "Unpacking libharfbuzz-icu0:amd64 (2.7.4-1ubuntu3.2) ...\n",
            "Selecting previously unselected package libhyphen0:amd64.\n",
            "Preparing to unpack .../53-libhyphen0_2.8.8-7build2_amd64.deb ...\n",
            "Unpacking libhyphen0:amd64 (2.8.8-7build2) ...\n",
            "Selecting previously unselected package libjson-glib-1.0-common.\n",
            "Preparing to unpack .../54-libjson-glib-1.0-common_1.6.6-1build1_all.deb ...\n",
            "Unpacking libjson-glib-1.0-common (1.6.6-1build1) ...\n",
            "Selecting previously unselected package libjson-glib-1.0-0:amd64.\n",
            "Preparing to unpack .../55-libjson-glib-1.0-0_1.6.6-1build1_amd64.deb ...\n",
            "Unpacking libjson-glib-1.0-0:amd64 (1.6.6-1build1) ...\n",
            "Selecting previously unselected package libkate1:amd64.\n",
            "Preparing to unpack .../56-libkate1_0.4.1-11build1_amd64.deb ...\n",
            "Unpacking libkate1:amd64 (0.4.1-11build1) ...\n",
            "Selecting previously unselected package libldacbt-enc2:amd64.\n",
            "Preparing to unpack .../57-libldacbt-enc2_2.0.2.3+git20200429+ed310a0-4_amd64.deb ...\n",
            "Unpacking libldacbt-enc2:amd64 (2.0.2.3+git20200429+ed310a0-4) ...\n",
            "Selecting previously unselected package libltc11:amd64.\n",
            "Preparing to unpack .../58-libltc11_1.3.1-1_amd64.deb ...\n",
            "Unpacking libltc11:amd64 (1.3.1-1) ...\n",
            "Selecting previously unselected package libevdev2:amd64.\n",
            "Preparing to unpack .../59-libevdev2_1.12.1+dfsg-1_amd64.deb ...\n",
            "Unpacking libevdev2:amd64 (1.12.1+dfsg-1) ...\n",
            "Selecting previously unselected package libmanette-0.2-0:amd64.\n",
            "Preparing to unpack .../60-libmanette-0.2-0_0.2.6-3build1_amd64.deb ...\n",
            "Unpacking libmanette-0.2-0:amd64 (0.2.6-3build1) ...\n",
            "Selecting previously unselected package libmjpegutils-2.1-0:amd64.\n",
            "Preparing to unpack .../61-libmjpegutils-2.1-0_1%3a2.1.0+debian-6build1_amd64.deb ...\n",
            "Unpacking libmjpegutils-2.1-0:amd64 (1:2.1.0+debian-6build1) ...\n",
            "Selecting previously unselected package libmodplug1:amd64.\n",
            "Preparing to unpack .../62-libmodplug1_1%3a0.8.9.0-3_amd64.deb ...\n",
            "Unpacking libmodplug1:amd64 (1:0.8.9.0-3) ...\n",
            "Selecting previously unselected package libmpcdec6:amd64.\n",
            "Preparing to unpack .../63-libmpcdec6_2%3a0.1~r495-2_amd64.deb ...\n",
            "Unpacking libmpcdec6:amd64 (2:0.1~r495-2) ...\n",
            "Selecting previously unselected package libmpeg2encpp-2.1-0:amd64.\n",
            "Preparing to unpack .../64-libmpeg2encpp-2.1-0_1%3a2.1.0+debian-6build1_amd64.deb ...\n",
            "Unpacking libmpeg2encpp-2.1-0:amd64 (1:2.1.0+debian-6build1) ...\n",
            "Selecting previously unselected package libmplex2-2.1-0:amd64.\n",
            "Preparing to unpack .../65-libmplex2-2.1-0_1%3a2.1.0+debian-6build1_amd64.deb ...\n",
            "Unpacking libmplex2-2.1-0:amd64 (1:2.1.0+debian-6build1) ...\n",
            "Selecting previously unselected package libnice10:amd64.\n",
            "Preparing to unpack .../66-libnice10_0.1.18-2_amd64.deb ...\n",
            "Unpacking libnice10:amd64 (0.1.18-2) ...\n",
            "Selecting previously unselected package libnotify4:amd64.\n",
            "Preparing to unpack .../67-libnotify4_0.7.9-3ubuntu5.22.04.1_amd64.deb ...\n",
            "Unpacking libnotify4:amd64 (0.7.9-3ubuntu5.22.04.1) ...\n",
            "Selecting previously unselected package libopenh264-6:amd64.\n",
            "Preparing to unpack .../68-libopenh264-6_2.2.0+dfsg-2_amd64.deb ...\n",
            "Unpacking libopenh264-6:amd64 (2.2.0+dfsg-2) ...\n",
            "Selecting previously unselected package libopenni2-0:amd64.\n",
            "Preparing to unpack .../69-libopenni2-0_2.2.0.33+dfsg-15_amd64.deb ...\n",
            "Unpacking libopenni2-0:amd64 (2.2.0.33+dfsg-15) ...\n",
            "Selecting previously unselected package libqrencode4:amd64.\n",
            "Preparing to unpack .../70-libqrencode4_4.1.1-1_amd64.deb ...\n",
            "Unpacking libqrencode4:amd64 (4.1.1-1) ...\n",
            "Selecting previously unselected package libsecret-common.\n",
            "Preparing to unpack .../71-libsecret-common_0.20.5-2_all.deb ...\n",
            "Unpacking libsecret-common (0.20.5-2) ...\n",
            "Selecting previously unselected package libsecret-1-0:amd64.\n",
            "Preparing to unpack .../72-libsecret-1-0_0.20.5-2_amd64.deb ...\n",
            "Unpacking libsecret-1-0:amd64 (0.20.5-2) ...\n",
            "Selecting previously unselected package libsoundtouch1:amd64.\n",
            "Preparing to unpack .../73-libsoundtouch1_2.3.1+ds1-1_amd64.deb ...\n",
            "Unpacking libsoundtouch1:amd64 (2.3.1+ds1-1) ...\n",
            "Selecting previously unselected package libsoup-3.0-common.\n",
            "Preparing to unpack .../74-libsoup-3.0-common_3.0.7-0ubuntu1_all.deb ...\n",
            "Unpacking libsoup-3.0-common (3.0.7-0ubuntu1) ...\n",
            "Selecting previously unselected package libsoup-3.0-0:amd64.\n",
            "Preparing to unpack .../75-libsoup-3.0-0_3.0.7-0ubuntu1_amd64.deb ...\n",
            "Unpacking libsoup-3.0-0:amd64 (3.0.7-0ubuntu1) ...\n",
            "Selecting previously unselected package libspandsp2:amd64.\n",
            "Preparing to unpack .../76-libspandsp2_0.0.6+dfsg-2_amd64.deb ...\n",
            "Unpacking libspandsp2:amd64 (0.0.6+dfsg-2) ...\n",
            "Selecting previously unselected package libsrtp2-1:amd64.\n",
            "Preparing to unpack .../77-libsrtp2-1_2.4.2-2_amd64.deb ...\n",
            "Unpacking libsrtp2-1:amd64 (2.4.2-2) ...\n",
            "Selecting previously unselected package libwebrtc-audio-processing1:amd64.\n",
            "Preparing to unpack .../78-libwebrtc-audio-processing1_0.3.1-0ubuntu5_amd64.deb ...\n",
            "Unpacking libwebrtc-audio-processing1:amd64 (0.3.1-0ubuntu5) ...\n",
            "Selecting previously unselected package libwildmidi2:amd64.\n",
            "Preparing to unpack .../79-libwildmidi2_0.4.3-1_amd64.deb ...\n",
            "Unpacking libwildmidi2:amd64 (0.4.3-1) ...\n",
            "Selecting previously unselected package libwoff1:amd64.\n",
            "Preparing to unpack .../80-libwoff1_1.0.2-1build4_amd64.deb ...\n",
            "Unpacking libwoff1:amd64 (1.0.2-1build4) ...\n",
            "Selecting previously unselected package libxtst6:amd64.\n",
            "Preparing to unpack .../81-libxtst6_2%3a1.2.3-1build4_amd64.deb ...\n",
            "Unpacking libxtst6:amd64 (2:1.2.3-1build4) ...\n",
            "Selecting previously unselected package libzbar0:amd64.\n",
            "Preparing to unpack .../82-libzbar0_0.23.92-4build2_amd64.deb ...\n",
            "Unpacking libzbar0:amd64 (0.23.92-4build2) ...\n",
            "Selecting previously unselected package libzxingcore1:amd64.\n",
            "Preparing to unpack .../83-libzxingcore1_1.2.0-1_amd64.deb ...\n",
            "Unpacking libzxingcore1:amd64 (1.2.0-1) ...\n",
            "Selecting previously unselected package xfonts-encodings.\n",
            "Preparing to unpack .../84-xfonts-encodings_1%3a1.0.5-0ubuntu2_all.deb ...\n",
            "Unpacking xfonts-encodings (1:1.0.5-0ubuntu2) ...\n",
            "Selecting previously unselected package xfonts-utils.\n",
            "Preparing to unpack .../85-xfonts-utils_1%3a7.7+6build2_amd64.deb ...\n",
            "Unpacking xfonts-utils (1:7.7+6build2) ...\n",
            "Selecting previously unselected package xfonts-cyrillic.\n",
            "Preparing to unpack .../86-xfonts-cyrillic_1%3a1.0.5_all.deb ...\n",
            "Unpacking xfonts-cyrillic (1:1.0.5) ...\n",
            "Selecting previously unselected package xfonts-scalable.\n",
            "Preparing to unpack .../87-xfonts-scalable_1%3a1.0.3-1.2ubuntu1_all.deb ...\n",
            "Unpacking xfonts-scalable (1:1.0.3-1.2ubuntu1) ...\n",
            "Selecting previously unselected package libdca0:amd64.\n",
            "Preparing to unpack .../88-libdca0_0.0.7-2_amd64.deb ...\n",
            "Unpacking libdca0:amd64 (0.0.7-2) ...\n",
            "Selecting previously unselected package libgstreamer-plugins-bad1.0-0:amd64.\n",
            "Preparing to unpack .../89-libgstreamer-plugins-bad1.0-0_1.20.3-0ubuntu1.1_amd64.deb ...\n",
            "Unpacking libgstreamer-plugins-bad1.0-0:amd64 (1.20.3-0ubuntu1.1) ...\n",
            "Selecting previously unselected package libsbc1:amd64.\n",
            "Preparing to unpack .../90-libsbc1_1.5-3build2_amd64.deb ...\n",
            "Unpacking libsbc1:amd64 (1.5-3build2) ...\n",
            "Selecting previously unselected package libvo-aacenc0:amd64.\n",
            "Preparing to unpack .../91-libvo-aacenc0_0.1.3-2_amd64.deb ...\n",
            "Unpacking libvo-aacenc0:amd64 (0.1.3-2) ...\n",
            "Selecting previously unselected package libvo-amrwbenc0:amd64.\n",
            "Preparing to unpack .../92-libvo-amrwbenc0_0.1.3-2_amd64.deb ...\n",
            "Unpacking libvo-amrwbenc0:amd64 (0.1.3-2) ...\n",
            "Selecting previously unselected package gstreamer1.0-plugins-bad:amd64.\n",
            "Preparing to unpack .../93-gstreamer1.0-plugins-bad_1.20.3-0ubuntu1.1_amd64.deb ...\n",
            "Unpacking gstreamer1.0-plugins-bad:amd64 (1.20.3-0ubuntu1.1) ...\n",
            "Setting up libtext-iconv-perl (1.7-7build3) ...\n",
            "Setting up libfreeaptx0:amd64 (0.1.1-1) ...\n",
            "Setting up libmodplug1:amd64 (1:0.8.9.0-3) ...\n",
            "Setting up libcdparanoia0:amd64 (3.10.2+debian-14build2) ...\n",
            "Setting up libvo-amrwbenc0:amd64 (0.1.3-2) ...\n",
            "Setting up session-migration (0.3.6) ...\n",
            "Created symlink /etc/systemd/user/graphical-session-pre.target.wants/session-migration.service → /usr/lib/systemd/user/session-migration.service.\n",
            "Setting up libsbc1:amd64 (1.5-3build2) ...\n",
            "Setting up libproxy1v5:amd64 (0.4.17-2) ...\n",
            "Setting up libtag1v5-vanilla:amd64 (1.11.1+dfsg.1-3ubuntu3) ...\n",
            "Setting up libkate1:amd64 (0.4.1-11build1) ...\n",
            "Setting up libharfbuzz-icu0:amd64 (2.7.4-1ubuntu3.2) ...\n",
            "Setting up libopenni2-0:amd64 (2.2.0.33+dfsg-15) ...\n",
            "Setting up libwoff1:amd64 (1.0.2-1build4) ...\n",
            "Setting up libqrencode4:amd64 (4.1.1-1) ...\n",
            "Setting up libhyphen0:amd64 (2.8.8-7build2) ...\n",
            "Setting up dictionaries-common (1.28.14) ...\n",
            "Setting up fonts-noto-color-emoji (2.047-0ubuntu0.22.04.1) ...\n",
            "Setting up libvisual-0.4-0:amd64 (0.4.0-17build2) ...\n",
            "Setting up libaspell15:amd64 (0.60.8-4build1) ...\n",
            "Setting up libxtst6:amd64 (2:1.2.3-1build4) ...\n",
            "Setting up libsrtp2-1:amd64 (2.4.2-2) ...\n",
            "Setting up libffi7:amd64 (3.3-5ubuntu1) ...\n",
            "Setting up libldacbt-enc2:amd64 (2.0.2.3+git20200429+ed310a0-4) ...\n",
            "Setting up fonts-wqy-zenhei (0.9.45-8) ...\n",
            "Setting up libwebrtc-audio-processing1:amd64 (0.3.1-0ubuntu5) ...\n",
            "Setting up fonts-freefont-ttf (20120503-10build1) ...\n",
            "Setting up libsoup-3.0-common (3.0.7-0ubuntu1) ...\n",
            "Setting up libmpcdec6:amd64 (2:0.1~r495-2) ...\n",
            "Setting up libspandsp2:amd64 (0.0.6+dfsg-2) ...\n",
            "Setting up libvo-aacenc0:amd64 (0.1.3-2) ...\n",
            "Setting up libgstreamer-plugins-bad1.0-0:amd64 (1.20.3-0ubuntu1.1) ...\n",
            "Setting up libgstreamer-plugins-good1.0-0:amd64 (1.20.3-0ubuntu1.3) ...\n",
            "Setting up libsoundtouch1:amd64 (2.3.1+ds1-1) ...\n",
            "Setting up gstreamer1.0-plugins-base:amd64 (1.20.1-1ubuntu0.4) ...\n",
            "Setting up fonts-tlwg-loma-otf (1:0.7.3-1) ...\n",
            "Setting up libdvdread8:amd64 (6.1.2-1) ...\n",
            "Setting up libdbus-glib-1-2:amd64 (0.112-2build1) ...\n",
            "Setting up libnotify4:amd64 (0.7.9-3ubuntu5.22.04.1) ...\n",
            "Setting up xfonts-encodings (1:1.0.5-0ubuntu2) ...\n",
            "Setting up libfaad2:amd64 (2.10.0-2) ...\n",
            "Setting up libshout3:amd64 (2.4.5-1build3) ...\n",
            "Setting up libabsl20210324:amd64 (0~20210324.2-2ubuntu0.2) ...\n",
            "Setting up libltc11:amd64 (1.3.1-1) ...\n",
            "Setting up libsoup2.4-common (2.74.2-3ubuntu0.6) ...\n",
            "Setting up libtag1v5:amd64 (1.11.1+dfsg.1-3ubuntu3) ...\n",
            "Setting up libdv4:amd64 (1.0.0-14build1) ...\n",
            "Setting up fonts-ipafont-gothic (00303-21ubuntu1) ...\n",
            "update-alternatives: using /usr/share/fonts/opentype/ipafont-gothic/ipag.ttf to provide /usr/share/fonts/truetype/fonts-japanese-gothic.ttf (fonts-japanese-gothic.ttf) in auto mode\n",
            "Setting up libwildmidi2:amd64 (0.4.3-1) ...\n",
            "Setting up libopenh264-6:amd64 (2.2.0+dfsg-2) ...\n",
            "Setting up libwavpack1:amd64 (5.4.0-1build2) ...\n",
            "Setting up libzxingcore1:amd64 (1.2.0-1) ...\n",
            "Setting up libv4lconvert0:amd64 (1.22.1-2build1) ...\n",
            "Setting up hunspell-en-us (1:2020.12.07-2) ...\n",
            "Setting up libdca0:amd64 (0.0.7-2) ...\n",
            "Setting up libjson-glib-1.0-common (1.6.6-1build1) ...\n",
            "Setting up libhunspell-1.7-0:amd64 (1.7.0-4build1) ...\n",
            "Setting up glib-networking-common (2.72.0-1) ...\n",
            "Setting up timgm6mb-soundfont (1.3-5) ...\n",
            "update-alternatives: using /usr/share/sounds/sf2/TimGM6mb.sf2 to provide /usr/share/sounds/sf2/default-GM.sf2 (default-GM.sf2) in auto mode\n",
            "update-alternatives: using /usr/share/sounds/sf2/TimGM6mb.sf2 to provide /usr/share/sounds/sf3/default-GM.sf3 (default-GM.sf3) in auto mode\n",
            "Setting up libyuv0:amd64 (0.0~git20220104.b91df1a-2) ...\n",
            "Setting up libevdev2:amd64 (1.12.1+dfsg-1) ...\n",
            "Setting up gstreamer1.0-libav:amd64 (1.20.3-0ubuntu1) ...\n",
            "Setting up libinstpatch-1.0-2:amd64 (1.1.6-1) ...\n",
            "Setting up libmjpegutils-2.1-0:amd64 (1:2.1.0+debian-6build1) ...\n",
            "Setting up libgudev-1.0-0:amd64 (1:237-2build1) ...\n",
            "Setting up libsecret-common (0.20.5-2) ...\n",
            "Setting up libfluidsynth3:amd64 (2.2.5-1) ...\n",
            "Setting up libdvdnav4:amd64 (6.1.1-1) ...\n",
            "Setting up fonts-unifont (1:14.0.01-1) ...\n",
            "Setting up libaa1:amd64 (1.4p5-50build1) ...\n",
            "Setting up gsettings-desktop-schemas (42.0-1ubuntu1) ...\n",
            "Setting up glib-networking-services (2.72.0-1) ...\n",
            "Setting up libenchant-2-2:amd64 (2.3.2-1ubuntu2) ...\n",
            "Setting up libmanette-0.2-0:amd64 (0.2.6-3build1) ...\n",
            "Setting up xfonts-utils (1:7.7+6build2) ...\n",
            "Setting up libjson-glib-1.0-0:amd64 (1.6.6-1build1) ...\n",
            "Setting up libv4l-0:amd64 (1.22.1-2build1) ...\n",
            "Setting up libsecret-1-0:amd64 (0.20.5-2) ...\n",
            "Setting up libgstreamer-gl1.0-0:amd64 (1.20.1-1ubuntu0.4) ...\n",
            "Setting up libgav1-0:amd64 (0.17.0-1build1) ...\n",
            "Setting up libmpeg2encpp-2.1-0:amd64 (1:2.1.0+debian-6build1) ...\n",
            "Setting up libavif13:amd64 (0.9.3-3) ...\n",
            "Setting up xfonts-cyrillic (1:1.0.5) ...\n",
            "Setting up libmplex2-2.1-0:amd64 (1:2.1.0+debian-6build1) ...\n",
            "Setting up xfonts-scalable (1:1.0.3-1.2ubuntu1) ...\n",
            "Setting up libzbar0:amd64 (0.23.92-4build2) ...\n",
            "Processing triggers for man-db (2.10.2-1) ...\n",
            "Processing triggers for fontconfig (2.13.1-4.2ubuntu5) ...\n",
            "Processing triggers for libglib2.0-0:amd64 (2.72.4-0ubuntu2.5) ...\n",
            "Processing triggers for libc-bin (2.35-0ubuntu3.8) ...\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtcm_debug.so.1 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbmalloc_proxy.so.2 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbbind_2_0.so.3 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtcm.so.1 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbbind_2_5.so.3 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libhwloc.so.15 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libur_adapter_level_zero_v2.so.0 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libumf.so.0 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbmalloc.so.2 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbb.so.12 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libur_adapter_opencl.so.0 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libur_adapter_level_zero.so.0 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbbind.so.3 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libur_loader.so.0 is not a symbolic link\n",
            "\n",
            "Setting up glib-networking:amd64 (2.72.0-1) ...\n",
            "Setting up libsoup2.4-1:amd64 (2.74.2-3ubuntu0.6) ...\n",
            "Setting up gstreamer1.0-plugins-good:amd64 (1.20.3-0ubuntu1.3) ...\n",
            "Setting up libsoup-3.0-0:amd64 (3.0.7-0ubuntu1) ...\n",
            "Setting up libgssdp-1.2-0:amd64 (1.4.0.1-2build1) ...\n",
            "Setting up libgupnp-1.2-1:amd64 (1.4.3-1) ...\n",
            "Setting up libgupnp-igd-1.0-4:amd64 (1.2.0-1build1) ...\n",
            "Setting up libnice10:amd64 (0.1.18-2) ...\n",
            "Setting up gstreamer1.0-plugins-bad:amd64 (1.20.3-0ubuntu1.1) ...\n",
            "Processing triggers for dictionaries-common (1.28.14) ...\n",
            "Processing triggers for libc-bin (2.35-0ubuntu3.8) ...\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtcm_debug.so.1 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbmalloc_proxy.so.2 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbbind_2_0.so.3 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtcm.so.1 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbbind_2_5.so.3 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libhwloc.so.15 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libur_adapter_level_zero_v2.so.0 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libumf.so.0 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbmalloc.so.2 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbb.so.12 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libur_adapter_opencl.so.0 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libur_adapter_level_zero.so.0 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbbind.so.3 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libur_loader.so.0 is not a symbolic link\n",
            "\n",
            "Downloading Chromium 139.0.7258.5 (playwright build v1181)\u001b[2m from https://cdn.playwright.dev/dbazure/download/playwright/builds/chromium/1181/chromium-linux.zip\u001b[22m\n",
            "\u001b[1G172.5 MiB [] 0% 0.0s\u001b[0K\u001b[1G172.5 MiB [] 0% 346.0s\u001b[0K\u001b[1G172.5 MiB [] 0% 344.1s\u001b[0K\u001b[1G172.5 MiB [] 0% 220.2s\u001b[0K\u001b[1G172.5 MiB [] 0% 201.2s\u001b[0K\u001b[1G172.5 MiB [] 0% 155.9s\u001b[0K\u001b[1G172.5 MiB [] 0% 123.9s\u001b[0K\u001b[1G172.5 MiB [] 0% 126.2s\u001b[0K\u001b[1G172.5 MiB [] 0% 97.7s\u001b[0K\u001b[1G172.5 MiB [] 0% 77.3s\u001b[0K\u001b[1G172.5 MiB [] 0% 75.2s\u001b[0K\u001b[1G172.5 MiB [] 0% 59.1s\u001b[0K\u001b[1G172.5 MiB [] 0% 46.8s\u001b[0K\u001b[1G172.5 MiB [] 0% 44.3s\u001b[0K\u001b[1G172.5 MiB [] 1% 35.2s\u001b[0K\u001b[1G172.5 MiB [] 1% 28.0s\u001b[0K\u001b[1G172.5 MiB [] 1% 25.6s\u001b[0K\u001b[1G172.5 MiB [] 2% 20.9s\u001b[0K\u001b[1G172.5 MiB [] 2% 16.1s\u001b[0K\u001b[1G172.5 MiB [] 3% 14.4s\u001b[0K\u001b[1G172.5 MiB [] 3% 12.9s\u001b[0K\u001b[1G172.5 MiB [] 4% 11.4s\u001b[0K\u001b[1G172.5 MiB [] 4% 10.2s\u001b[0K\u001b[1G172.5 MiB [] 5% 9.2s\u001b[0K\u001b[1G172.5 MiB [] 5% 9.4s\u001b[0K\u001b[1G172.5 MiB [] 6% 8.3s\u001b[0K\u001b[1G172.5 MiB [] 6% 8.0s\u001b[0K\u001b[1G172.5 MiB [] 7% 7.6s\u001b[0K\u001b[1G172.5 MiB [] 8% 7.1s\u001b[0K\u001b[1G172.5 MiB [] 8% 6.7s\u001b[0K\u001b[1G172.5 MiB [] 9% 6.7s\u001b[0K\u001b[1G172.5 MiB [] 9% 6.5s\u001b[0K\u001b[1G172.5 MiB [] 10% 6.2s\u001b[0K\u001b[1G172.5 MiB [] 11% 5.8s\u001b[0K\u001b[1G172.5 MiB [] 11% 5.6s\u001b[0K\u001b[1G172.5 MiB [] 12% 5.3s\u001b[0K\u001b[1G172.5 MiB [] 13% 5.2s\u001b[0K\u001b[1G172.5 MiB [] 13% 5.1s\u001b[0K\u001b[1G172.5 MiB [] 14% 4.9s\u001b[0K\u001b[1G172.5 MiB [] 15% 4.7s\u001b[0K\u001b[1G172.5 MiB [] 16% 4.5s\u001b[0K\u001b[1G172.5 MiB [] 17% 4.4s\u001b[0K\u001b[1G172.5 MiB [] 18% 4.2s\u001b[0K\u001b[1G172.5 MiB [] 18% 4.1s\u001b[0K\u001b[1G172.5 MiB [] 19% 4.1s\u001b[0K\u001b[1G172.5 MiB [] 20% 3.9s\u001b[0K\u001b[1G172.5 MiB [] 21% 3.8s\u001b[0K\u001b[1G172.5 MiB [] 22% 3.7s\u001b[0K\u001b[1G172.5 MiB [] 23% 3.6s\u001b[0K\u001b[1G172.5 MiB [] 23% 3.5s\u001b[0K\u001b[1G172.5 MiB [] 24% 3.4s\u001b[0K\u001b[1G172.5 MiB [] 25% 3.4s\u001b[0K\u001b[1G172.5 MiB [] 26% 3.3s\u001b[0K\u001b[1G172.5 MiB [] 27% 3.2s\u001b[0K\u001b[1G172.5 MiB [] 28% 3.1s\u001b[0K\u001b[1G172.5 MiB [] 29% 3.1s\u001b[0K\u001b[1G172.5 MiB [] 30% 3.0s\u001b[0K\u001b[1G172.5 MiB [] 30% 2.9s\u001b[0K\u001b[1G172.5 MiB [] 31% 2.9s\u001b[0K\u001b[1G172.5 MiB [] 32% 2.8s\u001b[0K\u001b[1G172.5 MiB [] 33% 2.8s\u001b[0K\u001b[1G172.5 MiB [] 34% 2.7s\u001b[0K\u001b[1G172.5 MiB [] 35% 2.6s\u001b[0K\u001b[1G172.5 MiB [] 36% 2.6s\u001b[0K\u001b[1G172.5 MiB [] 36% 2.5s\u001b[0K\u001b[1G172.5 MiB [] 37% 2.5s\u001b[0K\u001b[1G172.5 MiB [] 38% 2.4s\u001b[0K\u001b[1G172.5 MiB [] 39% 2.4s\u001b[0K\u001b[1G172.5 MiB [] 40% 2.3s\u001b[0K\u001b[1G172.5 MiB [] 41% 2.3s\u001b[0K\u001b[1G172.5 MiB [] 41% 2.2s\u001b[0K\u001b[1G172.5 MiB [] 42% 2.2s\u001b[0K\u001b[1G172.5 MiB [] 43% 2.2s\u001b[0K\u001b[1G172.5 MiB [] 44% 2.1s\u001b[0K\u001b[1G172.5 MiB [] 45% 2.1s\u001b[0K\u001b[1G172.5 MiB [] 46% 2.0s\u001b[0K\u001b[1G172.5 MiB [] 47% 2.0s\u001b[0K\u001b[1G172.5 MiB [] 48% 1.9s\u001b[0K\u001b[1G172.5 MiB [] 49% 1.9s\u001b[0K\u001b[1G172.5 MiB [] 50% 1.8s\u001b[0K\u001b[1G172.5 MiB [] 51% 1.8s\u001b[0K\u001b[1G172.5 MiB [] 52% 1.8s\u001b[0K\u001b[1G172.5 MiB [] 52% 1.7s\u001b[0K\u001b[1G172.5 MiB [] 53% 1.7s\u001b[0K\u001b[1G172.5 MiB [] 54% 1.7s\u001b[0K\u001b[1G172.5 MiB [] 55% 1.6s\u001b[0K\u001b[1G172.5 MiB [] 56% 1.6s\u001b[0K\u001b[1G172.5 MiB [] 57% 1.5s\u001b[0K\u001b[1G172.5 MiB [] 58% 1.5s\u001b[0K\u001b[1G172.5 MiB [] 59% 1.4s\u001b[0K\u001b[1G172.5 MiB [] 60% 1.4s\u001b[0K\u001b[1G172.5 MiB [] 61% 1.4s\u001b[0K\u001b[1G172.5 MiB [] 62% 1.3s\u001b[0K\u001b[1G172.5 MiB [] 63% 1.3s\u001b[0K\u001b[1G172.5 MiB [] 64% 1.2s\u001b[0K\u001b[1G172.5 MiB [] 65% 1.2s\u001b[0K\u001b[1G172.5 MiB [] 66% 1.2s\u001b[0K\u001b[1G172.5 MiB [] 66% 1.1s\u001b[0K\u001b[1G172.5 MiB [] 67% 1.1s\u001b[0K\u001b[1G172.5 MiB [] 68% 1.1s\u001b[0K\u001b[1G172.5 MiB [] 69% 1.1s\u001b[0K\u001b[1G172.5 MiB [] 69% 1.0s\u001b[0K\u001b[1G172.5 MiB [] 70% 1.0s\u001b[0K\u001b[1G172.5 MiB [] 71% 1.0s\u001b[0K\u001b[1G172.5 MiB [] 72% 0.9s\u001b[0K\u001b[1G172.5 MiB [] 73% 0.9s\u001b[0K\u001b[1G172.5 MiB [] 74% 0.9s\u001b[0K\u001b[1G172.5 MiB [] 75% 0.8s\u001b[0K\u001b[1G172.5 MiB [] 76% 0.8s\u001b[0K\u001b[1G172.5 MiB [] 77% 0.8s\u001b[0K\u001b[1G172.5 MiB [] 78% 0.7s\u001b[0K\u001b[1G172.5 MiB [] 79% 0.7s\u001b[0K\u001b[1G172.5 MiB [] 80% 0.7s\u001b[0K\u001b[1G172.5 MiB [] 80% 0.6s\u001b[0K\u001b[1G172.5 MiB [] 81% 0.6s\u001b[0K\u001b[1G172.5 MiB [] 82% 0.6s\u001b[0K\u001b[1G172.5 MiB [] 83% 0.6s\u001b[0K\u001b[1G172.5 MiB [] 83% 0.5s\u001b[0K\u001b[1G172.5 MiB [] 84% 0.5s\u001b[0K\u001b[1G172.5 MiB [] 85% 0.5s\u001b[0K\u001b[1G172.5 MiB [] 86% 0.5s\u001b[0K\u001b[1G172.5 MiB [] 86% 0.4s\u001b[0K\u001b[1G172.5 MiB [] 87% 0.4s\u001b[0K\u001b[1G172.5 MiB [] 88% 0.4s\u001b[0K\u001b[1G172.5 MiB [] 89% 0.4s\u001b[0K\u001b[1G172.5 MiB [] 89% 0.3s\u001b[0K\u001b[1G172.5 MiB [] 90% 0.3s\u001b[0K\u001b[1G172.5 MiB [] 91% 0.3s\u001b[0K\u001b[1G172.5 MiB [] 92% 0.3s\u001b[0K\u001b[1G172.5 MiB [] 92% 0.2s\u001b[0K\u001b[1G172.5 MiB [] 93% 0.2s\u001b[0K\u001b[1G172.5 MiB [] 94% 0.2s\u001b[0K\u001b[1G172.5 MiB [] 95% 0.2s\u001b[0K\u001b[1G172.5 MiB [] 95% 0.1s\u001b[0K\u001b[1G172.5 MiB [] 96% 0.1s\u001b[0K\u001b[1G172.5 MiB [] 97% 0.1s\u001b[0K\u001b[1G172.5 MiB [] 98% 0.1s\u001b[0K\u001b[1G172.5 MiB [] 98% 0.0s\u001b[0K\u001b[1G172.5 MiB [] 99% 0.0s\u001b[0K\u001b[1G172.5 MiB [] 100% 0.0s\u001b[0K\n",
            "Chromium 139.0.7258.5 (playwright build v1181) downloaded to /root/.cache/ms-playwright/chromium-1181\n",
            "Downloading Chromium Headless Shell 139.0.7258.5 (playwright build v1181)\u001b[2m from https://cdn.playwright.dev/dbazure/download/playwright/builds/chromium/1181/chromium-headless-shell-linux.zip\u001b[22m\n",
            "\u001b[1G104.8 MiB [] 0% 0.0s\u001b[0K\u001b[1G104.8 MiB [] 0% 181.0s\u001b[0K\u001b[1G104.8 MiB [] 0% 192.7s\u001b[0K\u001b[1G104.8 MiB [] 0% 128.2s\u001b[0K\u001b[1G104.8 MiB [] 0% 117.8s\u001b[0K\u001b[1G104.8 MiB [] 0% 92.2s\u001b[0K\u001b[1G104.8 MiB [] 0% 73.5s\u001b[0K\u001b[1G104.8 MiB [] 0% 74.8s\u001b[0K\u001b[1G104.8 MiB [] 0% 58.0s\u001b[0K\u001b[1G104.8 MiB [] 0% 46.4s\u001b[0K\u001b[1G104.8 MiB [] 0% 45.1s\u001b[0K\u001b[1G104.8 MiB [] 0% 35.6s\u001b[0K\u001b[1G104.8 MiB [] 1% 28.2s\u001b[0K\u001b[1G104.8 MiB [] 1% 26.4s\u001b[0K\u001b[1G104.8 MiB [] 1% 21.0s\u001b[0K\u001b[1G104.8 MiB [] 2% 16.6s\u001b[0K\u001b[1G104.8 MiB [] 2% 15.2s\u001b[0K\u001b[1G104.8 MiB [] 3% 12.1s\u001b[0K\u001b[1G104.8 MiB [] 4% 9.5s\u001b[0K\u001b[1G104.8 MiB [] 5% 8.4s\u001b[0K\u001b[1G104.8 MiB [] 6% 7.3s\u001b[0K\u001b[1G104.8 MiB [] 7% 6.2s\u001b[0K\u001b[1G104.8 MiB [] 8% 5.5s\u001b[0K\u001b[1G104.8 MiB [] 9% 5.2s\u001b[0K\u001b[1G104.8 MiB [] 9% 5.3s\u001b[0K\u001b[1G104.8 MiB [] 10% 4.7s\u001b[0K\u001b[1G104.8 MiB [] 11% 4.4s\u001b[0K\u001b[1G104.8 MiB [] 13% 4.0s\u001b[0K\u001b[1G104.8 MiB [] 13% 3.9s\u001b[0K\u001b[1G104.8 MiB [] 15% 3.6s\u001b[0K\u001b[1G104.8 MiB [] 16% 3.5s\u001b[0K\u001b[1G104.8 MiB [] 18% 3.2s\u001b[0K\u001b[1G104.8 MiB [] 19% 3.0s\u001b[0K\u001b[1G104.8 MiB [] 21% 2.8s\u001b[0K\u001b[1G104.8 MiB [] 21% 2.9s\u001b[0K\u001b[1G104.8 MiB [] 22% 2.8s\u001b[0K\u001b[1G104.8 MiB [] 24% 2.6s\u001b[0K\u001b[1G104.8 MiB [] 25% 2.5s\u001b[0K\u001b[1G104.8 MiB [] 26% 2.4s\u001b[0K\u001b[1G104.8 MiB [] 27% 2.3s\u001b[0K\u001b[1G104.8 MiB [] 28% 2.3s\u001b[0K\u001b[1G104.8 MiB [] 29% 2.2s\u001b[0K\u001b[1G104.8 MiB [] 30% 2.1s\u001b[0K\u001b[1G104.8 MiB [] 31% 2.1s\u001b[0K\u001b[1G104.8 MiB [] 32% 2.0s\u001b[0K\u001b[1G104.8 MiB [] 33% 2.0s\u001b[0K\u001b[1G104.8 MiB [] 35% 1.9s\u001b[0K\u001b[1G104.8 MiB [] 37% 1.8s\u001b[0K\u001b[1G104.8 MiB [] 38% 1.7s\u001b[0K\u001b[1G104.8 MiB [] 39% 1.7s\u001b[0K\u001b[1G104.8 MiB [] 40% 1.6s\u001b[0K\u001b[1G104.8 MiB [] 42% 1.6s\u001b[0K\u001b[1G104.8 MiB [] 43% 1.5s\u001b[0K\u001b[1G104.8 MiB [] 45% 1.4s\u001b[0K\u001b[1G104.8 MiB [] 46% 1.4s\u001b[0K\u001b[1G104.8 MiB [] 47% 1.4s\u001b[0K\u001b[1G104.8 MiB [] 48% 1.4s\u001b[0K\u001b[1G104.8 MiB [] 50% 1.3s\u001b[0K\u001b[1G104.8 MiB [] 51% 1.2s\u001b[0K\u001b[1G104.8 MiB [] 52% 1.2s\u001b[0K\u001b[1G104.8 MiB [] 53% 1.2s\u001b[0K\u001b[1G104.8 MiB [] 54% 1.1s\u001b[0K\u001b[1G104.8 MiB [] 55% 1.1s\u001b[0K\u001b[1G104.8 MiB [] 56% 1.1s\u001b[0K\u001b[1G104.8 MiB [] 57% 1.1s\u001b[0K\u001b[1G104.8 MiB [] 58% 1.0s\u001b[0K\u001b[1G104.8 MiB [] 59% 1.0s\u001b[0K\u001b[1G104.8 MiB [] 60% 1.0s\u001b[0K\u001b[1G104.8 MiB [] 61% 0.9s\u001b[0K\u001b[1G104.8 MiB [] 62% 0.9s\u001b[0K\u001b[1G104.8 MiB [] 63% 0.9s\u001b[0K\u001b[1G104.8 MiB [] 64% 0.9s\u001b[0K\u001b[1G104.8 MiB [] 64% 0.8s\u001b[0K\u001b[1G104.8 MiB [] 66% 0.8s\u001b[0K\u001b[1G104.8 MiB [] 67% 0.8s\u001b[0K\u001b[1G104.8 MiB [] 68% 0.8s\u001b[0K\u001b[1G104.8 MiB [] 68% 0.7s\u001b[0K\u001b[1G104.8 MiB [] 69% 0.7s\u001b[0K\u001b[1G104.8 MiB [] 70% 0.7s\u001b[0K\u001b[1G104.8 MiB [] 71% 0.7s\u001b[0K\u001b[1G104.8 MiB [] 72% 0.6s\u001b[0K\u001b[1G104.8 MiB [] 73% 0.6s\u001b[0K\u001b[1G104.8 MiB [] 74% 0.6s\u001b[0K\u001b[1G104.8 MiB [] 75% 0.6s\u001b[0K\u001b[1G104.8 MiB [] 77% 0.5s\u001b[0K\u001b[1G104.8 MiB [] 78% 0.5s\u001b[0K\u001b[1G104.8 MiB [] 79% 0.5s\u001b[0K\u001b[1G104.8 MiB [] 80% 0.5s\u001b[0K\u001b[1G104.8 MiB [] 80% 0.4s\u001b[0K\u001b[1G104.8 MiB [] 81% 0.4s\u001b[0K\u001b[1G104.8 MiB [] 82% 0.4s\u001b[0K\u001b[1G104.8 MiB [] 83% 0.4s\u001b[0K\u001b[1G104.8 MiB [] 84% 0.4s\u001b[0K\u001b[1G104.8 MiB [] 85% 0.3s\u001b[0K\u001b[1G104.8 MiB [] 86% 0.3s\u001b[0K\u001b[1G104.8 MiB [] 87% 0.3s\u001b[0K\u001b[1G104.8 MiB [] 88% 0.3s\u001b[0K\u001b[1G104.8 MiB [] 89% 0.2s\u001b[0K\u001b[1G104.8 MiB [] 90% 0.2s\u001b[0K\u001b[1G104.8 MiB [] 91% 0.2s\u001b[0K\u001b[1G104.8 MiB [] 92% 0.2s\u001b[0K\u001b[1G104.8 MiB [] 93% 0.2s\u001b[0K\u001b[1G104.8 MiB [] 94% 0.1s\u001b[0K\u001b[1G104.8 MiB [] 95% 0.1s\u001b[0K\u001b[1G104.8 MiB [] 96% 0.1s\u001b[0K\u001b[1G104.8 MiB [] 97% 0.1s\u001b[0K\u001b[1G104.8 MiB [] 98% 0.0s\u001b[0K\u001b[1G104.8 MiB [] 99% 0.0s\u001b[0K\u001b[1G104.8 MiB [] 100% 0.0s\u001b[0K\n",
            "Chromium Headless Shell 139.0.7258.5 (playwright build v1181) downloaded to /root/.cache/ms-playwright/chromium_headless_shell-1181\n",
            "Downloading Firefox 140.0.2 (playwright build v1489)\u001b[2m from https://cdn.playwright.dev/dbazure/download/playwright/builds/firefox/1489/firefox-ubuntu-22.04.zip\u001b[22m\n",
            "\u001b[1G92.5 MiB [] 0% 0.0s\u001b[0K\u001b[1G92.5 MiB [] 0% 173.6s\u001b[0K\u001b[1G92.5 MiB [] 0% 175.6s\u001b[0K\u001b[1G92.5 MiB [] 0% 109.7s\u001b[0K\u001b[1G92.5 MiB [] 0% 100.9s\u001b[0K\u001b[1G92.5 MiB [] 0% 74.1s\u001b[0K\u001b[1G92.5 MiB [] 0% 60.8s\u001b[0K\u001b[1G92.5 MiB [] 0% 62.9s\u001b[0K\u001b[1G92.5 MiB [] 0% 48.9s\u001b[0K\u001b[1G92.5 MiB [] 0% 37.7s\u001b[0K\u001b[1G92.5 MiB [] 0% 38.4s\u001b[0K\u001b[1G92.5 MiB [] 0% 29.5s\u001b[0K\u001b[1G92.5 MiB [] 1% 23.1s\u001b[0K\u001b[1G92.5 MiB [] 1% 22.2s\u001b[0K\u001b[1G92.5 MiB [] 1% 17.6s\u001b[0K\u001b[1G92.5 MiB [] 2% 13.9s\u001b[0K\u001b[1G92.5 MiB [] 2% 12.9s\u001b[0K\u001b[1G92.5 MiB [] 3% 10.1s\u001b[0K\u001b[1G92.5 MiB [] 5% 8.0s\u001b[0K\u001b[1G92.5 MiB [] 5% 7.1s\u001b[0K\u001b[1G92.5 MiB [] 7% 5.9s\u001b[0K\u001b[1G92.5 MiB [] 9% 4.8s\u001b[0K\u001b[1G92.5 MiB [] 9% 4.7s\u001b[0K\u001b[1G92.5 MiB [] 10% 4.4s\u001b[0K\u001b[1G92.5 MiB [] 12% 3.7s\u001b[0K\u001b[1G92.5 MiB [] 13% 3.5s\u001b[0K\u001b[1G92.5 MiB [] 14% 3.3s\u001b[0K\u001b[1G92.5 MiB [] 16% 2.9s\u001b[0K\u001b[1G92.5 MiB [] 18% 2.8s\u001b[0K\u001b[1G92.5 MiB [] 19% 2.7s\u001b[0K\u001b[1G92.5 MiB [] 20% 2.4s\u001b[0K\u001b[1G92.5 MiB [] 22% 2.4s\u001b[0K\u001b[1G92.5 MiB [] 23% 2.3s\u001b[0K\u001b[1G92.5 MiB [] 24% 2.2s\u001b[0K\u001b[1G92.5 MiB [] 26% 2.0s\u001b[0K\u001b[1G92.5 MiB [] 27% 2.0s\u001b[0K\u001b[1G92.5 MiB [] 28% 1.9s\u001b[0K\u001b[1G92.5 MiB [] 30% 1.8s\u001b[0K\u001b[1G92.5 MiB [] 31% 1.7s\u001b[0K\u001b[1G92.5 MiB [] 33% 1.7s\u001b[0K\u001b[1G92.5 MiB [] 34% 1.6s\u001b[0K\u001b[1G92.5 MiB [] 36% 1.5s\u001b[0K\u001b[1G92.5 MiB [] 37% 1.5s\u001b[0K\u001b[1G92.5 MiB [] 38% 1.4s\u001b[0K\u001b[1G92.5 MiB [] 40% 1.4s\u001b[0K\u001b[1G92.5 MiB [] 41% 1.3s\u001b[0K\u001b[1G92.5 MiB [] 43% 1.3s\u001b[0K\u001b[1G92.5 MiB [] 44% 1.2s\u001b[0K\u001b[1G92.5 MiB [] 45% 1.2s\u001b[0K\u001b[1G92.5 MiB [] 46% 1.1s\u001b[0K\u001b[1G92.5 MiB [] 47% 1.1s\u001b[0K\u001b[1G92.5 MiB [] 49% 1.1s\u001b[0K\u001b[1G92.5 MiB [] 51% 1.0s\u001b[0K\u001b[1G92.5 MiB [] 52% 1.0s\u001b[0K\u001b[1G92.5 MiB [] 53% 1.0s\u001b[0K\u001b[1G92.5 MiB [] 54% 0.9s\u001b[0K\u001b[1G92.5 MiB [] 56% 0.9s\u001b[0K\u001b[1G92.5 MiB [] 57% 0.9s\u001b[0K\u001b[1G92.5 MiB [] 58% 0.8s\u001b[0K\u001b[1G92.5 MiB [] 59% 0.8s\u001b[0K\u001b[1G92.5 MiB [] 60% 0.8s\u001b[0K\u001b[1G92.5 MiB [] 62% 0.7s\u001b[0K\u001b[1G92.5 MiB [] 63% 0.7s\u001b[0K\u001b[1G92.5 MiB [] 65% 0.7s\u001b[0K\u001b[1G92.5 MiB [] 66% 0.7s\u001b[0K\u001b[1G92.5 MiB [] 67% 0.6s\u001b[0K\u001b[1G92.5 MiB [] 68% 0.6s\u001b[0K\u001b[1G92.5 MiB [] 69% 0.6s\u001b[0K\u001b[1G92.5 MiB [] 70% 0.6s\u001b[0K\u001b[1G92.5 MiB [] 71% 0.5s\u001b[0K\u001b[1G92.5 MiB [] 73% 0.5s\u001b[0K\u001b[1G92.5 MiB [] 74% 0.5s\u001b[0K\u001b[1G92.5 MiB [] 75% 0.5s\u001b[0K\u001b[1G92.5 MiB [] 76% 0.4s\u001b[0K\u001b[1G92.5 MiB [] 77% 0.4s\u001b[0K\u001b[1G92.5 MiB [] 78% 0.4s\u001b[0K\u001b[1G92.5 MiB [] 79% 0.4s\u001b[0K\u001b[1G92.5 MiB [] 81% 0.3s\u001b[0K\u001b[1G92.5 MiB [] 82% 0.3s\u001b[0K\u001b[1G92.5 MiB [] 83% 0.3s\u001b[0K\u001b[1G92.5 MiB [] 84% 0.3s\u001b[0K\u001b[1G92.5 MiB [] 85% 0.3s\u001b[0K\u001b[1G92.5 MiB [] 86% 0.2s\u001b[0K\u001b[1G92.5 MiB [] 87% 0.2s\u001b[0K\u001b[1G92.5 MiB [] 89% 0.2s\u001b[0K\u001b[1G92.5 MiB [] 90% 0.2s\u001b[0K\u001b[1G92.5 MiB [] 92% 0.1s\u001b[0K\u001b[1G92.5 MiB [] 94% 0.1s\u001b[0K\u001b[1G92.5 MiB [] 95% 0.1s\u001b[0K\u001b[1G92.5 MiB [] 96% 0.1s\u001b[0K\u001b[1G92.5 MiB [] 98% 0.0s\u001b[0K\u001b[1G92.5 MiB [] 99% 0.0s\u001b[0K\u001b[1G92.5 MiB [] 100% 0.0s\u001b[0K\n",
            "Firefox 140.0.2 (playwright build v1489) downloaded to /root/.cache/ms-playwright/firefox-1489\n",
            "Downloading Webkit 26.0 (playwright build v2191)\u001b[2m from https://cdn.playwright.dev/dbazure/download/playwright/builds/webkit/2191/webkit-ubuntu-22.04.zip\u001b[22m\n",
            "\u001b[1G94.4 MiB [] 0% 0.0s\u001b[0K\u001b[1G94.4 MiB [] 0% 177.1s\u001b[0K\u001b[1G94.4 MiB [] 0% 176.7s\u001b[0K\u001b[1G94.4 MiB [] 0% 112.1s\u001b[0K\u001b[1G94.4 MiB [] 0% 103.0s\u001b[0K\u001b[1G94.4 MiB [] 0% 75.7s\u001b[0K\u001b[1G94.4 MiB [] 0% 64.3s\u001b[0K\u001b[1G94.4 MiB [] 0% 49.9s\u001b[0K\u001b[1G94.4 MiB [] 0% 38.5s\u001b[0K\u001b[1G94.4 MiB [] 0% 39.2s\u001b[0K\u001b[1G94.4 MiB [] 0% 30.1s\u001b[0K\u001b[1G94.4 MiB [] 1% 23.6s\u001b[0K\u001b[1G94.4 MiB [] 1% 22.8s\u001b[0K\u001b[1G94.4 MiB [] 1% 17.7s\u001b[0K\u001b[1G94.4 MiB [] 2% 14.0s\u001b[0K\u001b[1G94.4 MiB [] 2% 13.2s\u001b[0K\u001b[1G94.4 MiB [] 3% 10.5s\u001b[0K\u001b[1G94.4 MiB [] 5% 7.9s\u001b[0K\u001b[1G94.4 MiB [] 5% 7.3s\u001b[0K\u001b[1G94.4 MiB [] 7% 5.8s\u001b[0K\u001b[1G94.4 MiB [] 8% 5.0s\u001b[0K\u001b[1G94.4 MiB [] 9% 4.6s\u001b[0K\u001b[1G94.4 MiB [] 10% 4.6s\u001b[0K\u001b[1G94.4 MiB [] 11% 4.1s\u001b[0K\u001b[1G94.4 MiB [] 13% 3.6s\u001b[0K\u001b[1G94.4 MiB [] 14% 3.4s\u001b[0K\u001b[1G94.4 MiB [] 15% 3.1s\u001b[0K\u001b[1G94.4 MiB [] 16% 3.1s\u001b[0K\u001b[1G94.4 MiB [] 17% 3.0s\u001b[0K\u001b[1G94.4 MiB [] 18% 2.8s\u001b[0K\u001b[1G94.4 MiB [] 20% 2.6s\u001b[0K\u001b[1G94.4 MiB [] 21% 2.5s\u001b[0K\u001b[1G94.4 MiB [] 23% 2.4s\u001b[0K\u001b[1G94.4 MiB [] 24% 2.2s\u001b[0K\u001b[1G94.4 MiB [] 25% 2.2s\u001b[0K\u001b[1G94.4 MiB [] 27% 2.0s\u001b[0K\u001b[1G94.4 MiB [] 28% 2.0s\u001b[0K\u001b[1G94.4 MiB [] 29% 1.9s\u001b[0K\u001b[1G94.4 MiB [] 31% 1.8s\u001b[0K\u001b[1G94.4 MiB [] 32% 1.8s\u001b[0K\u001b[1G94.4 MiB [] 33% 1.7s\u001b[0K\u001b[1G94.4 MiB [] 34% 1.6s\u001b[0K\u001b[1G94.4 MiB [] 36% 1.6s\u001b[0K\u001b[1G94.4 MiB [] 37% 1.5s\u001b[0K\u001b[1G94.4 MiB [] 38% 1.5s\u001b[0K\u001b[1G94.4 MiB [] 40% 1.4s\u001b[0K\u001b[1G94.4 MiB [] 41% 1.4s\u001b[0K\u001b[1G94.4 MiB [] 42% 1.3s\u001b[0K\u001b[1G94.4 MiB [] 43% 1.3s\u001b[0K\u001b[1G94.4 MiB [] 44% 1.3s\u001b[0K\u001b[1G94.4 MiB [] 46% 1.2s\u001b[0K\u001b[1G94.4 MiB [] 47% 1.2s\u001b[0K\u001b[1G94.4 MiB [] 48% 1.2s\u001b[0K\u001b[1G94.4 MiB [] 49% 1.1s\u001b[0K\u001b[1G94.4 MiB [] 51% 1.1s\u001b[0K\u001b[1G94.4 MiB [] 52% 1.0s\u001b[0K\u001b[1G94.4 MiB [] 53% 1.0s\u001b[0K\u001b[1G94.4 MiB [] 54% 1.0s\u001b[0K\u001b[1G94.4 MiB [] 56% 0.9s\u001b[0K\u001b[1G94.4 MiB [] 57% 0.9s\u001b[0K\u001b[1G94.4 MiB [] 58% 0.9s\u001b[0K\u001b[1G94.4 MiB [] 60% 0.8s\u001b[0K\u001b[1G94.4 MiB [] 62% 0.8s\u001b[0K\u001b[1G94.4 MiB [] 63% 0.8s\u001b[0K\u001b[1G94.4 MiB [] 64% 0.7s\u001b[0K\u001b[1G94.4 MiB [] 65% 0.7s\u001b[0K\u001b[1G94.4 MiB [] 66% 0.7s\u001b[0K\u001b[1G94.4 MiB [] 68% 0.6s\u001b[0K\u001b[1G94.4 MiB [] 69% 0.6s\u001b[0K\u001b[1G94.4 MiB [] 70% 0.6s\u001b[0K\u001b[1G94.4 MiB [] 71% 0.6s\u001b[0K\u001b[1G94.4 MiB [] 72% 0.5s\u001b[0K\u001b[1G94.4 MiB [] 74% 0.5s\u001b[0K\u001b[1G94.4 MiB [] 75% 0.5s\u001b[0K\u001b[1G94.4 MiB [] 76% 0.5s\u001b[0K\u001b[1G94.4 MiB [] 78% 0.4s\u001b[0K\u001b[1G94.4 MiB [] 79% 0.4s\u001b[0K\u001b[1G94.4 MiB [] 80% 0.4s\u001b[0K\u001b[1G94.4 MiB [] 82% 0.3s\u001b[0K\u001b[1G94.4 MiB [] 83% 0.3s\u001b[0K\u001b[1G94.4 MiB [] 84% 0.3s\u001b[0K\u001b[1G94.4 MiB [] 86% 0.3s\u001b[0K\u001b[1G94.4 MiB [] 87% 0.2s\u001b[0K\u001b[1G94.4 MiB [] 88% 0.2s\u001b[0K\u001b[1G94.4 MiB [] 90% 0.2s\u001b[0K\u001b[1G94.4 MiB [] 91% 0.2s\u001b[0K\u001b[1G94.4 MiB [] 92% 0.1s\u001b[0K\u001b[1G94.4 MiB [] 94% 0.1s\u001b[0K\u001b[1G94.4 MiB [] 95% 0.1s\u001b[0K\u001b[1G94.4 MiB [] 97% 0.1s\u001b[0K\u001b[1G94.4 MiB [] 98% 0.0s\u001b[0K\u001b[1G94.4 MiB [] 99% 0.0s\u001b[0K\u001b[1G94.4 MiB [] 100% 0.0s\u001b[0K\n",
            "Webkit 26.0 (playwright build v2191) downloaded to /root/.cache/ms-playwright/webkit-2191\n",
            "Downloading FFMPEG playwright build v1011\u001b[2m from https://cdn.playwright.dev/dbazure/download/playwright/builds/ffmpeg/1011/ffmpeg-linux.zip\u001b[22m\n",
            "\u001b[1G2.3 MiB [] 0% 0.0s\u001b[0K\u001b[1G2.3 MiB [] 1% 3.9s\u001b[0K\u001b[1G2.3 MiB [] 2% 4.1s\u001b[0K\u001b[1G2.3 MiB [] 4% 2.6s\u001b[0K\u001b[1G2.3 MiB [] 6% 2.4s\u001b[0K\u001b[1G2.3 MiB [] 9% 1.8s\u001b[0K\u001b[1G2.3 MiB [] 13% 1.3s\u001b[0K\u001b[1G2.3 MiB [] 14% 1.4s\u001b[0K\u001b[1G2.3 MiB [] 19% 1.0s\u001b[0K\u001b[1G2.3 MiB [] 26% 0.7s\u001b[0K\u001b[1G2.3 MiB [] 30% 0.7s\u001b[0K\u001b[1G2.3 MiB [] 39% 0.5s\u001b[0K\u001b[1G2.3 MiB [] 52% 0.3s\u001b[0K\u001b[1G2.3 MiB [] 61% 0.2s\u001b[0K\u001b[1G2.3 MiB [] 80% 0.1s\u001b[0K\u001b[1G2.3 MiB [] 100% 0.0s\u001b[0K\n",
            "FFMPEG playwright build v1011 downloaded to /root/.cache/ms-playwright/ffmpeg-1011\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ПАРСИНГ"
      ],
      "metadata": {
        "id": "xnwfBzewmjTR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "import time\n",
        "import json\n",
        "import csv\n",
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "from urllib.parse import urljoin, urlparse, urlsplit, urlunsplit\n",
        "from pathlib import Path\n",
        "\n",
        "# --- Сохранение на Google Drive ---\n",
        "try:\n",
        "    from google.colab import drive\n",
        "    drive.mount('/content/drive', force_remount=True)\n",
        "    BASE_DIR = Path(\"/content/drive/MyDrive/MyDrive_ITMO/BOT\")\n",
        "except Exception:\n",
        "    # если не Colab — падаем на локальный каталог\n",
        "    BASE_DIR = Path(\"data\")\n",
        "\n",
        "PDF_DIR = BASE_DIR / \"files\"\n",
        "PDF_DIR.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "FILE_EXTS = (\".pdf\", \".doc\", \".docx\", \".xls\", \".xlsx\", \".csv\")\n",
        "\n",
        "# --- HTTP ---\n",
        "CONNECT_TIMEOUT, READ_TIMEOUT = 10, 20\n",
        "HEADERS = {\"User-Agent\": \"Mozilla/5.0\"}\n",
        "\n",
        "def get_html(url):\n",
        "    try:\n",
        "        r = requests.get(url, timeout=(CONNECT_TIMEOUT, READ_TIMEOUT), headers=HEADERS)\n",
        "        r.raise_for_status()\n",
        "        if not r.encoding:\n",
        "            r.encoding = r.apparent_encoding or \"utf-8\"\n",
        "        return r.text\n",
        "    except Exception as e:\n",
        "        print(f\"[ERR] {url}: {e}\")\n",
        "        return \"\"\n",
        "\n",
        "def download(url, path):\n",
        "    try:\n",
        "        r = requests.get(url, timeout=(CONNECT_TIMEOUT, READ_TIMEOUT), headers=HEADERS)\n",
        "        r.raise_for_status()\n",
        "        with open(path, \"wb\") as f:\n",
        "            f.write(r.content)\n",
        "        return True\n",
        "    except Exception as e:\n",
        "        print(f\"[DL-ERR] {url}: {e}\")\n",
        "        return False\n",
        "\n",
        "# --- Нормализация URL (убираем ?query и #fragment, чтобы меньше дублей) ---\n",
        "def normalize_url(base, href):\n",
        "    absu = urljoin(base, (href or \"\").strip())\n",
        "    parts = list(urlsplit(absu))\n",
        "    parts[3] = \"\"  # query\n",
        "    parts[4] = \"\"  # fragment\n",
        "    return urlunsplit(parts)\n",
        "\n",
        "# --- Текст из PDF ---\n",
        "def pdf_to_lines(path: Path) -> list[str]:\n",
        "    try:\n",
        "        import fitz\n",
        "    except ImportError:\n",
        "        return []\n",
        "    lines = []\n",
        "    try:\n",
        "        doc = fitz.open(path)\n",
        "        for i, page in enumerate(doc, 1):\n",
        "            text = page.get_text()\n",
        "            for ln in text.splitlines():\n",
        "                t = ln.strip()\n",
        "                if 3 < len(t) < 240:\n",
        "                    lines.append(f\"[p.{i}] {t}\")\n",
        "    except Exception:\n",
        "        return []\n",
        "    return lines\n",
        "\n",
        "# --- Текст из DOCX ---\n",
        "def docx_to_lines(path: Path) -> list[str]:\n",
        "    try:\n",
        "        from docx import Document\n",
        "    except ImportError:\n",
        "        return []\n",
        "    lines = []\n",
        "    try:\n",
        "        doc = Document(path)\n",
        "        for p in doc.paragraphs:\n",
        "            t = p.text.strip()\n",
        "            if 3 < len(t) < 240:\n",
        "                lines.append(t)\n",
        "        for tbl in doc.tables:\n",
        "            for row in tbl.rows:\n",
        "                cells = [c.text.strip() for c in row.cells]\n",
        "                if any(cells):\n",
        "                    s = \" | \".join(cells)\n",
        "                    if 3 < len(s) < 240:\n",
        "                        lines.append(s)\n",
        "    except Exception:\n",
        "        return []\n",
        "    return lines\n",
        "\n",
        "# --- Контакты (mailto/tel + из текста) ---\n",
        "MAIL_RE  = re.compile(r\"[A-Za-z0-9._%+-]+@[A-Za-z0-9.-]+\\.[A-Za-z]{2,}\")\n",
        "PHONE_RE = re.compile(r\"\\+?\\d[\\d\\-\\s()]{8,}\\d\")\n",
        "\n",
        "def extract_contacts_from_soup(soup: BeautifulSoup, page_url: str):\n",
        "    contacts = []\n",
        "    # mailto / tel\n",
        "    for a in soup.select('a[href^=\"mailto:\"], a[href^=\"tel:\"]'):\n",
        "        href = a.get(\"href\", \"\")\n",
        "        label = a.get_text(\" \", strip=True)\n",
        "        if href.startswith(\"mailto:\"):\n",
        "            contacts.append({\"type\":\"email\",\"value\":href.split(\":\",1)[1],\"label\":label,\"url\":page_url})\n",
        "        elif href.startswith(\"tel:\"):\n",
        "            contacts.append({\"type\":\"phone\",\"value\":href.split(\":\",1)[1],\"label\":label,\"url\":page_url})\n",
        "    # из текста (на случай, если нет href)\n",
        "    txt = soup.get_text(\" \", strip=True)\n",
        "    for m in MAIL_RE.finditer(txt):\n",
        "        contacts.append({\"type\":\"email\",\"value\":m.group(0),\"label\":\"\",\"url\":page_url})\n",
        "    for m in PHONE_RE.finditer(txt):\n",
        "        raw = m.group(0)\n",
        "        if len(re.sub(r\"\\D\",\"\",raw)) >= 9:\n",
        "            contacts.append({\"type\":\"phone\",\"value\":raw,\"label\":\"\",\"url\":page_url})\n",
        "    # дедуп по (type,value,url)\n",
        "    uniq = {}\n",
        "    for c in contacts:\n",
        "        uniq[(c[\"type\"], c[\"value\"], c[\"url\"])] = c\n",
        "    return list(uniq.values())\n",
        "\n",
        "# --- Сбор файлов с одной страницы + HTML текст ---\n",
        "def find_resources_and_html(url, visited_files):\n",
        "    soup = BeautifulSoup(get_html(url), \"html.parser\")\n",
        "    html_text = []\n",
        "\n",
        "    # Собираем текст со страницы (чуть шире: заголовки тоже полезны)\n",
        "    for tag in soup.find_all([\"h1\", \"h2\", \"h3\", \"p\", \"li\", \"div\", \"span\", \"td\", \"th\"]):\n",
        "        t = tag.get_text(\" \", strip=True)\n",
        "        if 3 < len(t) < 240:\n",
        "            html_text.append(t)\n",
        "\n",
        "    found_files = []\n",
        "    for a in soup.find_all(\"a\", href=True):\n",
        "        href = normalize_url(url, a[\"href\"].strip())\n",
        "        if not any(href.lower().endswith(ext) for ext in FILE_EXTS):\n",
        "            continue\n",
        "        if href not in visited_files:\n",
        "            visited_files.add(href)\n",
        "            found_files.append({\"url\": href, \"text\": a.get_text(\" \", strip=True) or \"\"})\n",
        "\n",
        "    # Контакты\n",
        "    contacts = extract_contacts_from_soup(soup, url)\n",
        "\n",
        "    # Ссылки для обхода (как было, но нормализуем)\n",
        "    links = [\n",
        "        (a.get_text(\" \", strip=True) or \"\", normalize_url(url, a[\"href\"].strip()))\n",
        "        for a in soup.find_all(\"a\", href=True)\n",
        "    ]\n",
        "\n",
        "    return found_files, html_text, links, contacts\n",
        "\n",
        "# --- Рекурсивный сбор до глубины ---\n",
        "def crawl(url, depth=1):\n",
        "    visited_files = set()\n",
        "    seen_pages = set()\n",
        "    all_files = []\n",
        "    all_html_text = []\n",
        "    all_contacts = []\n",
        "    to_visit = [(url, 0)]\n",
        "\n",
        "    while to_visit:\n",
        "        cur_url, d = to_visit.pop(0)\n",
        "        if cur_url in seen_pages:\n",
        "            continue\n",
        "        seen_pages.add(cur_url)\n",
        "\n",
        "        files, html_text, links_html, contacts = find_resources_and_html(cur_url, visited_files)\n",
        "        all_files.extend(files)\n",
        "        all_html_text.extend(html_text)\n",
        "        all_contacts.extend(contacts)\n",
        "\n",
        "        if d < depth:\n",
        "            for _, href in links_html:\n",
        "                if urlparse(href).netloc == urlparse(url).netloc and href not in seen_pages:\n",
        "                    if not any(href.lower().endswith(ext) for ext in FILE_EXTS):\n",
        "                        to_visit.append((href, d + 1))\n",
        "        time.sleep(0.5)\n",
        "    return all_files, all_html_text, all_contacts\n",
        "\n",
        "# --- Скачка и извлечение текста ---\n",
        "def grab_all_files(files, prefix):\n",
        "    texts = []\n",
        "    saved = []\n",
        "    for i, f in enumerate(files, 1):\n",
        "        ext = Path(urlparse(f[\"url\"]).path).suffix.lower()\n",
        "        path = PDF_DIR / f\"{prefix}_{i}{ext or '.bin'}\"\n",
        "        if download(f[\"url\"], path):\n",
        "            saved.append({\"file\": path.name, \"url\": f[\"url\"]})\n",
        "            if ext == \".pdf\":\n",
        "                texts.extend(pdf_to_lines(path))\n",
        "            elif ext == \".docx\":\n",
        "                texts.extend(docx_to_lines(path))\n",
        "    return texts, saved\n",
        "\n",
        "# --- Главная функция ---\n",
        "def parse_program(url):\n",
        "    all_files, html_texts, contacts = crawl(url, depth=2)\n",
        "    file_texts, saved_files = grab_all_files(all_files, \"file\")\n",
        "    result = {\n",
        "        \"HTML_TEXT\": html_texts,\n",
        "        \"FILE_TEXT\": file_texts,\n",
        "        \"FILES\": saved_files,\n",
        "        \"CONTACTS\": contacts\n",
        "    }\n",
        "    return result\n",
        "\n",
        "# --- Хелперы сохранения ---\n",
        "def save_json(obj, path: Path):\n",
        "    path.parent.mkdir(parents=True, exist_ok=True)\n",
        "    path.write_text(json.dumps(obj, ensure_ascii=False, indent=2))\n",
        "\n",
        "def save_contacts_csv(contacts, path: Path):\n",
        "    path.parent.mkdir(parents=True, exist_ok=True)\n",
        "    with open(path, \"w\", newline=\"\", encoding=\"utf-8\") as f:\n",
        "        w = csv.writer(f, delimiter=\";\")\n",
        "        w.writerow([\"type\",\"value\",\"label\",\"url\"])\n",
        "        for c in contacts:\n",
        "            w.writerow([c.get(\"type\",\"\"), c.get(\"value\",\"\"), c.get(\"label\",\"\"), c.get(\"url\",\"\")])\n",
        "\n",
        "# --- Пример ---\n",
        "if __name__ == \"__main__\":\n",
        "    urls = [\n",
        "        \"https://abit.itmo.ru/program/master/ai\",\n",
        "        \"https://abit.itmo.ru/program/master/ai_product\"\n",
        "    ]\n",
        "\n",
        "    all_contacts = []\n",
        "    for u in urls:\n",
        "        data = parse_program(u)\n",
        "\n",
        "        print(f\"=== {u} ===\")\n",
        "        print(f\"HTML_TEXT lines: {len(data['HTML_TEXT'])}\")\n",
        "        print(f\"FILE_TEXT lines: {len(data['FILE_TEXT'])}\")\n",
        "        print(f\"FILES: {len(data['FILES'])}\")\n",
        "        print(f\"CONTACTS: {len(data['CONTACTS'])}\")\n",
        "\n",
        "        # сохраняем JSON по каждой программе\n",
        "        fname = urlparse(u).path.strip(\"/\").replace(\"/\", \"_\") + \".json\"\n",
        "        out_json = BASE_DIR / fname\n",
        "        save_json(data, out_json)\n",
        "        print(\"Saved JSON:\", out_json)\n",
        "\n",
        "        all_contacts.extend(data[\"CONTACTS\"])\n",
        "\n",
        "    # общий CSV контактов\n",
        "    contacts_csv = BASE_DIR / \"contacts.csv\"\n",
        "    save_contacts_csv(all_contacts, contacts_csv)\n",
        "    print(\"Contacts CSV:\", contacts_csv)\n",
        "\n",
        "    print(\"Files saved to:\", PDF_DIR.resolve())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HrXMYj5rppyd",
        "outputId": "aa540738-dec0-4ae3-b788-ac19093b241f"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "=== https://abit.itmo.ru/program/master/ai ===\n",
            "HTML_TEXT lines: 3103\n",
            "FILE_TEXT lines: 0\n",
            "FILES: 12\n",
            "CONTACTS: 134\n",
            "Saved JSON: data/program_master_ai.json\n",
            "=== https://abit.itmo.ru/program/master/ai_product ===\n",
            "HTML_TEXT lines: 2180\n",
            "FILE_TEXT lines: 0\n",
            "FILES: 8\n",
            "CONTACTS: 114\n",
            "Saved JSON: data/program_master_ai_product.json\n",
            "Contacts CSV: data/contacts.csv\n",
            "Files saved to: /content/data/files\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Сохраняем в JSON"
      ],
      "metadata": {
        "id": "uYKQkDeXSeiF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# --- Сбор корпуса по программам ---\n",
        "def build_corpus(program_name, parsed_data):\n",
        "    \"\"\"\n",
        "    Объединяет HTML-текст и текст из файлов в единый корпус для программы.\n",
        "    \"\"\"\n",
        "    corpus = []\n",
        "\n",
        "    # HTML-текст\n",
        "    for line in parsed_data.get(\"HTML_TEXT\", []):\n",
        "        corpus.append(line)\n",
        "\n",
        "    # Текст из файлов (если был извлечён)\n",
        "    for line in parsed_data.get(\"FILE_TEXT\", []):\n",
        "        corpus.append(line)\n",
        "\n",
        "    return {\n",
        "        \"program\": program_name,\n",
        "        \"text\": corpus,\n",
        "        \"files\": parsed_data.get(\"FILES\", [])\n",
        "    }\n",
        "\n",
        "# --- Пример: используем данные после парсинга ---\n",
        "programs_data = {}\n",
        "\n",
        "# Парсинг двух программ\n",
        "data_ai = parse_program(\"https://abit.itmo.ru/program/master/ai\")\n",
        "programs_data[\"ai\"] = build_corpus(\"Artificial Intelligence\", data_ai)\n",
        "\n",
        "data_ai_prod = parse_program(\"https://abit.itmo.ru/program/master/ai_product\")\n",
        "programs_data[\"ai_product\"] = build_corpus(\"AI Product Management\", data_ai_prod)\n",
        "\n",
        "# Теперь programs_data содержит корпуса по обеим программам\n",
        "print(f\"Корпус AI: {len(programs_data['ai']['text'])} строк\")\n",
        "print(f\"Корпус AI Product: {len(programs_data['ai_product']['text'])} строк\")\n",
        "\n",
        "# --- Сохраняем в JSON ---\n",
        "import json\n",
        "with open(\"programs_corpus.json\", \"w\", encoding=\"utf-8\") as f:\n",
        "    json.dump(programs_data, f, ensure_ascii=False, indent=2)\n",
        "\n",
        "print(\"Сохранено в programs_corpus.json\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pbqe0CvzSbTN",
        "outputId": "55dc67e1-e63d-4c17-b7b5-e6d71935086a"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Корпус AI: 3103 строк\n",
            "Корпус AI Product: 2180 строк\n",
            "Сохранено в programs_corpus.json\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# === Склейка готовых дампов в один programs_corpus.json (без перепарсинга) ===\n",
        "# Читает:  /content/drive/MyDrive/MyDrive_ITMO/BOT/program_master_ai.json\n",
        "#          /content/drive/MyDrive/MyDrive_ITMO/BOT/program_master_ai_product.json\n",
        "# Пишет:   ./programs_corpus.json  и копию в /content/drive/MyDrive/MyDrive_ITMO/BOT/programs_corpus.json\n",
        "\n",
        "import json\n",
        "from pathlib import Path\n",
        "\n",
        "DRIVE_DIR = Path(\"/content/drive/MyDrive/MyDrive_ITMO/BOT\")\n",
        "SRC_AI = DRIVE_DIR / \"program_master_ai.json\"\n",
        "SRC_PM = DRIVE_DIR / \"program_master_ai_product.json\"\n",
        "OUT_LOCAL = Path(\"programs_corpus.json\")\n",
        "OUT_DRIVE = DRIVE_DIR / \"programs_corpus.json\"\n",
        "\n",
        "def _load_json(p: Path):\n",
        "    assert p.exists(), f\"Нет файла: {p}\"\n",
        "    return json.loads(p.read_text(encoding=\"utf-8\"))\n",
        "\n",
        "def _dedup_keep_order(seq):\n",
        "    seen = set(); out = []\n",
        "    for x in seq or []:\n",
        "        if isinstance(x, str):\n",
        "            s = x.strip()\n",
        "            if s and s not in seen:\n",
        "                seen.add(s); out.append(s)\n",
        "    return out\n",
        "\n",
        "def _entry(program_name: str, src: dict):\n",
        "    return {\n",
        "        \"program\": program_name,\n",
        "        \"file_text\": _dedup_keep_order(src.get(\"FILE_TEXT\", [])),\n",
        "        \"html_text\": _dedup_keep_order(src.get(\"HTML_TEXT\", [])),\n",
        "        \"files\": src.get(\"FILES\", []),\n",
        "        \"contacts\": src.get(\"CONTACTS\", []),\n",
        "    }\n",
        "\n",
        "ai       = _load_json(SRC_AI)\n",
        "ai_prod  = _load_json(SRC_PM)\n",
        "\n",
        "corpus = {\n",
        "    \"ai\": _entry(\"Artificial Intelligence\", ai),\n",
        "    \"ai_product\": _entry(\"AI Product Management\", ai_prod),\n",
        "}\n",
        "\n",
        "OUT_LOCAL.write_text(json.dumps(corpus, ensure_ascii=False, indent=2), encoding=\"utf-8\")\n",
        "print(\"Saved local:\", OUT_LOCAL.resolve())\n",
        "\n",
        "OUT_DRIVE.write_text(json.dumps(corpus, ensure_ascii=False, indent=2), encoding=\"utf-8\")\n",
        "print(\"Saved drive:\", OUT_DRIVE)\n",
        "\n",
        "# Краткий отчёт\n",
        "print(\"\\n[report]\")\n",
        "for k in (\"ai\", \"ai_product\"):\n",
        "    e = corpus[k]\n",
        "    print(f\"{k}: file_text={len(e['file_text'])} | html_text={len(e['html_text'])} | files={len(e['files'])} | contacts={len(e['contacts'])}\")\n"
      ],
      "metadata": {
        "id": "2GwbRe44Zyti"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Быстрый индекс с кешем"
      ],
      "metadata": {
        "id": "wc7MQlcFgVxK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip -q install langchain langchain-community langchain-huggingface faiss-cpu\n",
        "!pip -q install langchain langchain-community langchain-huggingface faiss-cpu python-telegram-bot requests nest_asyncio\n"
      ],
      "metadata": {
        "id": "UucTW7sbqDwq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# === fast_index_cache_build.py (Drive-persistent + fixed cache check) ===\n",
        "import os, json, time, torch, warnings\n",
        "from pathlib import Path\n",
        "from typing import List\n",
        "from tqdm.auto import tqdm\n",
        "\n",
        "from langchain.docstore.document import Document\n",
        "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
        "from langchain_community.vectorstores import FAISS\n",
        "from langchain_huggingface import HuggingFaceEmbeddings\n",
        "\n",
        "# тише, HF\n",
        "os.environ[\"HF_HUB_DISABLE_TELEMETRY\"] = \"1\"\n",
        "warnings.filterwarnings(\"ignore\", category=UserWarning, module=\"huggingface_hub.utils._auth\")\n",
        "\n",
        "# источник корпуса\n",
        "SRC = Path(\"programs_corpus.json\")\n",
        "assert SRC.exists(), \"Нет programs_corpus.json (собери склейкой перед этим шагом).\"\n",
        "\n",
        "# ——— кэш индексов на Google Drive (если доступен), иначе локально ———\n",
        "try:\n",
        "    from google.colab import drive\n",
        "    drive.mount('/content/drive', force_remount=True)\n",
        "    CACHE_DIR = Path(\"/content/drive/MyDrive/MyDrive_ITMO/BOT/index_cache\")\n",
        "except Exception:\n",
        "    CACHE_DIR = Path(\"index_cache\")\n",
        "CACHE_DIR.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "IDX_FILE_ONLY = CACHE_DIR / \"faiss_file_only\"   # индекс только file_text\n",
        "IDX_ALL       = CACHE_DIR / \"faiss_all\"         # индекс file_text + html_text\n",
        "\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "print(f\"[i] device: {device}\")\n",
        "\n",
        "emb = HuggingFaceEmbeddings(\n",
        "    model_name=\"sentence-transformers/all-MiniLM-L6-v2\",\n",
        "    model_kwargs={\"device\": device},\n",
        ")\n",
        "\n",
        "data = json.loads(SRC.read_text(encoding=\"utf-8\"))\n",
        "\n",
        "def make_docs(entry: dict, key: str) -> List[Document]:\n",
        "    arr = entry.get(key) or []\n",
        "    docs: List[Document] = []\n",
        "    for s in arr:\n",
        "        if isinstance(s, str):\n",
        "            s = s.strip()\n",
        "            if s:\n",
        "                docs.append(Document(page_content=s, metadata={\"program\": entry.get(\"program\"), \"src\": key}))\n",
        "    return docs\n",
        "\n",
        "# крупнее чанки → меньше эмбеддингов (быстрее индекс)\n",
        "splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=80)\n",
        "\n",
        "def embed_with_progress(texts: List[str], batch_size: int = 128) -> List[List[float]]:\n",
        "    vectors: List[List[float]] = []\n",
        "    total = len(texts)\n",
        "    if total == 0:\n",
        "        return vectors\n",
        "    pbar = tqdm(total=total, desc=\"Embedding\", unit=\"chunk\")\n",
        "    t0 = time.time()\n",
        "    for i in range(0, total, batch_size):\n",
        "        batch = texts[i:i+batch_size]\n",
        "        vecs = emb.embed_documents(batch)\n",
        "        vectors.extend(vecs)\n",
        "        pbar.update(len(batch))\n",
        "        done = i + len(batch)\n",
        "        elapsed = time.time() - t0\n",
        "        rate = done / max(elapsed, 1e-6)\n",
        "        remain = (total - done) / max(rate, 1e-6)\n",
        "        pbar.set_postfix_str(f\"rate≈{rate:.1f}/s eta≈{remain:,.0f}s\")\n",
        "    pbar.close()\n",
        "    return vectors\n",
        "\n",
        "# ——— правильная проверка наличия кэша FAISS ———\n",
        "def _faiss_cache_ok(path: Path) -> bool:\n",
        "    return (path / \"index.pkl\").exists() and (path / \"index.faiss\").exists()\n",
        "\n",
        "def build_or_load(index_path: Path, docs: List[Document], title: str) -> FAISS:\n",
        "    \"\"\"Если кэш есть — грузим, иначе строим и сохраняем.\"\"\"\n",
        "    index_path.mkdir(parents=True, exist_ok=True)\n",
        "    if _faiss_cache_ok(index_path):\n",
        "        print(f\"[OK] load cache → {index_path}\")\n",
        "        return FAISS.load_local(str(index_path), emb, allow_dangerous_deserialization=True)\n",
        "\n",
        "    print(f\"\\n[i] build index → {index_path}  ({title})\")\n",
        "    t0 = time.time()\n",
        "\n",
        "    print(\"[1/3] split documents …\")\n",
        "    chunks = splitter.split_documents(docs)\n",
        "    print(f\"     chunks: {len(chunks)}\")\n",
        "\n",
        "    print(\"[2/3] compute embeddings …\")\n",
        "    texts = [d.page_content for d in chunks]\n",
        "    metas = [d.metadata     for d in chunks]\n",
        "    vectors = embed_with_progress(texts, batch_size=128)\n",
        "\n",
        "    print(\"[3/3] build FAISS …\")\n",
        "    # новая сигнатура: передаём пары (text, embedding)\n",
        "    text_embeddings = list(zip(texts, vectors))\n",
        "    vs = FAISS.from_embeddings(text_embeddings=text_embeddings,\n",
        "                               embedding=emb,\n",
        "                               metadatas=metas)\n",
        "    vs.save_local(str(index_path))\n",
        "\n",
        "    dt = time.time() - t0\n",
        "    print(f\"[OK] built in {dt:.1f}s | chunks={len(chunks)} | saved → {index_path}\")\n",
        "    return vs\n",
        "\n",
        "# ---------- сбор исходных доков ----------\n",
        "docs_file: List[Document] = []\n",
        "for key in (\"ai\", \"ai_product\"):\n",
        "    docs_file += make_docs(data[key], \"file_text\")\n",
        "\n",
        "docs_all: List[Document] = []\n",
        "for key in (\"ai\", \"ai_product\"):\n",
        "    docs_all += make_docs(data[key], \"file_text\") + make_docs(data[key], \"html_text\")\n",
        "\n",
        "print(f\"[i] docs (file_text): {len(docs_file)} | docs (all): {len(docs_all)}\")\n",
        "\n",
        "# ---------- построение/загрузка индексов ----------\n",
        "vs_file = build_or_load(IDX_FILE_ONLY, docs_file, title=\"file_text only (PDF/DOCX приоритет)\")\n",
        "vs_all  = build_or_load(IDX_ALL,       docs_all,  title=\"file_text + html_text\")\n",
        "\n",
        "print(f\"\\n[READY] cache dir: {CACHE_DIR.resolve()}\")\n",
        "for p in sorted(CACHE_DIR.glob(\"*\")):\n",
        "    try:\n",
        "        size = sum(f.stat().st_size for f in p.glob(\"**/*\") if f.is_file())\n",
        "        print(\" -\", p.name, size//1024, \"KB\")\n",
        "    except Exception:\n",
        "        print(\" -\", p.name)\n"
      ],
      "metadata": {
        "id": "SzPY2fnuYFt3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# TG‑бот на кеше (file‑first retriever)"
      ],
      "metadata": {
        "id": "tNfPaajakmZx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ====== ACCESS BLOCK: вводим ТОЛЬКО Authorization key (Сбер) ======\n",
        "import os, re, base64, binascii, unicodedata, requests, urllib3\n",
        "from getpass import getpass\n",
        "urllib3.disable_warnings(urllib3.exceptions.InsecureRequestWarning)\n",
        "\n",
        "SCOPE = \"GIGACHAT_API_PERS\"\n",
        "\n",
        "# !!! ЗАМЕНИ на НОВЫЙ токен после перевыпуска у @BotFather !!!\n",
        "TG_TOKEN_RAW = \"7858029775:AAG2qpyCW--2ZeBto3Hzy7KLwX70RPWUemU\"\n",
        "\n",
        "def _mask(s, h=6, t=4):\n",
        "    s = str(s)\n",
        "    return (s[:h] + \"…\" + s[-t:]) if len(s) > h+t else s\n",
        "\n",
        "raw_inp = getpass(\"Вставь Authorization key (base64, можно с 'Basic'): \").strip()\n",
        "raw_inp = unicodedata.normalize(\"NFKC\", raw_inp).replace(\"\\u200b\",\"\").replace(\"\\u2060\",\"\")\n",
        "\n",
        "# Явно отлавливаем, если ты вдруг вставил TG-токен (формат: цифры:буквы_дефисы)\n",
        "if re.fullmatch(r\"\\d+:[A-Za-z0-9_\\-]{30,}\", raw_inp):\n",
        "    raise SystemExit(\"[ERR] Это Telegram Bot Token, а не ключ Сбера. Вставь Authorization key из кабинета (base64(client_id:client_secret)).\")\n",
        "\n",
        "m = re.search(r'(?i)basic\\s+([A-Za-z0-9+/=\\s]+)$', raw_inp)\n",
        "auth_b64 = m.group(1) if m else raw_inp\n",
        "auth_b64 = re.sub(r'[\\r\\n\\t \"\\']+', '', auth_b64)\n",
        "auth_b64 = re.sub(r'[^A-Za-z0-9+/=]', '', auth_b64)\n",
        "\n",
        "# валидация: внутри должен быть \"client_id:client_secret\"\n",
        "try:\n",
        "    decoded = base64.b64decode(auth_b64, validate=True).decode(\"utf-8\", \"ignore\")\n",
        "    assert \":\" in decoded and all(decoded.split(\":\",1)), \"decoded not client_id:client_secret\"\n",
        "except Exception as e:\n",
        "    raise SystemExit(f\"[ERR] Authorization key повреждён: {e}. Скопируй строку из поля 'Authorization key' в кабинете Сбера.\")\n",
        "\n",
        "AUTH_BASIC = f\"Basic {auth_b64}\"\n",
        "\n",
        "# 2) Кладём в ENV\n",
        "tg = unicodedata.normalize(\"NFKC\", TG_TOKEN_RAW).strip().strip(\"'\\\"`\").replace(\"\\u200b\",\"\").replace(\"\\u2060\",\"\")\n",
        "os.environ[\"TELEGRAM_BOT_TOKEN\"] = tg\n",
        "os.environ[\"GIGA_AUTH_BASIC\"] = AUTH_BASIC\n",
        "\n",
        "# 3) Мини-тест Telegram\n",
        "r = requests.get(f\"https://api.telegram.org/bot{tg}/getMe\", timeout=15)\n",
        "print(\"TG getMe:\", r.status_code, (\"OK\" if r.ok else r.text))\n",
        "print(\"TG token head/tail:\", _mask(tg))\n",
        "\n",
        "# 4) Мини-тест OAuth (Сбер)\n",
        "resp = requests.post(\n",
        "    \"https://ngw.devices.sberbank.ru:9443/api/v2/oauth\",\n",
        "    headers={\n",
        "        \"Authorization\": AUTH_BASIC,\n",
        "        \"Content-Type\": \"application/x-www-form-urlencoded\",\n",
        "        \"Accept\": \"application/json\",\n",
        "        \"RqUID\": \"00000000-0000-0000-0000-000000000001\",\n",
        "    },\n",
        "    data={\"scope\": SCOPE},\n",
        "    timeout=30, verify=False\n",
        ")\n",
        "print(\"OAuth preflight:\", resp.status_code, resp.text[:160])\n",
        "if resp.status_code != 200:\n",
        "    raise SystemExit(f\"[ERR] OAuth {resp.status_code}: {resp.text}\")\n",
        "\n",
        "print(\"AUTH ok:\", \"Basic\", _mask(auth_b64), \"| client_id:\", _mask(decoded.split(':',1)[0]))\n",
        "print(\"Доступы готовы. Ниже запускай блок с ботом.\")\n"
      ],
      "metadata": {
        "id": "rp7CFBwPIuph"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os, re, json, csv\n",
        "from pathlib import Path\n",
        "\n",
        "# ---------- ПУТИ ----------\n",
        "GDRIVE_DIR = Path(\"/content/drive/MyDrive/MyDrive_ITMO/BOT\")\n",
        "RAW_CANDIDATES = [\n",
        "    GDRIVE_DIR / \"contacts.csv\",\n",
        "    Path(\"/mnt/data/contacts.csv\"),\n",
        "    Path(\"contacts.csv\"),\n",
        "]\n",
        "OUT_JSON     = GDRIVE_DIR / \"contacts.json\"           # сюда бот смотрит\n",
        "BACKUP_JSON  = GDRIVE_DIR / \"contacts_raw_backup.json\"  # полный нормализованный дамп (для проверки)\n",
        "\n",
        "GDRIVE_DIR.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "# ---------- ПАРАМЕТРЫ ----------\n",
        "TOP_K_PER_PROGRAM = 4         # сколько контактов на программу оставить\n",
        "KEEP_ONLY_MANAGERISH = True   # стараться оставлять менеджеров/координаторов\n",
        "\n",
        "# ---------- HELPERS ----------\n",
        "def _norm_text(s: str) -> str:\n",
        "    s = (s or \"\").strip()\n",
        "    s = re.sub(r\"[\\u200b\\u2060]\", \"\", s)     # zero-width\n",
        "    s = re.sub(r\"\\s+\", \" \", s)\n",
        "    return s\n",
        "\n",
        "def _norm_phone(s: str) -> str:\n",
        "    s = (s or \"\").strip()\n",
        "    digits = re.sub(r\"\\D\", \"\", s)\n",
        "    if not digits:\n",
        "        return \"\"\n",
        "    if digits.startswith(\"8\"):\n",
        "        digits = \"7\" + digits[1:]\n",
        "    if digits.startswith(\"7\") and len(digits) == 11:\n",
        "        return f\"+7 ({digits[1:4]}) {digits[4:7]}-{digits[7:9]}-{digits[9:11]}\"\n",
        "    return s\n",
        "\n",
        "# ключевые слова\n",
        "AI_PAT  = re.compile(r\"(искусственн|ИИ\\b|AI\\b|artificial|интеллект|машинн|ML\\b)\", re.I)\n",
        "PM_PAT  = re.compile(r\"(управлени[ея]\\s*ИИ|ИИ[-\\s]?продукт|AI[-\\s]?product|product\\s+management|продакт|продуктовый менедж)\", re.I)\n",
        "URL_AI  = re.compile(r\"program/master/ai\\b\", re.I)\n",
        "URL_PM  = re.compile(r\"program/master/ai_product\\b\", re.I)\n",
        "\n",
        "# хорошие/плохие роли\n",
        "ROLE_GOOD = re.compile(r\"(менедж|координатор|куратор|руководител[ья]|администратор программ|program\\s*manager|coordinator)\", re.I)\n",
        "ROLE_BAD  = re.compile(r\"(при[её]мн|call[-\\s]?center|общий|горячая линия|help|поддержк|пресс|канцеляр|секретариат|media|smm)\", re.I)\n",
        "\n",
        "# сопоставление колонок CSV твоим названиям\n",
        "COLMAPS = {\n",
        "    \"name\":  [\"name\",\"fio\",\"ФИО\",\"title\",\"имя\"],\n",
        "    \"role\":  [\"role\",\"position\",\"должность\",\"роль\"],\n",
        "    \"email\": [\"email\",\"почта\",\"e-mail\",\"mail\"],\n",
        "    \"phone\": [\"phone\",\"телефон\",\"tel\",\"номер\"],\n",
        "    \"page\":  [\"page\",\"url\",\"ссылка\",\"link\",\"site\"],\n",
        "    \"program\":[\"program\",\"программа\",\"prog\"],\n",
        "}\n",
        "\n",
        "def _pick(row: dict, keys) -> str:\n",
        "    for k in keys:\n",
        "        if k in row and str(row[k]).strip():\n",
        "            return str(row[k])\n",
        "    return \"\"\n",
        "\n",
        "def _load_raw_csv():\n",
        "    src = None\n",
        "    for p in RAW_CANDIDATES:\n",
        "        if p.exists():\n",
        "            src = p\n",
        "            break\n",
        "    if not src:\n",
        "        raise SystemExit(\"contacts.csv не найден\")\n",
        "    # читаем надёжно, даже если порядок/названия столбцов странные\n",
        "    with src.open(\"r\", encoding=\"utf-8\") as f:\n",
        "        reader = csv.DictReader(f)\n",
        "        rows = [ {k.strip(): (v or \"\").strip() for k,v in r.items()} for r in reader ]\n",
        "    print(f\"[OK] raw contacts loaded: {len(rows)} rows from {src}\")\n",
        "    return rows\n",
        "\n",
        "def guess_program(blob: str, url: str) -> str:\n",
        "    if URL_AI.search(url): return \"ai\"\n",
        "    if URL_PM.search(url): return \"ai_product\"\n",
        "    ai = bool(AI_PAT.search(blob))\n",
        "    pm = bool(PM_PAT.search(blob))\n",
        "    if ai and not pm: return \"ai\"\n",
        "    if pm and not ai: return \"ai_product\"\n",
        "    return \"generic\"\n",
        "\n",
        "def is_managerish(role: str) -> bool:\n",
        "    return bool(ROLE_GOOD.search(role or \"\") or \"manager\" in (role or \"\").lower())\n",
        "\n",
        "def score_contact(rec: dict) -> int:\n",
        "    score = 0\n",
        "    role = rec.get(\"role\",\"\")\n",
        "    email = (rec.get(\"email\") or \"\").lower()\n",
        "    url   = (rec.get(\"page\") or \"\").lower()\n",
        "    prog  = rec.get(\"program\") or \"generic\"\n",
        "\n",
        "    if ROLE_GOOD.search(role): score += 3\n",
        "    if \"itmo.ru\" in email: score += 1\n",
        "    if rec.get(\"phone\"): score += 1\n",
        "    if ROLE_BAD.search(role): score -= 2\n",
        "    if prog == \"ai\" and URL_AI.search(url): score += 3\n",
        "    if prog == \"ai_product\" and URL_PM.search(url): score += 3\n",
        "    if prog == \"generic\": score -= 1\n",
        "    return score\n",
        "\n",
        "# ---------- ЧТЕНИЕ И НОРМАЛИЗАЦИЯ ----------\n",
        "raw_rows = _load_raw_csv()\n",
        "norm_rows = []\n",
        "for row in raw_rows:\n",
        "    r = {k: _pick(row, ks) for k, ks in COLMAPS.items()}\n",
        "    r = {k: _norm_text(v) for k, v in r.items()}\n",
        "    r[\"phone\"] = _norm_phone(r[\"phone\"])\n",
        "    blob = \" \".join(r.values())\n",
        "    r[\"program\"] = r.get(\"program\") or guess_program(blob, r.get(\"page\",\"\"))\n",
        "    # выкидываем явно мусорные записи (ни почты, ни телефона)\n",
        "    if not r.get(\"email\") and not r.get(\"phone\"):\n",
        "        continue\n",
        "    # фильтруем пресс-службы/общие линии\n",
        "    if ROLE_BAD.search(r.get(\"role\",\"\")):\n",
        "        continue\n",
        "    norm_rows.append(r)\n",
        "\n",
        "# ---------- ДЕДУП ПО email/phone/name+role С ВЫБОРОМ ЛУЧШЕГО СКОРА ----------\n",
        "bykey = {}\n",
        "for r in norm_rows:\n",
        "    key = (r.get(\"email\",\"\").lower(), r.get(\"phone\",\"\"), r.get(\"name\",\"\").lower(), r.get(\"role\",\"\").lower())\n",
        "    s = score_contact(r)\n",
        "    old = bykey.get(key)\n",
        "    if (not old) or (s > old[\"score\"]):\n",
        "        r[\"score\"] = s\n",
        "        bykey[key] = r\n",
        "clean = list(bykey.values())\n",
        "\n",
        "# ---------- РАЗБИВКА ПО ПРОГРАММАМ И TOP-K ----------\n",
        "def topk(pool, k):\n",
        "    if not pool: return []\n",
        "    pool = sorted(pool, key=lambda x: x.get(\"score\",0), reverse=True)\n",
        "    if KEEP_ONLY_MANAGERISH:\n",
        "        mgr = [r for r in pool if is_managerish(r.get(\"role\",\"\"))]\n",
        "        if len(mgr) >= k:\n",
        "            return mgr[:k]\n",
        "        need = k - len(mgr)\n",
        "        rest = [r for r in pool if r not in mgr]\n",
        "        return mgr + rest[:need]\n",
        "    return pool[:k]\n",
        "\n",
        "ai_pool      = [r for r in clean if r[\"program\"] == \"ai\"]\n",
        "pm_pool      = [r for r in clean if r[\"program\"] == \"ai_product\"]\n",
        "generic_pool = [r for r in clean if r[\"program\"] == \"generic\"]\n",
        "\n",
        "final_list = topk(ai_pool, TOP_K_PER_PROGRAM) + topk(pm_pool, TOP_K_PER_PROGRAM)\n",
        "if len(final_list) < TOP_K_PER_PROGRAM:  # добираем generic если пусто\n",
        "    need = TOP_K_PER_PROGRAM - len(final_list)\n",
        "    final_list += topk(generic_pool, need)\n",
        "\n",
        "# ---------- РУЧНЫЕ ФИКСЫ (опционально) ----------\n",
        "MANUAL_OVERRIDES = [\n",
        "      {\n",
        "       \"name\": \"Елизавета Василенко\",\n",
        "       \"role\": \"Менеджер программы\",\n",
        "       \"email\": \"aitalents@itmo.ru\",\n",
        "       \"phone\": \"+7 (993) 639-86-77\",\n",
        "       \"page\": \"https://abit.itmo.ru/program/master/ai\",\n",
        "       \"program\": \"ai\"\n",
        "     },\n",
        "      {\n",
        "       \"name\": \"Регина Ильдаровна Абдрашитова\",\n",
        "       \"role\": \"Менеджер программы\",\n",
        "       \"email\": \"aiproduct@itmo.ru\",\n",
        "       \"phone\": \"+7 (999) 526-79-88\",\n",
        "       \"page\": \"https://abit.itmo.ru/program/master/ai_product\",\n",
        "       \"program\": \"ai_product\"\n",
        "      },\n",
        "]\n",
        "# применяем ручные фиксы (замещают по email, если совпадение найдено)\n",
        "email_index = { (r.get(\"email\") or \"\").lower() for r in final_list }\n",
        "for r in MANUAL_OVERRIDES:\n",
        "    e = (r.get(\"email\") or \"\").lower()\n",
        "    r = {**r}  # копия\n",
        "    r[\"name\"]  = _norm_text(r.get(\"name\",\"\"))\n",
        "    r[\"role\"]  = _norm_text(r.get(\"role\",\"\"))\n",
        "    r[\"phone\"] = _norm_phone(r.get(\"phone\",\"\"))\n",
        "    r[\"page\"]  = _norm_text(r.get(\"page\",\"\"))\n",
        "    r[\"program\"] = (r.get(\"program\") or \"generic\").strip()\n",
        "    if e and e in email_index:\n",
        "        final_list = [r if (x.get(\"email\",\"\").lower()==e) else x for x in final_list]\n",
        "    else:\n",
        "        final_list.append(r)\n",
        "\n",
        "# ---------- SAVE ----------\n",
        "# Бэкап всего нормализованного набора (для ревью)\n",
        "BACKUP_JSON.write_text(json.dumps(clean, ensure_ascii=False, indent=2), encoding=\"utf-8\")\n",
        "# Итог, который читает бот\n",
        "OUT_JSON.write_text(json.dumps(final_list, ensure_ascii=False, indent=2), encoding=\"utf-8\")\n",
        "\n",
        "# ---------- LOG ----------\n",
        "print(f\"[OK] normalized: {len(norm_rows)} → dedup: {len(clean)} → final: {len(final_list)}\")\n",
        "for r in final_list:\n",
        "    print(\" -\", (r.get(\"program\") or \"?\"), \"|\", r.get(\"name\",\"?\"), \"|\", r.get(\"role\",\"?\"),\n",
        "          \"|\", r.get(\"email\",\"\"), \"|\", r.get(\"phone\",\"\"))\n",
        "\n",
        "print(\"\\nSaved for bot  →\", OUT_JSON)\n",
        "print(\"Backup (all normalized) →\", BACKUP_JSON)\n"
      ],
      "metadata": {
        "id": "OZcN8IuU1STD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ===== ITMO RAG bot — full single cell (tokens already in ENV) =====\n",
        "!pip -q install langchain langchain-community langchain-huggingface faiss-cpu python-telegram-bot requests nest_asyncio\n",
        "\n",
        "import os, re, json, time, warnings, requests, nest_asyncio, asyncio, urllib3\n",
        "from pathlib import Path\n",
        "from typing import Optional, List, Dict\n",
        "\n",
        "from langchain_community.vectorstores import FAISS\n",
        "from langchain_huggingface import HuggingFaceEmbeddings\n",
        "from langchain.llms.base import LLM\n",
        "\n",
        "from telegram import Update\n",
        "from telegram.ext import ApplicationBuilder, ContextTypes, CommandHandler, MessageHandler, filters\n",
        "\n",
        "# ---- quiet noisy libs\n",
        "urllib3.disable_warnings(urllib3.exceptions.InsecureRequestWarning)\n",
        "warnings.filterwarnings(\"ignore\", category=UserWarning, module=\"huggingface_hub.utils._auth\")\n",
        "os.environ[\"HF_HUB_DISABLE_TELEMETRY\"] = \"1\"\n",
        "\n",
        "# ---- tokens from ENV\n",
        "TG_TOKEN   = os.environ[\"TELEGRAM_BOT_TOKEN\"].strip()\n",
        "AUTH_BASIC = os.environ[\"GIGA_AUTH_BASIC\"].strip()\n",
        "assert TG_TOKEN and AUTH_BASIC.startswith(\"Basic \"), \"ENV tokens missing\"\n",
        "\n",
        "# ---- FAISS indexes (built earlier)\n",
        "def _cache_ok(p: Path) -> bool:\n",
        "    return (p / \"index.pkl\").exists() and (p / \"index.faiss\").exists()\n",
        "\n",
        "CACHE_DIR = Path(\"index_cache\")\n",
        "if not (_cache_ok(CACHE_DIR / \"faiss_file_only\") and _cache_ok(CACHE_DIR / \"faiss_all\")):\n",
        "    alt = Path(\"/content/drive/MyDrive/MyDrive_ITMO/BOT/index_cache\")\n",
        "    if _cache_ok(alt / \"faiss_file_only\") and _cache_ok(alt / \"faiss_all\"):\n",
        "        CACHE_DIR = alt\n",
        "    else:\n",
        "        raise SystemExit(\"FAISS cache not found. Build indexes first.\")\n",
        "\n",
        "IDX_FILE_ONLY = CACHE_DIR / \"faiss_file_only\"\n",
        "IDX_ALL       = CACHE_DIR / \"faiss_all\"\n",
        "\n",
        "# ---- embeddings (same as for build)\n",
        "try:\n",
        "    import torch\n",
        "    device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "except Exception:\n",
        "    device = \"cpu\"\n",
        "\n",
        "emb = HuggingFaceEmbeddings(\n",
        "    model_name=\"sentence-transformers/all-MiniLM-L6-v2\",\n",
        "    model_kwargs={\"device\": device},\n",
        ")\n",
        "\n",
        "# ---- load indexes\n",
        "vs_file = FAISS.load_local(str(IDX_FILE_ONLY), emb, allow_dangerous_deserialization=True)\n",
        "vs_all  = FAISS.load_local(str(IDX_ALL),       emb, allow_dangerous_deserialization=True)\n",
        "print(f\"[OK] indexes loaded from {CACHE_DIR.resolve()} | device={device}\")\n",
        "\n",
        "# =========================================================\n",
        "#                 Contacts: load contacts.json\n",
        "# =========================================================\n",
        "CONTACTS_PATHS = [\n",
        "    Path(\"/content/drive/MyDrive/MyDrive_ITMO/BOT/contacts.json\"),\n",
        "    Path(\"/mnt/data/contacts.json\"),\n",
        "    Path(\"contacts.json\"),\n",
        "]\n",
        "CONTACTS: List[Dict] = []\n",
        "for p in CONTACTS_PATHS:\n",
        "    if p.exists():\n",
        "        try:\n",
        "            CONTACTS = json.loads(p.read_text(encoding=\"utf-8\"))\n",
        "            print(f\"[OK] contacts loaded: {len(CONTACTS)} from {p}\")\n",
        "            break\n",
        "        except Exception as e:\n",
        "            print(\"[WARN] failed to load contacts:\", e)\n",
        "if not CONTACTS:\n",
        "    print(\"[WARN] contacts.json not found — контакты отвечать не смогу\")\n",
        "\n",
        "# ---- contact intent + routing\n",
        "RE_CONTACT_INTENT = re.compile(r\"(контакт|телефон|почт|email|e-mail|e mail|менедж|координатор|manager)\", re.I)\n",
        "RE_PROD = re.compile(r\"(управлени|продукт|продакт|ai[-\\s]?product|product\\s*management)\", re.I)\n",
        "RE_AI   = re.compile(r\"(искусствен|интеллект|нейросет|машинн|AI\\b|ML\\b)\", re.I)\n",
        "\n",
        "def detect_program(text: str) -> List[str]:\n",
        "    text = text or \"\"\n",
        "    prog = []\n",
        "    if RE_PROD.search(text): prog.append(\"ai_product\")\n",
        "    if RE_AI.search(text):   prog.append(\"ai\")\n",
        "    # если не смогли однозначно — покажем обе программы\n",
        "    return list(dict.fromkeys(prog)) or [\"ai\",\"ai_product\"]\n",
        "\n",
        "def try_contacts_answer(user_text: str) -> Optional[str]:\n",
        "    \"\"\"Если похоже на запрос контактов — вернуть готовый ответ (str), иначе None.\"\"\"\n",
        "    if not CONTACTS or not RE_CONTACT_INTENT.search(user_text or \"\"):\n",
        "        return None\n",
        "\n",
        "    progs = set(detect_program(user_text))\n",
        "    pool = [c for c in CONTACTS if (c.get(\"program\") in progs)]\n",
        "    if not pool:\n",
        "        pool = CONTACTS  # на всякий случай\n",
        "\n",
        "    # приоритизация менеджеров/координаторов и полноты данных\n",
        "    def _score(c):\n",
        "        role = c.get(\"role\") or \"\"\n",
        "        s = 0\n",
        "        if re.search(r\"(менедж|координатор|куратор|руководител|program\\s*manager|coordinat)\", role, re.I): s += 5\n",
        "        if c.get(\"phone\"): s += 2\n",
        "        if c.get(\"email\"): s += 1\n",
        "        if c.get(\"program\") in progs: s += 1\n",
        "        return -s\n",
        "\n",
        "    pool = sorted(pool, key=_score)[:6]\n",
        "    if not pool:\n",
        "        return \"Пока не вижу валидных контактов в справочнике. Убедись, что contacts.json сформирован и подхватывается.\"\n",
        "\n",
        "    head = \"Контакты по программе{}:\\n\".format(\n",
        "        \"м \" + \", \".join({\"ИИ‑продукт\" if p==\"ai_product\" else \"Искусственный интеллект\" for p in progs})\n",
        "    )\n",
        "    lines = []\n",
        "    for c in pool:\n",
        "        n  = c.get(\"name\")  or \"—\"\n",
        "        r  = c.get(\"role\")  or \"—\"\n",
        "        ph = c.get(\"phone\") or \"—\"\n",
        "        em = c.get(\"email\") or \"—\"\n",
        "        pg = \"ИИ‑продукт\" if c.get(\"program\")==\"ai_product\" else (\"Искусственный интеллект\" if c.get(\"program\")==\"ai\" else \"—\")\n",
        "        lines.append(f\"• [{pg}] {n} — {r}\\n   тел.: {ph} | email: {em}\")\n",
        "    return head + \"\\n\".join(lines)\n",
        "\n",
        "# =========================================================\n",
        "#                  GigaChat LLM wrapper\n",
        "# =========================================================\n",
        "_ACCESS_TOKEN, _TS = None, 0.0\n",
        "def get_access_token(force: bool = False) -> str:\n",
        "    \"\"\"OAuth with in-memory caching (30 min).\"\"\"\n",
        "    global _ACCESS_TOKEN, _TS\n",
        "    if _ACCESS_TOKEN and not force and time.time() - _TS < 1800:\n",
        "        return _ACCESS_TOKEN\n",
        "    r = requests.post(\n",
        "        \"https://ngw.devices.sberbank.ru:9443/api/v2/oauth\",\n",
        "        headers={\n",
        "            \"Authorization\": AUTH_BASIC,\n",
        "            \"Content-Type\": \"application/x-www-form-urlencoded\",\n",
        "            \"Accept\": \"application/json\",\n",
        "            \"RqUID\": \"00000000-0000-0000-0000-000000000001\",\n",
        "        },\n",
        "        data={\"scope\":\"GIGACHAT_API_PERS\"},\n",
        "        timeout=30, verify=False\n",
        "    )\n",
        "    if r.status_code != 200:\n",
        "        raise RuntimeError(f\"OAuth {r.status_code}: {r.text}\")\n",
        "    _ACCESS_TOKEN = r.json()[\"access_token\"]; _TS = time.time()\n",
        "    return _ACCESS_TOKEN\n",
        "\n",
        "class GigaChatLLM(LLM):\n",
        "    @property\n",
        "    def _llm_type(self): return \"gigachat\"\n",
        "    def _call(self, prompt: str, stop: Optional[List[str]] = None) -> str:\n",
        "        token = get_access_token()\n",
        "        headers = {\"Authorization\": f\"Bearer {token}\", \"Content-Type\": \"application/json\"}\n",
        "        payload = {\n",
        "            \"model\": \"GigaChat:latest\",\n",
        "            \"messages\": [{\"role\": \"user\", \"content\": prompt}],\n",
        "            \"temperature\": 0.40\n",
        "        }\n",
        "        r = requests.post(\"https://gigachat.devices.sberbank.ru/api/v1/chat/completions\",\n",
        "                          headers=headers, json=payload, timeout=60, verify=False)\n",
        "        if r.status_code != 200:\n",
        "            token = get_access_token(force=True)\n",
        "            headers[\"Authorization\"] = f\"Bearer {token}\"\n",
        "            r = requests.post(\"https://gigachat.devices.sberbank.ru/api/v1/chat/completions\",\n",
        "                              headers=headers, json=payload, timeout=60, verify=False)\n",
        "            if r.status_code != 200:\n",
        "                raise RuntimeError(f\"GigaChat {r.status_code}: {r.text}\")\n",
        "        data = r.json()\n",
        "        return data.get(\"choices\", [{}])[0].get(\"message\", {}).get(\"content\", \"\").strip()\n",
        "\n",
        "llm = GigaChatLLM()\n",
        "\n",
        "# =========================================================\n",
        "#                Memory: summary + packed history\n",
        "# =========================================================\n",
        "HISTORY_CHARS = 3500\n",
        "SUMMARY_EVERY = 6\n",
        "\n",
        "def pack_history(history: List[Dict], summary: Optional[str], limit: int = HISTORY_CHARS) -> str:\n",
        "    lines = []\n",
        "    if summary:\n",
        "        lines.append(\"[САММАРИ]\\n\" + summary.strip())\n",
        "    for m in history[-12:]:\n",
        "        role = \"Пользователь\" if m[\"role\"] == \"user\" else \"Ассистент\"\n",
        "        lines.append(f\"{role}: {m['content']}\")\n",
        "    text = \"\\n\".join(lines).strip()\n",
        "    if len(text) > limit:\n",
        "        text = text[-limit:]\n",
        "    return text\n",
        "\n",
        "def summarize_history(history: List[Dict], prev: Optional[str]) -> str:\n",
        "    chunk = \"\\n\".join([(\"П:\" if m[\"role\"]==\"user\" else \"А:\")+m[\"content\"] for m in history[-12:]]) or \"—\"\n",
        "    prompt = (\n",
        "        \"Сверни диалог в краткий конспект для консультанта по магистратурам ИТМО \"\n",
        "        \"(5–7 тезисов: критерии выбора, ответы, уточнения; без воды).\\n\\n\"\n",
        "        f\"[ПРЕДЫДУЩЕЕ САММАРИ]\\n{prev or '—'}\\n\\n[НОВОЕ]\\n{chunk}\\n\\n[ИТОГ]:\"\n",
        "    )\n",
        "    return (llm(prompt) or \"\").strip()\n",
        "\n",
        "# =========================================================\n",
        "#          Retrieval: MMR + backoff rephrase via LLM\n",
        "# =========================================================\n",
        "def retrieve_multi(queries: List[str], k: int = 12, fetch_k: int = 48, _backoff_done: bool = False):\n",
        "    \"\"\"MMR из обоих индексов + дедуп. При пустом результате — одна бэкофф‑перефраза.\"\"\"\n",
        "    def _mmr(store, q):\n",
        "        try:\n",
        "            retr = store.as_retriever(search_type=\"mmr\",\n",
        "                                      search_kwargs={\"k\": k, \"fetch_k\": fetch_k, \"lambda_mult\": 0.7})\n",
        "            return retr.get_relevant_documents(q)\n",
        "        except Exception:\n",
        "            return store.as_retriever(search_kwargs={\"k\": k}).get_relevant_documents(q)\n",
        "\n",
        "    queries = [q for q in (queries or []) if q]\n",
        "    seen, out = set(), []\n",
        "    for q in queries:\n",
        "        for store in (vs_file, vs_all):\n",
        "            for d in _mmr(store, q):\n",
        "                if d.page_content not in seen:\n",
        "                    seen.add(d.page_content); out.append(d)\n",
        "            if len(out) >= k: break\n",
        "        if len(out) >= k: break\n",
        "\n",
        "    if out or _backoff_done:\n",
        "        return out[:k]\n",
        "\n",
        "    # backoff: одна перефраза запросов\n",
        "    reform = (llm(\"Переформулируй поисковый запрос по официальным документам магистратур ИТМО из этого текста одной строкой: \"\n",
        "                  + \" / \".join(queries)) or \"\").strip()\n",
        "    if reform:\n",
        "        return retrieve_multi([reform], k=k, fetch_k=fetch_k, _backoff_done=True)[:k]\n",
        "    return []\n",
        "\n",
        "# =========================================================\n",
        "#        Planner: LLM строит queries для документов\n",
        "# =========================================================\n",
        "def _json_extract(s: str) -> dict:\n",
        "    m = re.search(r\"\\{.*\\}\", s, flags=re.S)\n",
        "    try: return json.loads(m.group(0)) if m else {}\n",
        "    except json.JSONDecodeError: return {}\n",
        "\n",
        "PLAN_PROMPT = \"\"\"\n",
        "Ты помогаешь консультировать по магистратурам ИТМО: «Искусственный интеллект» и «Управление ИИ-продуктом».\n",
        "Тебе дан текст пользователя и краткая история диалога.\n",
        "\n",
        "Задача:\n",
        "1) Определи, можно ли связать вопрос с этими програмами и их документами: related = true|false.\n",
        "2) Если related=true — придумай 3–6 поисковых формулировок (по-русски, терминология учебных планов, дисциплин,\n",
        "  проектов, итоговой аттестации, поступления).\n",
        "3) Если related=false — queries=[].\n",
        "\n",
        "Верни СТРОГО JSON:\n",
        "{ \"related\": true, \"queries\": [\"...\",\"...\"] }\n",
        "\"\"\"\n",
        "\n",
        "def build_plan(user_text: str, history: List[Dict]) -> dict:\n",
        "    hist = \"\\n\".join([(\"П\" if m[\"role\"]==\"user\" else \"А\")+\": \"+m[\"content\"] for m in history[-6:]]) or \"—\"\n",
        "    prompt = PLAN_PROMPT + f\"\\n[ИСТОРИЯ]\\n{hist}\\n[ПОЛЬЗОВАТЕЛЬ]\\n{user_text}\\nJSON:\"\n",
        "    raw = (llm(prompt) or \"\").strip()\n",
        "    data = _json_extract(raw) or {}\n",
        "    related = bool(data.get(\"related\", True))\n",
        "    queries = [q.strip() for q in (data.get(\"queries\") or []) if q and q.strip()]\n",
        "    return {\"related\": related, \"queries\": queries}\n",
        "\n",
        "# =========================================================\n",
        "#             Evidence pack + light fact guard\n",
        "# =========================================================\n",
        "IMPORTANT_KWS = [\"онлайн\", \"очно\", \"очно-заочно\", \"дистанц\", \"стоимость\", \"цена\", \"язык\", \"англ\", \"русск\", \"семестр\",\n",
        "                 \"ECTS\", \"з.е.\", \"зачётн\", \"срок\", \"год\", \"2 года\", \"4 семестр\", \"очная\"]\n",
        "\n",
        "def evidence_pack(docs, n=3):\n",
        "    snips = []\n",
        "    seen = set()\n",
        "    for d in docs:\n",
        "        t = (d.page_content or \"\").strip()\n",
        "        if 50 <= len(t) <= 220 and t not in seen:\n",
        "            seen.add(t)\n",
        "            src = d.metadata.get(\"src\",\"?\")\n",
        "            prog = d.metadata.get(\"program\",\"?\")\n",
        "            snips.append(f\"• [{prog} / {src}] {t}\")\n",
        "            if len(snips) >= n:\n",
        "                break\n",
        "    return \"\\n\".join(snips)\n",
        "\n",
        "def fact_guard(answer: str, context_text: str) -> List[str]:\n",
        "    miss = []\n",
        "    ans_l = (answer or \"\").lower()\n",
        "    ctx_l = (context_text or \"\").lower()\n",
        "    for kw in IMPORTANT_KWS:\n",
        "        if kw in ans_l and kw not in ctx_l:\n",
        "            miss.append(kw)\n",
        "    return miss\n",
        "\n",
        "# =========================================================\n",
        "#                     Answer generator\n",
        "# =========================================================\n",
        "def answer_always(user_text: str, history: List[Dict], summary: Optional[str], mode: str = \"brief\", show_evidence: bool = False) -> str:\n",
        "    user_text = (user_text or \"\").strip()\n",
        "    plan = build_plan(user_text, history)\n",
        "    queries = (plan[\"queries\"] or []) + [user_text]\n",
        "    docs = retrieve_multi(queries, k=12)\n",
        "\n",
        "    hist_block = pack_history(history, summary, HISTORY_CHARS)\n",
        "\n",
        "    if docs:\n",
        "        context = \"\\n\\n---\\n\\n\".join(d.page_content for d in docs)\n",
        "        style = \"Коротко (2–4 предложения)\" if mode == \"brief\" else \"Чуть подробнее (4–7 предложений)\"\n",
        "        prompt = (\n",
        "            \"Ты консультант по двум магистратурам ИТМО: «Искусственный интеллект» и «Управление ИИ‑продуктом».\\n\"\n",
        "            f\"Говори живо. {style}. Факты бери ТОЛЬКО из [КОНТЕКСТ].\\n\"\n",
        "            \"Если чего-то нет в контексте — честно скажи и предложи, как сузить вопрос.\\n\\n\"\n",
        "            f\"[ИСТОРИЯ]\\n{hist_block or '—'}\\n\\n\"\n",
        "            f\"[КОНТЕКСТ]\\n{context}\\n\\n\"\n",
        "            f\"[ВОПРОС]\\n{user_text}\\n\\n\"\n",
        "            \"Ответ:\"\n",
        "        )\n",
        "        out = (llm(prompt) or \"\").strip() or \"В документах такой информации нет.\"\n",
        "\n",
        "        miss = fact_guard(out, context)\n",
        "        if miss:\n",
        "            out += \"\\n\\n⚠️ По этим пунктам в найденных документах нет прямого упоминания: \" + \", \".join(sorted(set(miss))) + \".\"\n",
        "            out += \" Уточни формулировку (дисциплины, формат, сроки, язык, стоимость) — проверю ещё раз.\"\n",
        "\n",
        "        if show_evidence:\n",
        "            out += \"\\n\\n🔎 Основано на:\\n\" + (evidence_pack(docs, n=4) or \"—\")\n",
        "        return out\n",
        "\n",
        "    if plan[\"related\"]:\n",
        "        return (\"Похоже, прямого совпадения в документах нет по такой формулировке. \"\n",
        "                \"Сузь запрос до дисциплин, учебного плана, проектной/итоговой аттестации, поступления или различий программ — я проверю.\")\n",
        "    else:\n",
        "        return (\"Здесь консультирую только по магистратурам ИТМО «Искусственный интеллект» и «Управление ИИ‑продуктом». \"\n",
        "                \"Спроси про дисциплины, учебный план, проекты/защиту, поступление или различия программ — отвечу по документам.\")\n",
        "\n",
        "# =========================================================\n",
        "#                   Telegram handlers\n",
        "# =========================================================\n",
        "nest_asyncio.apply()\n",
        "\n",
        "async def start(update: Update, context: ContextTypes.DEFAULT_TYPE):\n",
        "    context.user_data[\"history\"] = []\n",
        "    context.user_data[\"summary\"] = None\n",
        "    context.user_data[\"mode\"] = \"brief\"\n",
        "    context.user_data[\"evidence\"] = False\n",
        "    await update.message.reply_text(\n",
        "        \"Привет! Я консультирую по магистратурам ИТМО: «Искусственный интеллект» и «Управление ИИ‑продуктом».\\n\"\n",
        "        \"Задавай вопросы: дисциплины, учебный план, проекты, поступление, отличия.\\n\"\n",
        "        \"Команды: /evidence — цитаты из документов, /brief /detailed, /reset, /help.\"\n",
        "    )\n",
        "\n",
        "async def on_msg(update: Update, context: ContextTypes.DEFAULT_TYPE):\n",
        "    text = (update.message.text or \"\").strip()\n",
        "    history = context.user_data.setdefault(\"history\", [])\n",
        "    summary = context.user_data.get(\"summary\")\n",
        "    mode = context.user_data.get(\"mode\", \"brief\")\n",
        "    show_evidence = bool(context.user_data.get(\"evidence\", False))\n",
        "\n",
        "    # ---- быстрый маршрут по contacts.json\n",
        "    contact_reply = try_contacts_answer(text)\n",
        "    if contact_reply:\n",
        "        history += [{\"role\":\"user\",\"content\":text},{\"role\":\"assistant\",\"content\":contact_reply}]\n",
        "        context.user_data[\"history\"] = history\n",
        "        await update.message.reply_text(contact_reply)\n",
        "        # делаем саммари по расписанию\n",
        "        if len(history) // 2 % SUMMARY_EVERY == 0 and len(history) >= 2*SUMMARY_EVERY:\n",
        "            context.user_data[\"summary\"] = summarize_history(history, summary)\n",
        "        return\n",
        "\n",
        "    # ---- обычный RAG‑ответ\n",
        "    reply = answer_always(text, history, summary, mode=mode, show_evidence=show_evidence)\n",
        "    history += [{\"role\":\"user\",\"content\":text},{\"role\":\"assistant\",\"content\":reply}]\n",
        "    context.user_data[\"history\"] = history\n",
        "    await update.message.reply_text(reply)\n",
        "\n",
        "    if len(history) // 2 % SUMMARY_EVERY == 0 and len(history) >= 2*SUMMARY_EVERY:\n",
        "        context.user_data[\"summary\"] = summarize_history(history, summary)\n",
        "\n",
        "async def cmd_evidence(update: Update, context: ContextTypes.DEFAULT_TYPE):\n",
        "    context.user_data[\"evidence\"] = not context.user_data.get(\"evidence\", False)\n",
        "    await update.message.reply_text(\"Evidence: \" + (\"ON\" if context.user_data[\"evidence\"] else \"OFF\"))\n",
        "\n",
        "async def cmd_brief(update: Update, context: ContextTypes.DEFAULT_TYPE):\n",
        "    context.user_data[\"mode\"] = \"brief\"\n",
        "    await update.message.reply_text(\"Режим: кратко.\")\n",
        "\n",
        "async def cmd_detailed(update: Update, context: ContextTypes.DEFAULT_TYPE):\n",
        "    context.user_data[\"mode\"] = \"detailed\"\n",
        "    await update.message.reply_text(\"Режим: подробнее.\")\n",
        "\n",
        "async def cmd_reset(update: Update, context: ContextTypes.DEFAULT_TYPE):\n",
        "    context.user_data[\"history\"] = []\n",
        "    context.user_data[\"summary\"] = None\n",
        "    await update.message.reply_text(\"История очищена.\")\n",
        "\n",
        "async def cmd_help(update: Update, context: ContextTypes.DEFAULT_TYPE):\n",
        "    await update.message.reply_text(\n",
        "        \"/evidence — вкл/выкл цитаты из документов\\n\"\n",
        "        \"/brief — короткие ответы\\n\"\n",
        "        \"/detailed — ответы подробнее\\n\"\n",
        "        \"/reset — очистить историю\\n\"\n",
        "        \"/help — помощь\"\n",
        "    )\n",
        "\n",
        "async def error_handler(update: object, context: ContextTypes.DEFAULT_TYPE) -> None:\n",
        "    print(\"Handler error:\", repr(context.error))\n",
        "\n",
        "async def main():\n",
        "    app = ApplicationBuilder().token(TG_TOKEN).build()\n",
        "    app.add_handler(CommandHandler(\"start\", start))\n",
        "    app.add_handler(CommandHandler(\"evidence\", cmd_evidence))\n",
        "    app.add_handler(CommandHandler(\"brief\", cmd_brief))\n",
        "    app.add_handler(CommandHandler(\"detailed\", cmd_detailed))\n",
        "    app.add_handler(CommandHandler(\"reset\", cmd_reset))\n",
        "    app.add_handler(CommandHandler(\"help\", cmd_help))\n",
        "    app.add_handler(MessageHandler(filters.TEXT & ~filters.COMMAND, on_msg))\n",
        "    app.add_error_handler(error_handler)\n",
        "    print(\"Бот запущен. Ждём сообщения…\")\n",
        "    await app.run_polling()\n",
        "\n",
        "await main()\n"
      ],
      "metadata": {
        "id": "0M2UN13z3bfJ"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}
