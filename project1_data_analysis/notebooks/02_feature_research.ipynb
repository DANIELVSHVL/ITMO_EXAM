{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyPWis0WEhVjIlAMN4t1942Z"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["# Обработка данных"],"metadata":{"id":"vv5N9krHEzVj"}},{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive', force_remount=True)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"2NvSoq1wZjuS","executionInfo":{"status":"ok","timestamp":1754842427382,"user_tz":-180,"elapsed":19487,"user":{"displayName":"Daniel Levashvili","userId":"18067212155029720823"}},"outputId":"941117ad-f8ee-41a2-8f17-532195e695c8"},"execution_count":5,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}]},{"cell_type":"code","source":["# 0. Загрузка и подготовка\n","\n","from google.colab import drive\n","drive.mount('/content/drive', force_remount=True)\n","\n","import pandas as pd\n","import numpy as np\n","import pyarrow.dataset as ds\n","\n","# Пути к файлам\n","import glob\n","parquet_path = glob.glob(\"/content/drive/MyDrive/*/transaction_fraud_data.parquet\")[0]\n","fx_path = glob.glob(\"/content/drive/MyDrive/*/historical-currency-exchange.csv\")[0]\n","\n","# Чтение parquet\n","dataset = ds.dataset(parquet_path, format=\"parquet\")\n","\n","# Чтение CSV с курсами валют\n","fx = pd.read_csv(fx_path)\n","fx[\"date\"] = pd.to_datetime(fx[\"date\"], errors=\"coerce\").dt.date\n","fx_long = fx.melt(id_vars=\"date\", var_name=\"currency\", value_name=\"rate\").dropna(subset=[\"rate\"])\n","fx_long[\"currency\"] = fx_long[\"currency\"].str.upper()\n","fx_map = {(d, c): float(r) for d, c, r in fx_long.itertuples(index=False)}\n","\n","print(f\"Файл транзакций: {parquet_path}\")\n","print(f\"Файл курсов валют: {fx_path}\")\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ek_BLE_vZn4z","executionInfo":{"status":"ok","timestamp":1754842438744,"user_tz":-180,"elapsed":8023,"user":{"displayName":"Daniel Levashvili","userId":"18067212155029720823"}},"outputId":"8a410c8d-a736-497f-9f6a-7c04d871c8c8"},"execution_count":6,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n","Файл транзакций: /content/drive/MyDrive/ИТМО/transaction_fraud_data.parquet\n","Файл курсов валют: /content/drive/MyDrive/ИТМО/historical-currency-exchange.csv\n"]}]},{"cell_type":"code","source":["!pip install xlsxwriter"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Xp0MJZPGxdHf","executionInfo":{"status":"ok","timestamp":1754842671082,"user_tz":-180,"elapsed":6414,"user":{"displayName":"Daniel Levashvili","userId":"18067212155029720823"}},"outputId":"d16a8241-9057-4411-a937-c61cbbfab10e"},"execution_count":11,"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting xlsxwriter\n","  Downloading xlsxwriter-3.2.5-py3-none-any.whl.metadata (2.7 kB)\n","Downloading xlsxwriter-3.2.5-py3-none-any.whl (172 kB)\n","\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/172.3 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m172.3/172.3 kB\u001b[0m \u001b[31m5.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hInstalling collected packages: xlsxwriter\n","Successfully installed xlsxwriter-3.2.5\n"]}]},{"cell_type":"markdown","source":["# Формирование fraud_quick_audit_report.xlsx"],"metadata":{"id":"QwRtgkaiEU-Y"}},{"cell_type":"code","source":["import xlsxwriter\n","import os, json\n","from pathlib import Path\n","import numpy as np\n","import pandas as pd\n","import matplotlib.pyplot as plt\n","\n","# Путь для сохранения одного Excel-файла\n","OUT_XLSX = Path(\"/content/drive/MyDrive/ИТМО/fraud_quick_audit_report.xlsx\")\n","\n","def to_pandas_head(dataset, n):\n","    if hasattr(dataset, \"head\") and hasattr(dataset.head(1), \"to_pandas\"):\n","        return dataset.head(n).to_pandas()\n","    if isinstance(dataset, pd.DataFrame):\n","        return dataset.head(n).copy()\n","    raise TypeError(\"dataset не распознан\")\n","\n","def safe_nunique(s: pd.Series) -> int:\n","    return s.map(lambda x: json.dumps(x, sort_keys=True) if isinstance(x, (dict, list)) else x) \\\n","            .nunique(dropna=True)\n","\n","def parse_lha_val(x):\n","    if isinstance(x, dict):\n","        return x\n","    if pd.isna(x):\n","        return {}\n","    try:\n","        return json.loads(x)\n","    except Exception:\n","        return {}\n","\n","def ensure_datetime(s):\n","    return pd.to_datetime(s, errors=\"coerce\", utc=True)\n","\n","def run_combined_report(dataset):\n","    with pd.ExcelWriter(OUT_XLSX, engine=\"xlsxwriter\") as writer:\n","        # 1) Быстрый профиль\n","        df = to_pandas_head(dataset, 100_000)\n","        desc = df.describe(include=[np.number]).T\n","        desc.to_excel(writer, sheet_name=\"profile_numeric\")\n","\n","        na = df.isna().sum().sort_values(ascending=False).to_frame(name=\"na_count\")\n","        na[\"na_rate\"] = na[\"na_count\"] / len(df)\n","        na.to_excel(writer, sheet_name=\"profile_na\")\n","\n","        uniq = pd.Series({col: safe_nunique(df[col]) for col in df.columns}, name=\"nunique_safe\")\n","        uniq.sort_values(ascending=False).to_frame().to_excel(writer, sheet_name=\"profile_nunique\")\n","\n","        if \"last_hour_activity\" in df.columns:\n","            keys = [\"num_transactions\", \"total_amount\", \"unique_merchants\", \"unique_countries\", \"max_single_amount\"]\n","            lha = df[\"last_hour_activity\"].map(parse_lha_val)\n","            rows = []\n","            for k in keys:\n","                vals = pd.to_numeric(lha.map(lambda d: d.get(k, np.nan)), errors=\"coerce\")\n","                rows.append({\n","                    \"key\": k,\n","                    \"non_null\": int(vals.notna().sum()),\n","                    \"min\": float(vals.min()) if vals.notna().any() else np.nan,\n","                    \"mean\": float(vals.mean()) if vals.notna().any() else np.nan,\n","                    \"max\": float(vals.max()) if vals.notna().any() else np.nan,\n","                })\n","            pd.DataFrame(rows).to_excel(writer, sheet_name=\"profile_last_hour_activity\", index=False)\n","\n","        df.head(20).to_excel(writer, sheet_name=\"sample_head\", index=False)\n","\n","        # 2) Лифты\n","        df_big = to_pandas_head(dataset, 1_000_000)\n","        base = df_big[\"is_fraud\"].mean()\n","\n","        def lift_one(col):\n","            t = df_big.groupby(col)[\"is_fraud\"].agg(['mean','count']).rename(columns={'mean':'fraud_rate','count':'transactions'})\n","            t[\"lift\"] = t[\"fraud_rate\"] / base\n","            return t.sort_values(\"lift\", ascending=False)\n","\n","        for col in [\"vendor_category\", \"vendor_type\"]:\n","            if col in df_big.columns:\n","                lift_one(col).to_excel(writer, sheet_name=f\"lift_{col}\")\n","\n","        def lift_table(group_cols, min_n=300):\n","            t = (df_big.groupby(group_cols, dropna=False)[\"is_fraud\"]\n","                 .agg(['mean','count'])\n","                 .rename(columns={'mean':'fraud_rate','count':'transactions'})\n","                 .reset_index())\n","            t[\"lift\"] = t[\"fraud_rate\"] / base\n","            return t[t[\"transactions\"] >= min_n].sort_values(\"lift\", ascending=False)\n","\n","        combos = [\n","            ([\"channel\",\"device\"], 300, \"lift_channel_x_device\"),\n","            ([\"is_outside_home_country\",\"is_high_risk_vendor\"], 200, \"lift_outside_x_highrisk\"),\n","            ([\"country\"], 500, \"lift_country\"),\n","            ([\"country\",\"city\"], 400, \"lift_country_x_city\"),\n","        ]\n","        for cols, min_n, name in combos:\n","            if set(cols).issubset(df_big.columns):\n","                lift_table(cols, min_n).to_excel(writer, sheet_name=name, index=False)\n","\n","        # 3) Время\n","        if \"timestamp\" in df_big.columns:\n","            if not np.issubdtype(df_big[\"timestamp\"].dtype, np.datetime64):\n","                df_big[\"timestamp\"] = ensure_datetime(df_big[\"timestamp\"])\n","            df_big[\"day_of_week\"] = df_big[\"timestamp\"].dt.day_name()\n","            df_big[\"hour\"] = df_big[\"timestamp\"].dt.hour\n","            pivot = df_big.pivot_table(index=\"day_of_week\", columns=\"hour\",\n","                                       values=\"is_fraud\", aggfunc=\"mean\").fillna(0.0)\n","            days_order = [\"Monday\",\"Tuesday\",\"Wednesday\",\"Thursday\",\"Friday\",\"Saturday\",\"Sunday\"]\n","            pivot = pivot.reindex(days_order)\n","            pivot.to_excel(writer, sheet_name=\"fraud_rate_by_dow_hour\")\n","\n","        # 4) Кандидаты на фичи\n","        if \"timestamp\" in df.columns:\n","            df[\"timestamp\"] = ensure_datetime(df[\"timestamp\"])\n","        if set([\"country\",\"city\",\"vendor_type\",\"amount\"]).issubset(df.columns):\n","            med = df.groupby([\"country\",\"city\",\"vendor_type\"])[\"amount\"].median().rename(\"city_vendor_median\")\n","            df = df.merge(med, on=[\"country\",\"city\",\"vendor_type\"], how=\"left\")\n","            df[\"RelativeAmountCity\"] = df[\"amount\"] / df[\"city_vendor_median\"].replace(0, np.nan)\n","            q = df[\"RelativeAmountCity\"].quantile(0.995)\n","            df[\"RelativeAmountCity\"] = df[\"RelativeAmountCity\"].clip(upper=q)\n","\n","        if \"is_fraud\" in df.columns:\n","            df[\"hour\"] = df[\"timestamp\"].dt.hour\n","            hr = df.groupby(\"hour\")[\"is_fraud\"].mean().rename(\"HourRiskMap\")\n","            df = df.merge(hr, on=\"hour\", how=\"left\")\n","            df[\"HourRisk\"] = df[\"HourRiskMap\"]\n","\n","        if set([\"customer_id\",\"device_fingerprint\",\"timestamp\"]).issubset(df.columns):\n","            first_ts = df.groupby([\"customer_id\",\"device_fingerprint\"])[\"timestamp\"].transform(\"min\")\n","            df[\"DeviceFirstSeen\"] = (df[\"timestamp\"] == first_ts).astype(\"int8\")\n","\n","        if \"last_hour_activity\" in df.columns:\n","            lha = df[\"last_hour_activity\"].map(parse_lha_val)\n","            df[\"lha_num_tx\"] = pd.to_numeric(lha.map(lambda d: d.get(\"num_transactions\", np.nan)), errors=\"coerce\")\n","            df[\"lha_total_amount\"] = pd.to_numeric(lha.map(lambda d: d.get(\"total_amount\", np.nan)), errors=\"coerce\")\n","            z_tx = (df[\"lha_num_tx\"] - df[\"lha_num_tx\"].mean()) / (df[\"lha_num_tx\"].std(ddof=0) + 1e-9)\n","            z_amt = (np.log1p(df[\"lha_total_amount\"]) - np.log1p(df[\"lha_total_amount\"]).mean()) / (np.log1p(df[\"lha_total_amount\"]).std(ddof=0) + 1e-9)\n","            df[\"HyperActivityScore\"] = (z_tx + z_amt).clip(-5, 5)\n","\n","        cand = [c for c in [\"RelativeAmountCity\",\"HourRisk\",\"DeviceFirstSeen\",\"HyperActivityScore\"] if c in df.columns]\n","        if cand and \"is_fraud\" in df.columns:\n","            corr = df[cand].join(df[\"is_fraud\"].astype(int)).corr(method=\"spearman\").loc[cand, \"is_fraud\"] \\\n","                .sort_values(ascending=False).to_frame(\"spearman_vs_fraud\")\n","            corr.to_excel(writer, sheet_name=\"feature_candidates_spearman\")\n","            df[cand].quantile([0.01,0.5,0.99]).to_excel(writer, sheet_name=\"feature_candidates_quantiles\")\n","            keep = [\"transaction_id\",\"is_fraud\"] + cand\n","            df[keep].to_excel(writer, sheet_name=\"feature_candidates\", index=False)\n","\n","    print(f\"Отчёт сохранён в: {OUT_XLSX}\")\n","\n","# ---- Запуск ----\n","run_combined_report(dataset)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"8ONwWnk0w-0r","executionInfo":{"status":"ok","timestamp":1754845487160,"user_tz":-180,"elapsed":43332,"user":{"displayName":"Daniel Levashvili","userId":"18067212155029720823"}},"outputId":"92aa9c2c-475f-437d-dfff-cef22e1c2f18"},"execution_count":13,"outputs":[{"output_type":"stream","name":"stdout","text":["Отчёт сохранён в: /content/drive/MyDrive/ИТМО/fraud_quick_audit_report.xlsx\n"]}]},{"cell_type":"markdown","source":["# Проверка 10 гипотез"],"metadata":{"id":"PPCR14Op42VN"}},{"cell_type":"code","source":["# === ГИПОТЕЗЫ: экономная загрузка + конвертация валют + проверка 10/10 ===\n","import os, json, math, gc\n","from pathlib import Path\n","import numpy as np\n","import pandas as pd\n","\n","# ---------- ПУТИ ----------\n","PARQUET_PATH = \"/content/drive/MyDrive/ИТМО/transaction_fraud_data.parquet\"   # ваш паркет\n","FX_CSV_PATH  = \"/content/drive/MyDrive/ИТМО/historical-currency-exchange.csv\" # CSV с курсами\n","OUT_DIR      = Path(\"/content/drive/MyDrive/ИТМО/audit_out\"); OUT_DIR.mkdir(parents=True, exist_ok=True)\n","\n","# ---------- КОНФИГ ПРАГМАТИКИ / ПОРОГОВ ----------\n","MIN_N       = 300       # минимальный надёжный объём сегмента\n","LIFT_THR    = 1.20      # «сильный» лифт\n","FR_THR      = 0.15      # «сильная» доля фрода (для фич, где считаем пороги)\n","ZSIGMA_HA   = 2.0       # порог для HyperActivityScore (z>2)\n","RELAMT_Q    = 0.95      # «высокая сумма» — квантиль по amount_usd\n","LHA_COUNTRY = 3         # «> N уникальных стран» за час\n","LHA_MERCH   = 5         # «> N уникальных мерчантов» за час\n","\n","# ---------- КОЛОНКИ, которые тянем из паркета (экономно) ----------\n","COLS = [\n","    \"transaction_id\",\"customer_id\",\"device_fingerprint\",\n","    \"timestamp\",\"is_fraud\",\n","    \"vendor_category\",\"vendor_type\",\n","    \"channel\",\"device\",\n","    \"country\",\"city\",\n","    \"is_outside_home_country\",\"is_high_risk_vendor\",\n","    \"amount\",\"currency\",\n","    \"last_hour_activity\"\n","]\n","\n","# ---------- УТИЛИТЫ ----------\n","def to_datetime_utc(s):\n","    s = pd.to_datetime(s, errors=\"coerce\", utc=True)\n","    return s\n","\n","def parse_lha(x):\n","    if isinstance(x, dict): return x\n","    if pd.isna(x): return {}\n","    try:\n","        return json.loads(x)\n","    except Exception:\n","        return {}\n","\n","def safe_rate_lookup(row, fx_wide):\n","    # row: has date_floor, currency; fx_wide has columns ['date','USD','EUR',...], USD=1\n","    # если валюты нет в fx или NaN — вернём NaN => amount_usd станет NaN (мы их отбросим в соответствующих гипотезах)\n","    try:\n","        return fx_wide.at[row[\"date_floor\"], row[\"currency\"]]\n","    except Exception:\n","        return np.nan\n","\n","def segment_lift(df, seg_mask, min_n=MIN_N):\n","    \"\"\"Лифт и показатели для булевого сегмента.\"\"\"\n","    n_all = df[\"is_fraud\"].notna().sum()\n","    base = df[\"is_fraud\"].mean() if n_all else np.nan\n","\n","    seg = df.loc[seg_mask]\n","    n = seg[\"is_fraud\"].notna().sum()\n","    fr = seg[\"is_fraud\"].mean() if n else np.nan\n","    lift = (fr / base) if (n and base and base>0) else np.nan\n","    return {\n","        \"n\": int(n),\n","        \"fraud_rate\": float(fr) if pd.notna(fr) else np.nan,\n","        \"lift\": float(lift) if pd.notna(lift) else np.nan\n","    }\n","\n","def top_lift_by_group(df, cols, min_n=MIN_N, top_k=1):\n","    base = df[\"is_fraud\"].mean()\n","    g = (df.groupby(cols, dropna=False)[\"is_fraud\"]\n","           .agg(['mean','count'])\n","           .rename(columns={'mean':'fraud_rate','count':'n'})\n","           .reset_index())\n","    g = g[g[\"n\"]>=min_n]\n","    g[\"lift\"] = g[\"fraud_rate\"] / base\n","    g = g.sort_values(\"lift\", ascending=False)\n","    if g.empty:\n","        return np.nan, None\n","    row = g.iloc[0:top_k]\n","    return float(row[\"lift\"].iloc[0]), row\n","\n","def print_line(name, ok, metric, extra=\"\"):\n","    badge = \"✅\" if ok else \"⚠️\"\n","    print(f\"{badge} {name:35s} | passed={str(ok):5s} | metric={metric:<8.3f} {extra}\")\n","\n","# ---------- 1) ЗАГРУЗКА ДАННЫХ (экономно) ----------\n","try:\n","    df = pd.read_parquet(PARQUET_PATH, columns=COLS)\n","except MemoryError:\n","    # fallback: по частям через pyarrow.dataset (если совсем тесно по памяти)\n","    import pyarrow.dataset as ds\n","    dataset = ds.dataset(PARQUET_PATH, format=\"parquet\")\n","    batches = []\n","    for b in dataset.to_batches(columns=COLS, batch_size=200_000):\n","        batches.append(b.to_pandas())\n","    df = pd.concat(batches, ignore_index=True)\n","    del batches; gc.collect()\n","\n","# только строки с is_fraud в [0,1]\n","df = df[df[\"is_fraud\"].isin([0,1])].copy()\n","df[\"is_fraud\"] = df[\"is_fraud\"].astype(\"float32\")\n","\n","# ---------- 2) КОНВЕРТАЦИЯ ВАЛЮТ ----------\n","fx = pd.read_csv(FX_CSV_PATH)\n","# приводим к «широкому» виду: индекс date, колонки — коды валют, значения — курс (единиц валюты за 1 USD)\n","fx[\"date\"] = pd.to_datetime(fx[\"date\"], utc=True)\n","fx = fx.set_index(\"date\").sort_index()\n","df[\"timestamp\"] = to_datetime_utc(df[\"timestamp\"])\n","df[\"date_floor\"] = df[\"timestamp\"].dt.floor(\"D\")\n","\n","# убедимся, что у нас есть только нужные даты\n","fx_wide = fx.copy()\n","\n","# векторный маппинг курса\n","# подготовим возможные пропуски/редкие валюты\n","avail_curr = set(fx_wide.columns)\n","mask_known = df[\"currency\"].isin(avail_curr)\n","df[\"fx_rate\"] = np.nan\n","if mask_known.any():\n","    # построчный lookup (быстро на Cython не сделать — но этот участок обычно не узкое место)\n","    df.loc[mask_known, \"fx_rate\"] = df.loc[mask_known, [\"date_floor\",\"currency\"]].apply(\n","        lambda r: fx_wide.at[r[\"date_floor\"], r[\"currency\"]]\n","        if (r[\"date_floor\"] in fx_wide.index) and (r[\"currency\"] in fx_wide.columns)\n","        else np.nan, axis=1\n","    )\n","\n","# amount_usd: amount / rate (т.к. курсы «за 1 USD»)\n","df[\"amount_usd\"] = df[\"amount\"] / df[\"fx_rate\"]\n","# невалидные — в NaN\n","df.loc[~np.isfinite(df[\"amount_usd\"]), \"amount_usd\"] = np.nan\n","\n","# ---------- 3) БАЗОВЫЕ ВЫЧИСЛЕНИЯ ----------\n","base_fr = df[\"is_fraud\"].mean()\n","base_n  = len(df)\n","summary_rows = []\n","\n","# ===== Гипотеза 1: Лифты по vendor_category =====\n","ok1_lift, top1 = top_lift_by_group(df.dropna(subset=[\"vendor_category\"]), [\"vendor_category\"], MIN_N)\n","summary_rows.append([\"lift_vendor_category\", ok1_lift>=LIFT_THR if pd.notna(ok1_lift) else False, ok1_lift, int(top1[\"n\"].iloc[0]) if isinstance(top1, pd.DataFrame) else 0])\n","\n","# ===== Гипотеза 2: Лифты по vendor_type =====\n","ok2_lift, top2 = top_lift_by_group(df.dropna(subset=[\"vendor_type\"]), [\"vendor_type\"], MIN_N)\n","summary_rows.append([\"lift_vendor_type\", ok2_lift>=LIFT_THR if pd.notna(ok2_lift) else False, ok2_lift, int(top2[\"n\"].iloc[0]) if isinstance(top2, pd.DataFrame) else 0])\n","\n","# ===== Гипотеза 3: Канал × устройство =====\n","ok3_lift, top3 = top_lift_by_group(df.dropna(subset=[\"channel\",\"device\"]), [\"channel\",\"device\"], MIN_N)\n","summary_rows.append([\"lift_channel_x_device\", ok3_lift>=LIFT_THR if pd.notna(ok3_lift) else False, ok3_lift, int(top3[\"n\"].iloc[0]) if isinstance(top3, pd.DataFrame) else 0])\n","\n","# ===== Гипотеза 4: Гео страна =====\n","ok4_lift, top4 = top_lift_by_group(df.dropna(subset=[\"country\"]), [\"country\"], MIN_N)\n","summary_rows.append([\"lift_country\", ok4_lift>=LIFT_THR if pd.notna(ok4_lift) else False, ok4_lift, int(top4[\"n\"].iloc[0]) if isinstance(top4, pd.DataFrame) else 0])\n","\n","# ===== Гипотеза 5: Гео страна×город =====\n","ok5_lift, top5 = top_lift_by_group(df.dropna(subset=[\"country\",\"city\"]), [\"country\",\"city\"], MIN_N)\n","summary_rows.append([\"lift_country_x_city\", ok5_lift>=LIFT_THR if pd.notna(ok5_lift) else False, ok5_lift, int(top5[\"n\"].iloc[0]) if isinstance(top5, pd.DataFrame) else 0])\n","\n","# ===== Гипотеза 6: Outside_home × High_risk_vendor =====\n","ok6_lift, top6 = top_lift_by_group(df.dropna(subset=[\"is_outside_home_country\",\"is_high_risk_vendor\"]),\n","                                   [\"is_outside_home_country\",\"is_high_risk_vendor\"], MIN_N)\n","summary_rows.append([\"outside_home_x_highrisk\", ok6_lift>=LIFT_THR if pd.notna(ok6_lift) else False, ok6_lift, int(top6[\"n\"].iloc[0]) if isinstance(top6, pd.DataFrame) else 0])\n","\n","# ===== Гипотеза 7: Время — fraud rate по часу (берём максимальный час) =====\n","dft = df.dropna(subset=[\"timestamp\"]).copy()\n","dft[\"hour\"] = dft[\"timestamp\"].dt.hour\n","fr_by_hour = dft.groupby(\"hour\")[\"is_fraud\"].agg(['mean','count']).rename(columns={'mean':'fraud_rate','count':'n'})\n","fr_by_hour = fr_by_hour[fr_by_hour[\"n\"]>=MIN_N]\n","max_fr = fr_by_hour[\"fraud_rate\"].max() if not fr_by_hour.empty else np.nan\n","summary_rows.append([\"fraud_rate_by_hour\", (max_fr>=FR_THR) if pd.notna(max_fr) else False, max_fr, int(fr_by_hour[\"n\"].max()) if not fr_by_hour.empty else 0])\n","\n","# ===== Гипотеза 8: RelativeAmountCity (на USD) =====\n","rel_df = df.dropna(subset=[\"amount_usd\",\"country\",\"city\",\"vendor_type\"]).copy()\n","if not rel_df.empty:\n","    med = rel_df.groupby([\"country\",\"city\",\"vendor_type\"])[\"amount_usd\"].median().rename(\"city_vendor_median\")\n","    rel_df = rel_df.join(med, on=[\"country\",\"city\",\"vendor_type\"])\n","    rel_df[\"RelativeAmountCity\"] = rel_df[\"amount_usd\"] / rel_df[\"city_vendor_median\"].replace(0,np.nan)\n","    high_thr = rel_df[\"RelativeAmountCity\"].quantile(RELAMT_Q)\n","    seg = rel_df[\"RelativeAmountCity\"] >= high_thr\n","    m8 = segment_lift(rel_df, seg)\n","    ok8 = (m8[\"n\"]>=MIN_N) and ((m8[\"lift\"]>=LIFT_THR) or (m8[\"fraud_rate\"]>=FR_THR))\n","else:\n","    m8 = {\"n\":0,\"fraud_rate\":np.nan,\"lift\":np.nan}; ok8=False\n","summary_rows.append([\"relative_amount_city_high\", ok8, m8[\"lift\"], m8[\"n\"]])\n","\n","# ===== Гипотеза 9: DeviceFirstSeen × amount (high) =====\n","dfs_df = df.dropna(subset=[\"timestamp\",\"customer_id\",\"device_fingerprint\",\"amount_usd\"]).copy()\n","if not dfs_df.empty:\n","    first_ts = dfs_df.groupby([\"customer_id\",\"device_fingerprint\"])[\"timestamp\"].transform(\"min\")\n","    dfs_df[\"DeviceFirstSeen\"] = (dfs_df[\"timestamp\"]==first_ts)\n","    amt_thr = dfs_df[\"amount_usd\"].quantile(RELAMT_Q)\n","    seg = (dfs_df[\"DeviceFirstSeen\"]) & (dfs_df[\"amount_usd\"]>=amt_thr)\n","    m9 = segment_lift(dfs_df, seg)\n","    ok9 = (m9[\"n\"]>=MIN_N) and ((m9[\"lift\"]>=LIFT_THR) or (m9[\"fraud_rate\"]>=FR_THR))\n","else:\n","    m9 = {\"n\":0,\"fraud_rate\":np.nan,\"lift\":np.nan}; ok9=False\n","summary_rows.append([\"device_first_seen_x_amount\", ok9, m9[\"lift\"], m9[\"n\"]])\n","\n","# ===== Гипотеза 10: HyperActivityScore + last_hour_activity raw =====\n","lha_df = df.dropna(subset=[\"last_hour_activity\"]).copy()\n","if not lha_df.empty:\n","    lha = lha_df[\"last_hour_activity\"].map(parse_lha)\n","    lha_df[\"lha_num_tx\"] = pd.to_numeric(lha.map(lambda d: d.get(\"num_transactions\", np.nan)), errors=\"coerce\")\n","    lha_df[\"lha_total_amount\"] = pd.to_numeric(lha.map(lambda d: d.get(\"total_amount\", np.nan)), errors=\"coerce\")\n","    lha_df[\"lha_unique_merchants\"] = pd.to_numeric(lha.map(lambda d: d.get(\"unique_merchants\", np.nan)), errors=\"coerce\")\n","    lha_df[\"lha_unique_countries\"] = pd.to_numeric(lha.map(lambda d: d.get(\"unique_countries\", np.nan)), errors=\"coerce\")\n","\n","    z_tx  = (lha_df[\"lha_num_tx\"] - lha_df[\"lha_num_tx\"].mean()) / (lha_df[\"lha_num_tx\"].std(ddof=0) + 1e-9)\n","    z_amt = (np.log1p(lha_df[\"lha_total_amount\"]) - np.log1p(lha_df[\"lha_total_amount\"]).mean()) / (np.log1p(lha_df[\"lha_total_amount\"]).std(ddof=0) + 1e-9)\n","    lha_df[\"HyperActivityScore\"] = (z_tx + z_amt).clip(-5,5)\n","\n","    # 10a: HyperActivityScore > 2σ\n","    seg_a = lha_df[\"HyperActivityScore\"] > ZSIGMA_HA\n","    m10a = segment_lift(lha_df, seg_a)\n","    ok10a = (m10a[\"n\"]>=MIN_N) and ((m10a[\"lift\"]>=LIFT_THR) or (m10a[\"fraud_rate\"]>=FR_THR))\n","\n","    # 10b: raw-условие: много стран или много мерчантов за час\n","    seg_b = (lha_df[\"lha_unique_countries\"]>LHA_COUNTRY) | (lha_df[\"lha_unique_merchants\"]>LHA_MERCH)\n","    m10b = segment_lift(lha_df, seg_b)\n","    ok10b = (m10b[\"n\"]>=MIN_N) and ((m10b[\"lift\"]>=LIFT_THR) or (m10b[\"fraud_rate\"]>=FR_THR))\n","else:\n","    m10a={\"n\":0,\"fraud_rate\":np.nan,\"lift\":np.nan}; ok10a=False\n","    m10b={\"n\":0,\"fraud_rate\":np.nan,\"lift\":np.nan}; ok10b=False\n","\n","summary_rows.append([\"hyper_activity_score>2σ\", ok10a, m10a[\"lift\"], m10a[\"n\"]])\n","summary_rows.append([\"lha_raw_anomaly\",       ok10b, m10b[\"lift\"], m10b[\"n\"]])\n","\n","# ---------- 4) СВОДНЫЙ ОТЧЁТ ----------\n","summary = pd.DataFrame(summary_rows, columns=[\"Hypothesis\",\"Passed\",\"Metric_Lift_or_FR\",\"N\"])\n","summary.insert(1, \"Thresholds\", f\"LIFT_THR={LIFT_THR}; FR_THR={FR_THR}; MIN_N={MIN_N}\")\n","summary.to_csv(OUT_DIR/\"hypotheses_summary.csv\", index=False)\n","\n","print(f\"\\nВсего строк: {base_n:,}; базовая доля фрода: {base_fr:.4f}\")\n","print(\"—\"*88)\n","for _,r in summary.iterrows():\n","    print_line(r[\"Hypothesis\"], r[\"Passed\"], r[\"Metric_Lift_or_FR\"], extra=f\"| n={int(r['N'])}\")\n","\n","# Отдельно сохраняем топ-группы для ключевых гипотез (если пригодится для слайдов)\n","extras = {}\n","if isinstance(top3, pd.DataFrame): extras[\"top_channel_x_device.csv\"]      = top3\n","if isinstance(top4, pd.DataFrame): extras[\"top_country.csv\"]               = top4\n","if isinstance(top5, pd.DataFrame): extras[\"top_country_x_city.csv\"]        = top5\n","if isinstance(top6, pd.DataFrame): extras[\"top_outside_x_highrisk.csv\"]    = top6\n","\n","for name, tbl in extras.items():\n","    tbl.to_csv(OUT_DIR/name, index=False)\n","\n","print(\"\\n[saved]\", OUT_DIR/\"hypotheses_summary.csv\")\n","for k in extras: print(\"[saved]\", OUT_DIR/k)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"LO9L6eLk2S_K","executionInfo":{"status":"ok","timestamp":1754866231755,"user_tz":-180,"elapsed":417455,"user":{"displayName":"Daniel Levashvili","userId":"18067212155029720823"}},"outputId":"690656a9-df1a-4c67-c592-07b08dc07727"},"execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":["\n","Всего строк: 7,483,766; базовая доля фрода: 0.1997\n","————————————————————————————————————————————————————————————————————————————————————————\n","⚠️ lift_vendor_category                | passed=False | metric=1.003    | n=935790\n","⚠️ lift_vendor_type                    | passed=False | metric=1.007    | n=233977\n","✅ lift_channel_x_device               | passed=True  | metric=5.007    | n=217324\n","✅ lift_country                        | passed=True  | metric=1.904    | n=785704\n","✅ lift_country_x_city                 | passed=True  | metric=1.904    | n=785704\n","✅ outside_home_x_highrisk             | passed=True  | metric=2.843    | n=1806158\n","✅ fraud_rate_by_hour                  | passed=True  | metric=0.593    | n=456393\n","✅ relative_amount_city_high           | passed=True  | metric=2.677    | n=374189\n","✅ device_first_seen_x_amount          | passed=True  | metric=5.001    | n=233155\n","✅ hyper_activity_score>2σ             | passed=True  | metric=1.016    | n=970402\n","✅ lha_raw_anomaly                     | passed=True  | metric=1.003    | n=7307953\n","\n","[saved] /content/drive/MyDrive/ИТМО/audit_out/hypotheses_summary.csv\n","[saved] /content/drive/MyDrive/ИТМО/audit_out/top_channel_x_device.csv\n","[saved] /content/drive/MyDrive/ИТМО/audit_out/top_country.csv\n","[saved] /content/drive/MyDrive/ИТМО/audit_out/top_country_x_city.csv\n","[saved] /content/drive/MyDrive/ИТМО/audit_out/top_outside_x_highrisk.csv\n"]}]},{"cell_type":"code","source":["# ---------- БЛОК 1. ЗАГРУЗКА ----------\n","import pandas as pd, numpy as np, textwrap, math\n","import matplotlib.pyplot as plt\n","from pathlib import Path\n","\n","CSV_PATH = \"/content/drive/MyDrive/ИТМО/insights/top_signals_reliable.csv\"\n","OUT_DIR  = Path(\"/content/drive/MyDrive/ИТМО/insights/visuals_final\")\n","OUT_DIR.mkdir(parents=True, exist_ok=True)\n","\n","# Порогы\n","MIN_N   = 200     # минимальный объём, чтобы считать сигнал \"надёжным\"\n","LOW_N   = 1000    # пометка (low N) на графике\n","TOP_N   = 10\n","LIFT_THR= 1.2\n","FR_THR  = 0.15\n","SP_THR  = 0.30\n","\n","df = pd.read_csv(CSV_PATH)\n","df.columns = [c.strip() for c in df.columns]\n","\n","# Какие колонки не включать в подпись фичи\n","EXCLUDE = {\n","    \"lift\",\"fraud_rate\",\"spearman_vs_fraud\",\n","    \"transactions\",\"count\",\"metric\",\"sheet\",\"priority_mark\",\n","    \"mean_metric_all\",\"index\",\"Unnamed: 0\"\n","}\n","\n","def wrap(s, w=42):\n","    return textwrap.fill(str(s), width=w, break_long_words=False, replace_whitespace=False)\n","\n","def make_feature_label(row: pd.Series, width=42) -> str:\n","    parts = []\n","    for col, val in row.items():\n","        if col in EXCLUDE or pd.isna(val):\n","            continue\n","        sval = str(int(val)) if isinstance(val,(int,float)) and float(val).is_integer() else str(val)\n","        if sval == \"\" or sval.lower()==\"nan\":\n","            continue\n","        parts.append(f\"{col}={sval}\")\n","    txt = \" | \".join(parts) if parts else \"(misc)\"\n","    return wrap(txt, width)\n","\n","def is_priority(label: str) -> bool:\n","    s = label.lower()\n","    return any([\n","        (\"is_outside_home_country=1\" in s and \"is_high_risk_vendor=1\" in s),\n","        \"devicefirstseen\" in s,\n","        \"hyperactivityscore\" in s,\n","        \"relativeamountcity\" in s,\n","        (\"channel=\" in s and \"device=\" in s)\n","    ])\n","\n","# Служебные удобства\n","def pick_weight_col(frame: pd.DataFrame):\n","    return \"transactions\" if \"transactions\" in frame.columns else (\"count\" if \"count\" in frame.columns else None)\n","\n","print(\"Файл:\", CSV_PATH, \"| строк:\", len(df))\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"QvETMhYYXo-V","executionInfo":{"status":"ok","timestamp":1754862396307,"user_tz":-180,"elapsed":48,"user":{"displayName":"Daniel Levashvili","userId":"18067212155029720823"}},"outputId":"48bcb20b-fa5c-4e53-e105-56e62ca1d008"},"execution_count":40,"outputs":[{"output_type":"stream","name":"stdout","text":["Файл: /content/drive/MyDrive/ИТМО/insights/top_signals_reliable.csv | строк: 48\n"]}]},{"cell_type":"markdown","source":["# Визуализация лучших гипотез"],"metadata":{"id":"kPuqjma0FXvU"}},{"cell_type":"code","source":["# ---------- БЛОК 2 (V2). ПРЕЗЕНТАЦИОННЫЕ СЛАЙДЫ: ГЕО / ПОВЕДЕНИЕ / ТРАНЗАКЦИИ ----------\n","import numpy as np, pandas as pd, re, os\n","import matplotlib.pyplot as plt\n","from matplotlib.backends.backend_pdf import PdfPages\n","\n","# ВХОД: df = pd.read_csv(\"/content/drive/MyDrive/ИТМО/insights/top_signals_reliable.csv\")\n","# (или из Excel-пайплайна), плюс хелперы/константы из блока 1 уже определены.\n","\n","empty_notes = []\n","pdf_path = OUT_DIR / \"slides_final_v2.pdf\"\n","pdf = PdfPages(pdf_path)\n","\n","# ===== 1) ФИЛЬТР СИЛЬНЫХ СИГНАЛОВ =====\n","def strong_filter(frame: pd.DataFrame) -> pd.DataFrame:\n","    if frame.empty:\n","        return frame.copy()\n","    m = np.zeros(len(frame), dtype=bool)\n","    if \"lift\" in frame:               m |= frame[\"lift\"].fillna(0) >= LIFT_THR\n","    if \"fraud_rate\" in frame:         m |= frame[\"fraud_rate\"].fillna(0) >= FR_THR\n","    if \"spearman_vs_fraud\" in frame:  m |= frame[\"spearman_vs_fraud\"].abs().fillna(0) >= SP_THR\n","    w = pick_weight_col(frame)\n","    if w: m &= frame[w].fillna(0) >= MIN_N\n","    return frame[m].copy()\n","\n","strong = strong_filter(df)\n","if strong.empty:\n","    raise SystemExit(\"После фильтров сильных сигналов нет. Проверь пороги/путь к файлам.\")\n","\n","# Читаемые ярлыки + приоритеты\n","strong[\"feature\"]  = strong.apply(make_feature_label, axis=1)\n","strong[\"priority\"] = strong[\"feature\"].apply(is_priority)\n","weight_col = pick_weight_col(strong)\n","\n","# ===== 2) КЛАССИФИКАЦИЯ СИГНАЛОВ НА БЛОКИ =====\n","def classify_block(txt: str) -> str:\n","    s = txt.lower()\n","    if \"country=\" in s or \"city=\" in s:\n","        return \"geo\"\n","    if any(k in s for k in [\n","        \"device=\", \"devicefirstseen\", \"hyperactivityscore\", \"relativeamountcity\",\n","        \"last_hour_activity\", \"is_outside_home_country=\", \"is_weekend\", \"hourrisk\", \"hour=\"\n","    ]):\n","        return \"behavior\"\n","    if any(k in s for k in [\n","        \"vendor_category\", \"vendor_type\", \"channel=\", \"card_type\", \"is_card_present\"\n","    ]):\n","        return \"transaction\"\n","    return \"other\"\n","\n","strong[\"block\"] = strong[\"feature\"].map(classify_block)\n","\n","# ===== 3) УБОРКА ПОЧТИ-ДУБЛЕЙ (особенно для GEO) =====\n","def collapse_geo_duplicates(frame: pd.DataFrame) -> pd.DataFrame:\n","    \"\"\"\n","    Схлопывает пары вида:\n","    country=Russia   vs   country=Russia | city=Unknown City\n","    Оставляем более детальный или более сильный по метрике вариант.\n","    \"\"\"\n","    if frame.empty:\n","        return frame\n","\n","    f = frame.copy()\n","    f[\"country_key\"] = f[\"feature\"].str.extract(r\"(country=[^|]+)\")\n","    f[\"city_key\"]    = f[\"feature\"].str.extract(r\"(city=[^|]+)\")\n","\n","    # ключ «только страна», чтобы ловить смерть-дубликаты\n","    only_country = f[~f[\"country_key\"].isna() & f[\"city_key\"].isna()].copy()\n","    country_city = f[~f[\"country_key\"].isna() & ~f[\"city_key\"].isna()].copy()\n","\n","    # если есть country=XX и также country=XX|city=Unknown City — оставим тот, у кого метрика выше\n","    # Возьмём «главную» метрику — используем приоритет: lift > fraud_rate > |spearman|\n","    def main_metric_row(row):\n","        if \"lift\" in row and pd.notna(row[\"lift\"]): return (\"lift\", row[\"lift\"])\n","        if \"fraud_rate\" in row and pd.notna(row[\"fraud_rate\"]): return (\"fraud_rate\", row[\"fraud_rate\"])\n","        if \"spearman_vs_fraud\" in row and pd.notna(row[\"spearman_vs_fraud\"]): return (\"spearman\", abs(row[\"spearman_vs_fraud\"]))\n","        return (\"none\", -np.inf)\n","\n","    f[\"_metric_name\"], f[\"_metric_val\"] = zip(*f.apply(main_metric_row, axis=1))\n","\n","    # сгруппируем по country_key и выберем строку с max _metric_val (city-специфику оставим, если она сильнее)\n","    keep_idx = []\n","    for ck, grp in f.groupby(\"country_key\", dropna=True):\n","        # если одинаковые фичи — оставим одну\n","        grp = grp.sort_values(\"_metric_val\", ascending=False)\n","        keep_idx.append(grp.index[0])\n","\n","    # доберём строки без country_key (не гео или гео без пар)\n","    no_ck = f[f[\"country_key\"].isna()].index.tolist()\n","\n","    cleaned = f.loc[keep_idx + no_ck].drop(columns=[\"country_key\",\"city_key\",\"_metric_name\",\"_metric_val\"])\n","    return cleaned\n","\n","geo_df        = collapse_geo_duplicates(strong[strong[\"block\"] == \"geo\"])\n","behavior_df   = strong[strong[\"block\"] == \"behavior\"].copy()\n","transaction_df= strong[strong[\"block\"] == \"transaction\"].copy()\n","\n","# ===== 4) КОРОТКИЕ ИНСАЙТЫ ДЛЯ НАДПИСЕЙ У БАРОВ =====\n","def short_insight(label: str, metric: str, value: float) -> str:\n","    s = label.lower()\n","    if \"is_outside_home_country=1\" in s and \"is_high_risk_vendor=1\" in s:\n","        return \"вне дома + high‑risk\"\n","    if \"channel=\" in s and \"device=\" in s:\n","        return \"канал×устройство\"\n","    if \"devicefirstseen\" in s:\n","        return \"новое устройство\"\n","    if \"relativeamountcity\" in s:\n","        return \"откл. суммы\"\n","    if \"hyperactivityscore\" in s:\n","        return \"всплеск активности\"\n","    if \"is_card_present=0\" in s:\n","        return \"CNP‑риск\"\n","    if \"country=\" in s and \"city=\" in s:\n","        return \"гео‑кластер\"\n","    if \"country=\" in s:\n","        return \"гео‑риск (страна)\"\n","    if \"vendor_category\" in s or \"vendor_type\" in s:\n","        return \"категорийный риск\"\n","    return f\"{metric}={value:.3f}\"\n","\n","def build_note(value, n, priority_flag):\n","    note = f\"{value:.3f}\"\n","    if n is not None:\n","        note += f\" | n={int(n)}\"\n","        if int(n) < LOW_N: note += \" (low N)\"\n","    if priority_flag: note += \"  ★\"\n","    return note\n","\n","def footer_note(metric: str) -> str:\n","    return (\n","        \"Красный бар + ★ = приоритетная гипотеза.  \"\n","        \"Жёлтая обводка = ТОП‑3 по значению метрики.  \"\n","        f\"Ось X: {metric}.  Фильтр надёжности: N ≥ {MIN_N}.\"\n","    )\n","\n","def annotate_top3(ax, xvals, yvals, k=3):\n","    if len(xvals) == 0: return\n","    order_desc = np.argsort(-xvals)[:min(k, len(xvals))]\n","    for rank, idx in enumerate(order_desc, start=1):\n","        ax.annotate(\n","            f\"Топ‑{rank}\", xy=(xvals[idx], yvals[idx]),\n","            xytext=(xvals[idx]*1.02 if xvals[idx] > 0 else 0.02, yvals[idx]+0.22),\n","            arrowprops=dict(arrowstyle=\"->\", lw=1.2, color=\"#444\"),\n","            fontsize=10, color=\"#111\"\n","        )\n","\n","# ===== 5) УНИВЕРСАЛЬНЫЙ РИСОВАЛЬЩИК СЛАЙДОВ =====\n","plt.rcParams.update({\n","    \"axes.titlesize\": 18, \"axes.labelsize\": 12, \"xtick.labelsize\": 10, \"ytick.labelsize\": 10\n","})\n","\n","def plot_section(tbl: pd.DataFrame, title_prefix: str, metric: str, fname: str, top_n=TOP_N):\n","    if tbl.empty or metric not in tbl or not tbl[metric].notna().any():\n","        empty_notes.append(f\"{title_prefix} — {metric}: пусто → график не строим.\")\n","        return False\n","\n","    t = (tbl.dropna(subset=[metric])\n","           .sort_values(metric, ascending=False)\n","           .drop_duplicates(subset=[\"feature\"], keep=\"first\")\n","           .head(top_n)\n","           .copy())\n","    if t.empty:\n","        empty_notes.append(f\"{title_prefix} — {metric}: после фильтров пусто.\")\n","        return False\n","\n","    # данные\n","    y = np.arange(len(t))[::-1]\n","    x = t[metric].values[::-1]\n","    labels = t[\"feature\"].values[::-1]\n","    pr = t[\"priority\"].values[::-1]\n","    n_vals = t[weight_col].values[::-1] if weight_col else [None]*len(t)\n","    colors = np.where(pr, \"#d62728\", \"#1f77b4\")\n","\n","    # фигура\n","    h = max(5.0, 0.80*len(t))\n","    fig, ax = plt.subplots(figsize=(16, h))\n","    bars = ax.barh(y, x, color=colors, edgecolor=\"none\")\n","\n","    # топ‑3 — жёлтая обводка\n","    top3 = set(np.argsort(-x)[:min(3, len(x))])\n","    for i, bar in enumerate(bars):\n","        if i in top3:\n","            bar.set_edgecolor(\"#ffbf00\")\n","            bar.set_linewidth(2.4)\n","\n","    ax.set_yticks(y, labels, fontsize=10)\n","    ax.set_xlabel(metric)\n","    ax.set_title(f\"{title_prefix}: Top {metric}\")\n","\n","    xmax = float(np.nanmax(x)) if len(x) else 1.0\n","    ax.set_xlim(0, xmax*1.14 + 1e-6)\n","\n","    for yi, xi, nn, pflag, lab in zip(y, x, n_vals, pr, labels):\n","        note = build_note(xi, nn, pflag)\n","        insight = short_insight(lab, metric, xi)\n","        ax.text(xi, yi, \" \" + note + \"  —  \" + insight, va=\"center\", ha=\"left\", fontsize=10)\n","\n","    annotate_top3(ax, x, y, k=3)\n","    fig.text(0.01, 0.01, footer_note(metric), fontsize=9, ha=\"left\", va=\"bottom\", color=\"#333\")\n","\n","    fig.tight_layout(rect=[0, 0.04, 1, 1])\n","    out = OUT_DIR / fname\n","    fig.savefig(out, dpi=240)\n","    pdf.savefig(fig)\n","    plt.close(fig)\n","    print(\"[saved]\", out)\n","    return True\n","\n","# ===== 6) СБОРКА СЛАЙДОВ ПО БЛОКАМ =====\n","subtitle = f\"Источник: top_signals_reliable.csv • Топ-{TOP_N} • Фильтр N≥{MIN_N}\"\n","\n","built = 0\n","for metric in [\"lift\", \"fraud_rate\", \"spearman_vs_fraud\"]:\n","    built += plot_section(geo_df,        \"ГЕО (страна/город)\",        metric, f\"geo_top_{metric}.png\")\n","    built += plot_section(behavior_df,   \"ПОВЕДЕНИЕ (устройства/окна)\",metric, f\"behavior_top_{metric}.png\")\n","    built += plot_section(transaction_df,\"ТРАНЗАКЦИИ (канал/категории)\",metric, f\"transaction_top_{metric}.png\")\n","\n","# Комбинированный скор — общий «топ-10»\n","norm_cols, nd = [], strong.copy()\n","if \"lift\" in nd:\n","    v = nd[\"lift\"].clip(lower=0)\n","    nd[\"lift_norm\"] = (v - v.min())/(v.max()-v.min() + 1e-9); norm_cols.append(\"lift_norm\")\n","if \"fraud_rate\" in nd:\n","    v = nd[\"fraud_rate\"].clip(lower=0)\n","    nd[\"fraud_rate_norm\"] = (v - v.min())/(v.max()-v.min() + 1e-9); norm_cols.append(\"fraud_rate_norm\")\n","if \"spearman_vs_fraud\" in nd:\n","    v = nd[\"spearman_vs_fraud\"].abs()\n","    nd[\"spearman_norm\"] = (v - v.min())/(v.max()-v.min() + 1e-9); norm_cols.append(\"spearman_norm\")\n","\n","if norm_cols:\n","    nd[\"score\"] = nd[norm_cols].mean(axis=1)\n","    top = (nd.sort_values(\"score\", ascending=False)\n","             .drop_duplicates(subset=[\"feature\"])\n","             .head(TOP_N)\n","             .copy())\n","\n","    y = np.arange(len(top))[::-1]\n","    x = top[\"score\"].values[::-1]\n","    labels = top[\"feature\"].values[::-1]\n","    pr = top[\"priority\"].values[::-1]\n","    n_vals = top[weight_col].values[::-1] if weight_col else [None]*len(top)\n","    colors = np.where(pr, \"#d62728\", \"#1f77b4\")\n","\n","    h = max(5.0, 0.80*len(top))\n","    fig, ax = plt.subplots(figsize=(16, h))\n","    bars = ax.barh(y, x, color=colors, edgecolor=\"none\")\n","\n","    top3 = set(np.argsort(-x)[:min(3, len(x))])\n","    for i, bar in enumerate(bars):\n","        if i in top3:\n","            bar.set_edgecolor(\"#ffbf00\")\n","            bar.set_linewidth(2.4)\n","\n","    ax.set_yticks(y, labels, fontsize=10)\n","    ax.set_xlabel(\"Normalized Score (0–1)\")\n","    ax.set_title(\"СВОДНО: Top‑10 по комбинированному скору\")\n","\n","    xmax = float(np.nanmax(x)) if len(x) else 1.0\n","    ax.set_xlim(0, xmax*1.14 + 1e-6)\n","\n","    for yi, xi, nn, pflag, lab in zip(y, x, n_vals, pr, labels):\n","        note = build_note(xi, nn, pflag)\n","        insight = short_insight(lab, \"score\", xi)\n","        ax.text(xi, yi, \" \" + note + \"  —  \" + insight, va=\"center\", ha=\"left\", fontsize=10)\n","\n","    annotate_top3(ax, x, y, k=3)\n","    fig.text(0.01, 0.01, footer_note(\"score\"), fontsize=9, ha=\"left\", va=\"bottom\", color=\"#333\")\n","\n","    fig.tight_layout(rect=[0, 0.04, 1, 1])\n","    out = OUT_DIR / \"overall_top10_combined.png\"\n","    fig.savefig(out, dpi=240)\n","    pdf.savefig(fig)\n","    plt.close(fig)\n","    print(\"[saved]\", out)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"7cL9e-wgXxYv","executionInfo":{"status":"ok","timestamp":1754862406487,"user_tz":-180,"elapsed":5539,"user":{"displayName":"Daniel Levashvili","userId":"18067212155029720823"}},"outputId":"8e85a5c0-841f-4ca5-b06b-42db3eb84491"},"execution_count":41,"outputs":[{"output_type":"stream","name":"stdout","text":["[saved] /content/drive/MyDrive/ИТМО/insights/visuals_final/geo_top_lift.png\n","[saved] /content/drive/MyDrive/ИТМО/insights/visuals_final/behavior_top_lift.png\n","[saved] /content/drive/MyDrive/ИТМО/insights/visuals_final/transaction_top_lift.png\n","[saved] /content/drive/MyDrive/ИТМО/insights/visuals_final/geo_top_fraud_rate.png\n","[saved] /content/drive/MyDrive/ИТМО/insights/visuals_final/behavior_top_fraud_rate.png\n","[saved] /content/drive/MyDrive/ИТМО/insights/visuals_final/transaction_top_fraud_rate.png\n","[saved] /content/drive/MyDrive/ИТМО/insights/visuals_final/overall_top10_combined.png\n"]}]},{"cell_type":"code","source":["# Клонируем репо в /content/tmp_repo и смотрим структуру\n","GH_USER = \"DANIELVSHVL\"\n","GH_REPO = \"ITMO_EXAM\"\n","\n","!rm -rf /content/tmp_repo\n","!git clone https://github.com/{GH_USER}/{GH_REPO}.git /content/tmp_repo\n","!tree /content/tmp_repo\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"PB0iTrRVZtbw","executionInfo":{"status":"ok","timestamp":1754870507764,"user_tz":-180,"elapsed":1230,"user":{"displayName":"Daniel Levashvili","userId":"18067212155029720823"}},"outputId":"ff66c70e-6f93-4bfc-cb59-6faf771588e9"},"execution_count":5,"outputs":[{"output_type":"stream","name":"stdout","text":["Cloning into '/content/tmp_repo'...\n","remote: Enumerating objects: 18, done.\u001b[K\n","remote: Counting objects: 100% (18/18), done.\u001b[K\n","remote: Compressing objects: 100% (13/13), done.\u001b[K\n","remote: Total 18 (delta 1), reused 14 (delta 1), pack-reused 0 (from 0)\u001b[K\n","Receiving objects: 100% (18/18), 9.00 KiB | 9.00 MiB/s, done.\n","Resolving deltas: 100% (1/1), done.\n","/bin/bash: line 1: tree: command not found\n"]}]},{"cell_type":"code","source":["BRANCH = \"feature/data-analysis-answers\"\n","\n","!rm -rf /content/tmp_repo\n","!git clone -b {BRANCH} https://github.com/{GH_USER}/{GH_REPO}.git /content/tmp_repo\n","!tree /content/tmp_repo\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"XU6e54HkbuKa","executionInfo":{"status":"ok","timestamp":1754870521538,"user_tz":-180,"elapsed":516,"user":{"displayName":"Daniel Levashvili","userId":"18067212155029720823"}},"outputId":"566996fc-0542-457e-87fd-dc18114a1b16"},"execution_count":6,"outputs":[{"output_type":"stream","name":"stdout","text":["Cloning into '/content/tmp_repo'...\n","fatal: Remote branch feature/data-analysis-answers not found in upstream origin\n","/bin/bash: line 1: tree: command not found\n"]}]},{"cell_type":"code","source":["# ==== НАСТРОЙКИ ====\n","GH_USER  = \"DANIELVSHVL\"\n","GH_REPO  = \"ITMO_EXAM\"\n","BRANCH   = \"feature/data-analysis-research\"\n","\n","NB_EXPECTED_DIR   = \"/content/drive/MyDrive/Colab Notebooks\"\n","ITMO_DIR          = \"/content/drive/MyDrive/ITMO\"\n","VISUALS_SUBDIR    = \"insights/visuals_final\"\n","TOP_SIGNALS_NAME  = \"top_signals_reliable.csv\"\n","\n","USER_EMAIL = \"you@example.com\"   # замени\n","USER_NAME  = \"Your Name\"         # замени\n","\n","from getpass import getpass\n","GITHUB_TOKEN = getpass(\"Введите GitHub Personal Access Token: \")\n","\n","# ==== КОД ====\n","import os, shutil, subprocess, pathlib, glob, textwrap\n","# ФИКС: гарантируем нормальный cwd\n","os.chdir(\"/content\")\n","\n","# (монтирование диска на всякий случай)\n","try:\n","    from google.colab import drive\n","    drive.mount('/content/drive', force_remount=False)\n","except Exception:\n","    pass\n","\n","def run(cmd, cwd=None):\n","    r = subprocess.run(cmd, cwd=cwd, text=True, capture_output=True)\n","    if r.returncode != 0:\n","        print(r.stdout); print(r.stderr)\n","        raise RuntimeError(\" \".join(cmd))\n","    return r.stdout.strip()\n","\n","def find_one(patterns):\n","    for pat in patterns:\n","        hits = glob.glob(pat)\n","        if hits: return hits[0]\n","    return None\n","\n","# ищем файлы\n","nb_path = find_one([\n","    os.path.join(NB_EXPECTED_DIR, \"02_feature_research.ipynb\"),\n","    os.path.join(NB_EXPECTED_DIR, \"*feature*research*.ipynb\"),\n","    os.path.join(NB_EXPECTED_DIR, \"*answers*1-11*.ipynb\"),\n","])\n","if not nb_path:\n","    raise FileNotFoundError(\"Не найден ноутбук исследования в 'Colab Notebooks'.\")\n","\n","top_signals_path = find_one([\n","    os.path.join(ITMO_DIR, \"insights\", TOP_SIGNALS_NAME),\n","    os.path.join(ITMO_DIR, \"**\", TOP_SIGNALS_NAME),\n","])\n","visuals_dir = find_one([\n","    os.path.join(ITMO_DIR, VISUALS_SUBDIR),\n","    os.path.join(ITMO_DIR, \"insights\", \"visuals_final\"),\n","])\n","\n","print(\"[found] notebook:\", nb_path)\n","print(\"[found] top csv :\", top_signals_path or \"(skip)\")\n","print(\"[found] visuals :\", visuals_dir or \"(skip)\")\n","\n","# готовим локальный репо\n","workdir = \"/content/tmp_repo\"\n","repo_public = f\"https://github.com/{GH_USER}/{GH_REPO}.git\"\n","repo_token  = f\"https://{GITHUB_TOKEN}@github.com/{GH_USER}/{GH_REPO}.git\"\n","\n","shutil.rmtree(workdir, ignore_errors=True)\n","run([\"git\", \"clone\", repo_public, workdir])\n","\n","run([\"git\", \"config\", \"--global\", \"user.email\", USER_EMAIL])\n","run([\"git\", \"config\", \"--global\", \"user.name\", USER_NAME])\n","run([\"git\", \"checkout\", \"-b\", BRANCH], cwd=workdir)\n","\n","# структура\n","p_root    = pathlib.Path(workdir, \"project1_data_analysis\")\n","p_nb      = p_root / \"notebooks\"\n","p_outputs = p_root / \"outputs\"\n","p_visuals = p_outputs / \"visuals\"\n","for p in [p_nb, p_outputs, p_visuals]:\n","    p.mkdir(parents=True, exist_ok=True)\n","\n","# копируем\n","shutil.copy2(nb_path, p_nb / pathlib.Path(nb_path).name)\n","if top_signals_path and os.path.isfile(top_signals_path):\n","    shutil.copy2(top_signals_path, p_outputs / pathlib.Path(top_signals_path).name)\n","if visuals_dir and os.path.isdir(visuals_dir):\n","    for f in os.listdir(visuals_dir):\n","        src = os.path.join(visuals_dir, f)\n","        if os.path.isfile(src):\n","            shutil.copy2(src, p_visuals / f)\n","\n","# коммит и пуш\n","run([\"git\", \"add\", \"-A\"], cwd=workdir)\n","run([\"git\", \"commit\", \"-m\", \"feat(research): add exploration notebook and selected outputs\"], cwd=workdir)\n","run([\"git\", \"remote\", \"set-url\", \"origin\", repo_token], cwd=workdir)\n","run([\"git\", \"push\", \"-u\", \"origin\", BRANCH], cwd=workdir)\n","run([\"git\", \"remote\", \"set-url\", \"origin\", repo_public], cwd=workdir)\n","\n","print(f\"\\nГотово → https://github.com/{GH_USER}/{GH_REPO}/tree/{BRANCH}\")\n"],"metadata":{"id":"Mh3jiiNlbxs5"},"execution_count":null,"outputs":[]}]}