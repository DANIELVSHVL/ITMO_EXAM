{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# 02 — Feature Research\n",
        "\n",
        "**Цель:** найти сильные фичи для выявления мошенничества.\n",
        "- Проверяем утечки (data leakage)\n",
        "- Делаем фичи по времени, географии, устройствам, поведенческие агрегаты\n",
        "- Валидируем на простых моделях\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "# Базовые импорты\n",
        "import json, numpy as np, pandas as pd\n",
        "import pyarrow.dataset as ds\n",
        "from collections import defaultdict, Counter\n",
        "\n",
        "path_tx = \"/content/drive/MyDrive/ИТМО/transaction_fraud_data.parquet\"\n",
        "path_fx = \"/content/drive/MyDrive/ИТМО/historical-currency-exchange.csv\"\n",
        "\n",
        "# Если работаешь в Colab, не забудь смонтировать Google Drive до запуска:\n",
        "# from google.colab import drive; drive.mount('/content/drive')\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "# Быстрые sanity-checks\n",
        "ds_tx = ds.dataset(path_tx, format=\"parquet\")\n",
        "cols = ds_tx.schema.names\n",
        "print(\"Колонки:\", cols)\n",
        "print(\"Пример данных:\")\n",
        "print(ds_tx.head(3).to_pandas())\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Кандидаты фич\n",
        "1. **Временные:** час/день недели/праздники, частота клиента за окно.\n",
        "2. **Гео:** дистанция между домашним городом клиента и текущей транзакцией; частота \"вне дома\".\n",
        "3. **Девайсы/канал:** количество уникальных устройств/каналов на клиента за N дней.\n",
        "4. **Деньги:** amount в валюте USD; нормировка на медианный чек клиента.\n",
        "5. **Поведение:** кол-во уникальных мерчантов/стран за окно; всплески активности.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "# Пример: онлайновые агрегаты по клиенту\n",
        "usecols = [\"customer_id\",\"timestamp\",\"amount\",\"currency\",\"country\",\"city\",\"device\",\"is_fraud\"]\n",
        "dataset = ds.dataset(path_tx, format=\"parquet\")\n",
        "per_client_last_24h = defaultdict(lambda: [0,0.0, set(), set()]) # cnt, sum, countries, devices\n",
        "\n",
        "for b in dataset.to_batches(columns=usecols, batch_size=1_000_000):\n",
        "    df = b.to_pandas()\n",
        "    df[\"ts\"] = pd.to_datetime(df[\"timestamp\"], errors=\"coerce\")\n",
        "    df = df.sort_values(\"ts\")\n",
        "    # тут можно добавить скользящее окно; для примера ограничимся группировками\n",
        "    g = df.groupby(\"customer_id\").agg(cnt=(\"amount\",\"size\"), amt_sum=(\"amount\",\"sum\"),\n",
        "                                      n_countries=(\"country\",lambda x: x.nunique()),\n",
        "                                      n_devices=(\"device\",lambda x: x.nunique()))\n",
        "    print(g.head())\n",
        "    break  # для примера выходим после первого батча\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Дальше\n",
        "- Сохранить конструированные фичи (parquet/csv) в `data/` (локально, в гит не коммитить).\n",
        "- Быстрая валидация: train/val split по времени, baseline `LogisticRegression`/`XGBoost`.\n",
        "- Метрики: ROC-AUC, PR-AUC; важности фич; stability по времени.\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.11.13"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}