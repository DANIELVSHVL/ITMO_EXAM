{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "4c6df6d501c74c6a816c9fff9cd67d82": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_deee39c035474547a4993202a6de2741",
            "max": 100,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_7b5aa03574b741d5811ba14060520f86",
            "value": 100
          }
        },
        "deee39c035474547a4993202a6de2741": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "auto"
          }
        },
        "7b5aa03574b741d5811ba14060520f86": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": "black",
            "description_width": ""
          }
        },
        "5e0443dd68ac4ad1ba57099d480591c8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6bdf4741c9564d3a90d5e2b154b375e9",
            "max": 100,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_248c631b7f4749379802c1a9e77b49ec",
            "value": 100
          }
        },
        "6bdf4741c9564d3a90d5e2b154b375e9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "auto"
          }
        },
        "248c631b7f4749379802c1a9e77b49ec": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": "black",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Обработка данных"
      ],
      "metadata": {
        "id": "vv5N9krHEzVj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive', force_remount=True)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2NvSoq1wZjuS",
        "outputId": "3455d277-5eaf-4196-a464-9ac1bd6ac17f"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 0. Загрузка и подготовка\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive', force_remount=True)\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import pyarrow.dataset as ds\n",
        "\n",
        "# Пути к файлам\n",
        "import glob\n",
        "parquet_path = glob.glob(\"/content/drive/MyDrive/*/transaction_fraud_data.parquet\")[0]\n",
        "fx_path = glob.glob(\"/content/drive/MyDrive/*/historical-currency-exchange.csv\")[0]\n",
        "\n",
        "# Чтение parquet\n",
        "dataset = ds.dataset(parquet_path, format=\"parquet\")\n",
        "\n",
        "# Чтение CSV с курсами валют\n",
        "fx = pd.read_csv(fx_path)\n",
        "fx[\"date\"] = pd.to_datetime(fx[\"date\"], errors=\"coerce\").dt.date\n",
        "fx_long = fx.melt(id_vars=\"date\", var_name=\"currency\", value_name=\"rate\").dropna(subset=[\"rate\"])\n",
        "fx_long[\"currency\"] = fx_long[\"currency\"].str.upper()\n",
        "fx_map = {(d, c): float(r) for d, c, r in fx_long.itertuples(index=False)}\n",
        "\n",
        "print(f\"Файл транзакций: {parquet_path}\")\n",
        "print(f\"Файл курсов валют: {fx_path}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ek_BLE_vZn4z",
        "outputId": "e196b476-6ec1-4242-ff22-381939eeb392"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n",
            "Файл транзакций: /content/drive/MyDrive/ИТМО/transaction_fraud_data.parquet\n",
            "Файл курсов валют: /content/drive/MyDrive/ИТМО/historical-currency-exchange.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install xlsxwriter"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Xp0MJZPGxdHf",
        "outputId": "1a7f0794-5f88-435b-f90a-eb0c16e8ee8b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting xlsxwriter\n",
            "  Downloading xlsxwriter-3.2.5-py3-none-any.whl.metadata (2.7 kB)\n",
            "Downloading xlsxwriter-3.2.5-py3-none-any.whl (172 kB)\n",
            "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/172.3 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m71.7/172.3 kB\u001b[0m \u001b[31m2.5 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m172.3/172.3 kB\u001b[0m \u001b[31m2.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: xlsxwriter\n",
            "Successfully installed xlsxwriter-3.2.5\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Формирование fraud_quick_audit_report.xlsx"
      ],
      "metadata": {
        "id": "QwRtgkaiEU-Y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import xlsxwriter\n",
        "import os, json\n",
        "from pathlib import Path\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Путь для сохранения одного Excel-файла\n",
        "OUT_XLSX = Path(\"/content/drive/MyDrive/ИТМО/fraud_quick_audit_report.xlsx\")\n",
        "\n",
        "def to_pandas_head(dataset, n):\n",
        "    if hasattr(dataset, \"head\") and hasattr(dataset.head(1), \"to_pandas\"):\n",
        "        return dataset.head(n).to_pandas()\n",
        "    if isinstance(dataset, pd.DataFrame):\n",
        "        return dataset.head(n).copy()\n",
        "    raise TypeError(\"dataset не распознан\")\n",
        "\n",
        "def safe_nunique(s: pd.Series) -> int:\n",
        "    return s.map(lambda x: json.dumps(x, sort_keys=True) if isinstance(x, (dict, list)) else x) \\\n",
        "            .nunique(dropna=True)\n",
        "\n",
        "def parse_lha_val(x):\n",
        "    if isinstance(x, dict):\n",
        "        return x\n",
        "    if pd.isna(x):\n",
        "        return {}\n",
        "    try:\n",
        "        return json.loads(x)\n",
        "    except Exception:\n",
        "        return {}\n",
        "\n",
        "def ensure_datetime(s):\n",
        "    return pd.to_datetime(s, errors=\"coerce\", utc=True)\n",
        "\n",
        "def run_combined_report(dataset):\n",
        "    with pd.ExcelWriter(OUT_XLSX, engine=\"xlsxwriter\") as writer:\n",
        "        # 1) Быстрый профиль\n",
        "        df = to_pandas_head(dataset, 100_000)\n",
        "        desc = df.describe(include=[np.number]).T\n",
        "        desc.to_excel(writer, sheet_name=\"profile_numeric\")\n",
        "\n",
        "        na = df.isna().sum().sort_values(ascending=False).to_frame(name=\"na_count\")\n",
        "        na[\"na_rate\"] = na[\"na_count\"] / len(df)\n",
        "        na.to_excel(writer, sheet_name=\"profile_na\")\n",
        "\n",
        "        uniq = pd.Series({col: safe_nunique(df[col]) for col in df.columns}, name=\"nunique_safe\")\n",
        "        uniq.sort_values(ascending=False).to_frame().to_excel(writer, sheet_name=\"profile_nunique\")\n",
        "\n",
        "        if \"last_hour_activity\" in df.columns:\n",
        "            keys = [\"num_transactions\", \"total_amount\", \"unique_merchants\", \"unique_countries\", \"max_single_amount\"]\n",
        "            lha = df[\"last_hour_activity\"].map(parse_lha_val)\n",
        "            rows = []\n",
        "            for k in keys:\n",
        "                vals = pd.to_numeric(lha.map(lambda d: d.get(k, np.nan)), errors=\"coerce\")\n",
        "                rows.append({\n",
        "                    \"key\": k,\n",
        "                    \"non_null\": int(vals.notna().sum()),\n",
        "                    \"min\": float(vals.min()) if vals.notna().any() else np.nan,\n",
        "                    \"mean\": float(vals.mean()) if vals.notna().any() else np.nan,\n",
        "                    \"max\": float(vals.max()) if vals.notna().any() else np.nan,\n",
        "                })\n",
        "            pd.DataFrame(rows).to_excel(writer, sheet_name=\"profile_last_hour_activity\", index=False)\n",
        "\n",
        "        df.head(20).to_excel(writer, sheet_name=\"sample_head\", index=False)\n",
        "\n",
        "        # 2) Лифты\n",
        "        df_big = to_pandas_head(dataset, 1_000_000)\n",
        "        base = df_big[\"is_fraud\"].mean()\n",
        "\n",
        "        def lift_one(col):\n",
        "            t = df_big.groupby(col)[\"is_fraud\"].agg(['mean','count']).rename(columns={'mean':'fraud_rate','count':'transactions'})\n",
        "            t[\"lift\"] = t[\"fraud_rate\"] / base\n",
        "            return t.sort_values(\"lift\", ascending=False)\n",
        "\n",
        "        for col in [\"vendor_category\", \"vendor_type\"]:\n",
        "            if col in df_big.columns:\n",
        "                lift_one(col).to_excel(writer, sheet_name=f\"lift_{col}\")\n",
        "\n",
        "        def lift_table(group_cols, min_n=300):\n",
        "            t = (df_big.groupby(group_cols, dropna=False)[\"is_fraud\"]\n",
        "                 .agg(['mean','count'])\n",
        "                 .rename(columns={'mean':'fraud_rate','count':'transactions'})\n",
        "                 .reset_index())\n",
        "            t[\"lift\"] = t[\"fraud_rate\"] / base\n",
        "            return t[t[\"transactions\"] >= min_n].sort_values(\"lift\", ascending=False)\n",
        "\n",
        "        combos = [\n",
        "            ([\"channel\",\"device\"], 300, \"lift_channel_x_device\"),\n",
        "            ([\"is_outside_home_country\",\"is_high_risk_vendor\"], 200, \"lift_outside_x_highrisk\"),\n",
        "            ([\"country\"], 500, \"lift_country\"),\n",
        "            ([\"country\",\"city\"], 400, \"lift_country_x_city\"),\n",
        "        ]\n",
        "        for cols, min_n, name in combos:\n",
        "            if set(cols).issubset(df_big.columns):\n",
        "                lift_table(cols, min_n).to_excel(writer, sheet_name=name, index=False)\n",
        "\n",
        "        # 3) Время\n",
        "        if \"timestamp\" in df_big.columns:\n",
        "            if not np.issubdtype(df_big[\"timestamp\"].dtype, np.datetime64):\n",
        "                df_big[\"timestamp\"] = ensure_datetime(df_big[\"timestamp\"])\n",
        "            df_big[\"day_of_week\"] = df_big[\"timestamp\"].dt.day_name()\n",
        "            df_big[\"hour\"] = df_big[\"timestamp\"].dt.hour\n",
        "            pivot = df_big.pivot_table(index=\"day_of_week\", columns=\"hour\",\n",
        "                                       values=\"is_fraud\", aggfunc=\"mean\").fillna(0.0)\n",
        "            days_order = [\"Monday\",\"Tuesday\",\"Wednesday\",\"Thursday\",\"Friday\",\"Saturday\",\"Sunday\"]\n",
        "            pivot = pivot.reindex(days_order)\n",
        "            pivot.to_excel(writer, sheet_name=\"fraud_rate_by_dow_hour\")\n",
        "\n",
        "        # 4) Кандидаты на фичи\n",
        "        if \"timestamp\" in df.columns:\n",
        "            df[\"timestamp\"] = ensure_datetime(df[\"timestamp\"])\n",
        "        if set([\"country\",\"city\",\"vendor_type\",\"amount\"]).issubset(df.columns):\n",
        "            med = df.groupby([\"country\",\"city\",\"vendor_type\"])[\"amount\"].median().rename(\"city_vendor_median\")\n",
        "            df = df.merge(med, on=[\"country\",\"city\",\"vendor_type\"], how=\"left\")\n",
        "            df[\"RelativeAmountCity\"] = df[\"amount\"] / df[\"city_vendor_median\"].replace(0, np.nan)\n",
        "            q = df[\"RelativeAmountCity\"].quantile(0.995)\n",
        "            df[\"RelativeAmountCity\"] = df[\"RelativeAmountCity\"].clip(upper=q)\n",
        "\n",
        "        if \"is_fraud\" in df.columns:\n",
        "            df[\"hour\"] = df[\"timestamp\"].dt.hour\n",
        "            hr = df.groupby(\"hour\")[\"is_fraud\"].mean().rename(\"HourRiskMap\")\n",
        "            df = df.merge(hr, on=\"hour\", how=\"left\")\n",
        "            df[\"HourRisk\"] = df[\"HourRiskMap\"]\n",
        "\n",
        "        if set([\"customer_id\",\"device_fingerprint\",\"timestamp\"]).issubset(df.columns):\n",
        "            first_ts = df.groupby([\"customer_id\",\"device_fingerprint\"])[\"timestamp\"].transform(\"min\")\n",
        "            df[\"DeviceFirstSeen\"] = (df[\"timestamp\"] == first_ts).astype(\"int8\")\n",
        "\n",
        "        if \"last_hour_activity\" in df.columns:\n",
        "            lha = df[\"last_hour_activity\"].map(parse_lha_val)\n",
        "            df[\"lha_num_tx\"] = pd.to_numeric(lha.map(lambda d: d.get(\"num_transactions\", np.nan)), errors=\"coerce\")\n",
        "            df[\"lha_total_amount\"] = pd.to_numeric(lha.map(lambda d: d.get(\"total_amount\", np.nan)), errors=\"coerce\")\n",
        "            z_tx = (df[\"lha_num_tx\"] - df[\"lha_num_tx\"].mean()) / (df[\"lha_num_tx\"].std(ddof=0) + 1e-9)\n",
        "            z_amt = (np.log1p(df[\"lha_total_amount\"]) - np.log1p(df[\"lha_total_amount\"]).mean()) / (np.log1p(df[\"lha_total_amount\"]).std(ddof=0) + 1e-9)\n",
        "            df[\"HyperActivityScore\"] = (z_tx + z_amt).clip(-5, 5)\n",
        "\n",
        "        cand = [c for c in [\"RelativeAmountCity\",\"HourRisk\",\"DeviceFirstSeen\",\"HyperActivityScore\"] if c in df.columns]\n",
        "        if cand and \"is_fraud\" in df.columns:\n",
        "            corr = df[cand].join(df[\"is_fraud\"].astype(int)).corr(method=\"spearman\").loc[cand, \"is_fraud\"] \\\n",
        "                .sort_values(ascending=False).to_frame(\"spearman_vs_fraud\")\n",
        "            corr.to_excel(writer, sheet_name=\"feature_candidates_spearman\")\n",
        "            df[cand].quantile([0.01,0.5,0.99]).to_excel(writer, sheet_name=\"feature_candidates_quantiles\")\n",
        "            keep = [\"transaction_id\",\"is_fraud\"] + cand\n",
        "            df[keep].to_excel(writer, sheet_name=\"feature_candidates\", index=False)\n",
        "\n",
        "    print(f\"Отчёт сохранён в: {OUT_XLSX}\")\n",
        "\n",
        "# ---- Запуск ----\n",
        "run_combined_report(dataset)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8ONwWnk0w-0r",
        "outputId": "92aa9c2c-475f-437d-dfff-cef22e1c2f18"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Отчёт сохранён в: /content/drive/MyDrive/ИТМО/fraud_quick_audit_report.xlsx\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Проверка 10 гипотез"
      ],
      "metadata": {
        "id": "PPCR14Op42VN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# === ГИПОТЕЗЫ: экономная загрузка + конвертация валют + проверка 10/10 ===\n",
        "import os, json, math, gc\n",
        "from pathlib import Path\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "# ---------- ПУТИ ----------\n",
        "PARQUET_PATH = \"/content/drive/MyDrive/ИТМО/transaction_fraud_data.parquet\"   # ваш паркет\n",
        "FX_CSV_PATH  = \"/content/drive/MyDrive/ИТМО/historical-currency-exchange.csv\" # CSV с курсами\n",
        "OUT_DIR      = Path(\"/content/drive/MyDrive/ИТМО/audit_out\"); OUT_DIR.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "# ---------- КОНФИГ ПРАГМАТИКИ / ПОРОГОВ ----------\n",
        "MIN_N       = 300       # минимальный надёжный объём сегмента\n",
        "LIFT_THR    = 1.20      # «сильный» лифт\n",
        "FR_THR      = 0.15      # «сильная» доля фрода (для фич, где считаем пороги)\n",
        "ZSIGMA_HA   = 2.0       # порог для HyperActivityScore (z>2)\n",
        "RELAMT_Q    = 0.95      # «высокая сумма» — квантиль по amount_usd\n",
        "LHA_COUNTRY = 3         # «> N уникальных стран» за час\n",
        "LHA_MERCH   = 5         # «> N уникальных мерчантов» за час\n",
        "\n",
        "# ---------- КОЛОНКИ, которые тянем из паркета (экономно) ----------\n",
        "COLS = [\n",
        "    \"transaction_id\",\"customer_id\",\"device_fingerprint\",\n",
        "    \"timestamp\",\"is_fraud\",\n",
        "    \"vendor_category\",\"vendor_type\",\n",
        "    \"channel\",\"device\",\n",
        "    \"country\",\"city\",\n",
        "    \"is_outside_home_country\",\"is_high_risk_vendor\",\n",
        "    \"amount\",\"currency\",\n",
        "    \"last_hour_activity\"\n",
        "]\n",
        "\n",
        "# ---------- УТИЛИТЫ ----------\n",
        "def to_datetime_utc(s):\n",
        "    s = pd.to_datetime(s, errors=\"coerce\", utc=True)\n",
        "    return s\n",
        "\n",
        "def parse_lha(x):\n",
        "    if isinstance(x, dict): return x\n",
        "    if pd.isna(x): return {}\n",
        "    try:\n",
        "        return json.loads(x)\n",
        "    except Exception:\n",
        "        return {}\n",
        "\n",
        "def safe_rate_lookup(row, fx_wide):\n",
        "    # row: has date_floor, currency; fx_wide has columns ['date','USD','EUR',...], USD=1\n",
        "    # если валюты нет в fx или NaN — вернём NaN => amount_usd станет NaN (мы их отбросим в соответствующих гипотезах)\n",
        "    try:\n",
        "        return fx_wide.at[row[\"date_floor\"], row[\"currency\"]]\n",
        "    except Exception:\n",
        "        return np.nan\n",
        "\n",
        "def segment_lift(df, seg_mask, min_n=MIN_N):\n",
        "    \"\"\"Лифт и показатели для булевого сегмента.\"\"\"\n",
        "    n_all = df[\"is_fraud\"].notna().sum()\n",
        "    base = df[\"is_fraud\"].mean() if n_all else np.nan\n",
        "\n",
        "    seg = df.loc[seg_mask]\n",
        "    n = seg[\"is_fraud\"].notna().sum()\n",
        "    fr = seg[\"is_fraud\"].mean() if n else np.nan\n",
        "    lift = (fr / base) if (n and base and base>0) else np.nan\n",
        "    return {\n",
        "        \"n\": int(n),\n",
        "        \"fraud_rate\": float(fr) if pd.notna(fr) else np.nan,\n",
        "        \"lift\": float(lift) if pd.notna(lift) else np.nan\n",
        "    }\n",
        "\n",
        "def top_lift_by_group(df, cols, min_n=MIN_N, top_k=1):\n",
        "    base = df[\"is_fraud\"].mean()\n",
        "    g = (df.groupby(cols, dropna=False)[\"is_fraud\"]\n",
        "           .agg(['mean','count'])\n",
        "           .rename(columns={'mean':'fraud_rate','count':'n'})\n",
        "           .reset_index())\n",
        "    g = g[g[\"n\"]>=min_n]\n",
        "    g[\"lift\"] = g[\"fraud_rate\"] / base\n",
        "    g = g.sort_values(\"lift\", ascending=False)\n",
        "    if g.empty:\n",
        "        return np.nan, None\n",
        "    row = g.iloc[0:top_k]\n",
        "    return float(row[\"lift\"].iloc[0]), row\n",
        "\n",
        "def print_line(name, ok, metric, extra=\"\"):\n",
        "    badge = \"✅\" if ok else \"⚠️\"\n",
        "    print(f\"{badge} {name:35s} | passed={str(ok):5s} | metric={metric:<8.3f} {extra}\")\n",
        "\n",
        "# ---------- 1) ЗАГРУЗКА ДАННЫХ (экономно) ----------\n",
        "try:\n",
        "    df = pd.read_parquet(PARQUET_PATH, columns=COLS)\n",
        "except MemoryError:\n",
        "    # fallback: по частям через pyarrow.dataset (если совсем тесно по памяти)\n",
        "    import pyarrow.dataset as ds\n",
        "    dataset = ds.dataset(PARQUET_PATH, format=\"parquet\")\n",
        "    batches = []\n",
        "    for b in dataset.to_batches(columns=COLS, batch_size=200_000):\n",
        "        batches.append(b.to_pandas())\n",
        "    df = pd.concat(batches, ignore_index=True)\n",
        "    del batches; gc.collect()\n",
        "\n",
        "# только строки с is_fraud в [0,1]\n",
        "df = df[df[\"is_fraud\"].isin([0,1])].copy()\n",
        "df[\"is_fraud\"] = df[\"is_fraud\"].astype(\"float32\")\n",
        "\n",
        "# ---------- 2) КОНВЕРТАЦИЯ ВАЛЮТ ----------\n",
        "fx = pd.read_csv(FX_CSV_PATH)\n",
        "# приводим к «широкому» виду: индекс date, колонки — коды валют, значения — курс (единиц валюты за 1 USD)\n",
        "fx[\"date\"] = pd.to_datetime(fx[\"date\"], utc=True)\n",
        "fx = fx.set_index(\"date\").sort_index()\n",
        "df[\"timestamp\"] = to_datetime_utc(df[\"timestamp\"])\n",
        "df[\"date_floor\"] = df[\"timestamp\"].dt.floor(\"D\")\n",
        "\n",
        "# убедимся, что у нас есть только нужные даты\n",
        "fx_wide = fx.copy()\n",
        "\n",
        "# векторный маппинг курса\n",
        "# подготовим возможные пропуски/редкие валюты\n",
        "avail_curr = set(fx_wide.columns)\n",
        "mask_known = df[\"currency\"].isin(avail_curr)\n",
        "df[\"fx_rate\"] = np.nan\n",
        "if mask_known.any():\n",
        "    # построчный lookup (быстро на Cython не сделать — но этот участок обычно не узкое место)\n",
        "    df.loc[mask_known, \"fx_rate\"] = df.loc[mask_known, [\"date_floor\",\"currency\"]].apply(\n",
        "        lambda r: fx_wide.at[r[\"date_floor\"], r[\"currency\"]]\n",
        "        if (r[\"date_floor\"] in fx_wide.index) and (r[\"currency\"] in fx_wide.columns)\n",
        "        else np.nan, axis=1\n",
        "    )\n",
        "\n",
        "# amount_usd: amount / rate (т.к. курсы «за 1 USD»)\n",
        "df[\"amount_usd\"] = df[\"amount\"] / df[\"fx_rate\"]\n",
        "# невалидные — в NaN\n",
        "df.loc[~np.isfinite(df[\"amount_usd\"]), \"amount_usd\"] = np.nan\n",
        "\n",
        "# ---------- 3) БАЗОВЫЕ ВЫЧИСЛЕНИЯ ----------\n",
        "base_fr = df[\"is_fraud\"].mean()\n",
        "base_n  = len(df)\n",
        "summary_rows = []\n",
        "\n",
        "# ===== Гипотеза 1: Лифты по vendor_category =====\n",
        "ok1_lift, top1 = top_lift_by_group(df.dropna(subset=[\"vendor_category\"]), [\"vendor_category\"], MIN_N)\n",
        "summary_rows.append([\"lift_vendor_category\", ok1_lift>=LIFT_THR if pd.notna(ok1_lift) else False, ok1_lift, int(top1[\"n\"].iloc[0]) if isinstance(top1, pd.DataFrame) else 0])\n",
        "\n",
        "# ===== Гипотеза 2: Лифты по vendor_type =====\n",
        "ok2_lift, top2 = top_lift_by_group(df.dropna(subset=[\"vendor_type\"]), [\"vendor_type\"], MIN_N)\n",
        "summary_rows.append([\"lift_vendor_type\", ok2_lift>=LIFT_THR if pd.notna(ok2_lift) else False, ok2_lift, int(top2[\"n\"].iloc[0]) if isinstance(top2, pd.DataFrame) else 0])\n",
        "\n",
        "# ===== Гипотеза 3: Канал × устройство =====\n",
        "ok3_lift, top3 = top_lift_by_group(df.dropna(subset=[\"channel\",\"device\"]), [\"channel\",\"device\"], MIN_N)\n",
        "summary_rows.append([\"lift_channel_x_device\", ok3_lift>=LIFT_THR if pd.notna(ok3_lift) else False, ok3_lift, int(top3[\"n\"].iloc[0]) if isinstance(top3, pd.DataFrame) else 0])\n",
        "\n",
        "# ===== Гипотеза 4: Гео страна =====\n",
        "ok4_lift, top4 = top_lift_by_group(df.dropna(subset=[\"country\"]), [\"country\"], MIN_N)\n",
        "summary_rows.append([\"lift_country\", ok4_lift>=LIFT_THR if pd.notna(ok4_lift) else False, ok4_lift, int(top4[\"n\"].iloc[0]) if isinstance(top4, pd.DataFrame) else 0])\n",
        "\n",
        "# ===== Гипотеза 5: Гео страна×город =====\n",
        "ok5_lift, top5 = top_lift_by_group(df.dropna(subset=[\"country\",\"city\"]), [\"country\",\"city\"], MIN_N)\n",
        "summary_rows.append([\"lift_country_x_city\", ok5_lift>=LIFT_THR if pd.notna(ok5_lift) else False, ok5_lift, int(top5[\"n\"].iloc[0]) if isinstance(top5, pd.DataFrame) else 0])\n",
        "\n",
        "# ===== Гипотеза 6: Outside_home × High_risk_vendor =====\n",
        "ok6_lift, top6 = top_lift_by_group(df.dropna(subset=[\"is_outside_home_country\",\"is_high_risk_vendor\"]),\n",
        "                                   [\"is_outside_home_country\",\"is_high_risk_vendor\"], MIN_N)\n",
        "summary_rows.append([\"outside_home_x_highrisk\", ok6_lift>=LIFT_THR if pd.notna(ok6_lift) else False, ok6_lift, int(top6[\"n\"].iloc[0]) if isinstance(top6, pd.DataFrame) else 0])\n",
        "\n",
        "# ===== Гипотеза 7: Время — fraud rate по часу (берём максимальный час) =====\n",
        "dft = df.dropna(subset=[\"timestamp\"]).copy()\n",
        "dft[\"hour\"] = dft[\"timestamp\"].dt.hour\n",
        "fr_by_hour = dft.groupby(\"hour\")[\"is_fraud\"].agg(['mean','count']).rename(columns={'mean':'fraud_rate','count':'n'})\n",
        "fr_by_hour = fr_by_hour[fr_by_hour[\"n\"]>=MIN_N]\n",
        "max_fr = fr_by_hour[\"fraud_rate\"].max() if not fr_by_hour.empty else np.nan\n",
        "summary_rows.append([\"fraud_rate_by_hour\", (max_fr>=FR_THR) if pd.notna(max_fr) else False, max_fr, int(fr_by_hour[\"n\"].max()) if not fr_by_hour.empty else 0])\n",
        "\n",
        "# ===== Гипотеза 8: RelativeAmountCity (на USD) =====\n",
        "rel_df = df.dropna(subset=[\"amount_usd\",\"country\",\"city\",\"vendor_type\"]).copy()\n",
        "if not rel_df.empty:\n",
        "    med = rel_df.groupby([\"country\",\"city\",\"vendor_type\"])[\"amount_usd\"].median().rename(\"city_vendor_median\")\n",
        "    rel_df = rel_df.join(med, on=[\"country\",\"city\",\"vendor_type\"])\n",
        "    rel_df[\"RelativeAmountCity\"] = rel_df[\"amount_usd\"] / rel_df[\"city_vendor_median\"].replace(0,np.nan)\n",
        "    high_thr = rel_df[\"RelativeAmountCity\"].quantile(RELAMT_Q)\n",
        "    seg = rel_df[\"RelativeAmountCity\"] >= high_thr\n",
        "    m8 = segment_lift(rel_df, seg)\n",
        "    ok8 = (m8[\"n\"]>=MIN_N) and ((m8[\"lift\"]>=LIFT_THR) or (m8[\"fraud_rate\"]>=FR_THR))\n",
        "else:\n",
        "    m8 = {\"n\":0,\"fraud_rate\":np.nan,\"lift\":np.nan}; ok8=False\n",
        "summary_rows.append([\"relative_amount_city_high\", ok8, m8[\"lift\"], m8[\"n\"]])\n",
        "\n",
        "# ===== Гипотеза 9: DeviceFirstSeen × amount (high) =====\n",
        "dfs_df = df.dropna(subset=[\"timestamp\",\"customer_id\",\"device_fingerprint\",\"amount_usd\"]).copy()\n",
        "if not dfs_df.empty:\n",
        "    first_ts = dfs_df.groupby([\"customer_id\",\"device_fingerprint\"])[\"timestamp\"].transform(\"min\")\n",
        "    dfs_df[\"DeviceFirstSeen\"] = (dfs_df[\"timestamp\"]==first_ts)\n",
        "    amt_thr = dfs_df[\"amount_usd\"].quantile(RELAMT_Q)\n",
        "    seg = (dfs_df[\"DeviceFirstSeen\"]) & (dfs_df[\"amount_usd\"]>=amt_thr)\n",
        "    m9 = segment_lift(dfs_df, seg)\n",
        "    ok9 = (m9[\"n\"]>=MIN_N) and ((m9[\"lift\"]>=LIFT_THR) or (m9[\"fraud_rate\"]>=FR_THR))\n",
        "else:\n",
        "    m9 = {\"n\":0,\"fraud_rate\":np.nan,\"lift\":np.nan}; ok9=False\n",
        "summary_rows.append([\"device_first_seen_x_amount\", ok9, m9[\"lift\"], m9[\"n\"]])\n",
        "\n",
        "# ===== Гипотеза 10: HyperActivityScore + last_hour_activity raw =====\n",
        "lha_df = df.dropna(subset=[\"last_hour_activity\"]).copy()\n",
        "if not lha_df.empty:\n",
        "    lha = lha_df[\"last_hour_activity\"].map(parse_lha)\n",
        "    lha_df[\"lha_num_tx\"] = pd.to_numeric(lha.map(lambda d: d.get(\"num_transactions\", np.nan)), errors=\"coerce\")\n",
        "    lha_df[\"lha_total_amount\"] = pd.to_numeric(lha.map(lambda d: d.get(\"total_amount\", np.nan)), errors=\"coerce\")\n",
        "    lha_df[\"lha_unique_merchants\"] = pd.to_numeric(lha.map(lambda d: d.get(\"unique_merchants\", np.nan)), errors=\"coerce\")\n",
        "    lha_df[\"lha_unique_countries\"] = pd.to_numeric(lha.map(lambda d: d.get(\"unique_countries\", np.nan)), errors=\"coerce\")\n",
        "\n",
        "    z_tx  = (lha_df[\"lha_num_tx\"] - lha_df[\"lha_num_tx\"].mean()) / (lha_df[\"lha_num_tx\"].std(ddof=0) + 1e-9)\n",
        "    z_amt = (np.log1p(lha_df[\"lha_total_amount\"]) - np.log1p(lha_df[\"lha_total_amount\"]).mean()) / (np.log1p(lha_df[\"lha_total_amount\"]).std(ddof=0) + 1e-9)\n",
        "    lha_df[\"HyperActivityScore\"] = (z_tx + z_amt).clip(-5,5)\n",
        "\n",
        "    # 10a: HyperActivityScore > 2σ\n",
        "    seg_a = lha_df[\"HyperActivityScore\"] > ZSIGMA_HA\n",
        "    m10a = segment_lift(lha_df, seg_a)\n",
        "    ok10a = (m10a[\"n\"]>=MIN_N) and ((m10a[\"lift\"]>=LIFT_THR) or (m10a[\"fraud_rate\"]>=FR_THR))\n",
        "\n",
        "    # 10b: raw-условие: много стран или много мерчантов за час\n",
        "    seg_b = (lha_df[\"lha_unique_countries\"]>LHA_COUNTRY) | (lha_df[\"lha_unique_merchants\"]>LHA_MERCH)\n",
        "    m10b = segment_lift(lha_df, seg_b)\n",
        "    ok10b = (m10b[\"n\"]>=MIN_N) and ((m10b[\"lift\"]>=LIFT_THR) or (m10b[\"fraud_rate\"]>=FR_THR))\n",
        "else:\n",
        "    m10a={\"n\":0,\"fraud_rate\":np.nan,\"lift\":np.nan}; ok10a=False\n",
        "    m10b={\"n\":0,\"fraud_rate\":np.nan,\"lift\":np.nan}; ok10b=False\n",
        "\n",
        "summary_rows.append([\"hyper_activity_score>2σ\", ok10a, m10a[\"lift\"], m10a[\"n\"]])\n",
        "summary_rows.append([\"lha_raw_anomaly\",       ok10b, m10b[\"lift\"], m10b[\"n\"]])\n",
        "\n",
        "# ---------- 4) СВОДНЫЙ ОТЧЁТ ----------\n",
        "summary = pd.DataFrame(summary_rows, columns=[\"Hypothesis\",\"Passed\",\"Metric_Lift_or_FR\",\"N\"])\n",
        "summary.insert(1, \"Thresholds\", f\"LIFT_THR={LIFT_THR}; FR_THR={FR_THR}; MIN_N={MIN_N}\")\n",
        "summary.to_csv(OUT_DIR/\"hypotheses_summary.csv\", index=False)\n",
        "\n",
        "print(f\"\\nВсего строк: {base_n:,}; базовая доля фрода: {base_fr:.4f}\")\n",
        "print(\"—\"*88)\n",
        "for _,r in summary.iterrows():\n",
        "    print_line(r[\"Hypothesis\"], r[\"Passed\"], r[\"Metric_Lift_or_FR\"], extra=f\"| n={int(r['N'])}\")\n",
        "\n",
        "# Отдельно сохраняем топ-группы для ключевых гипотез (если пригодится для слайдов)\n",
        "extras = {}\n",
        "if isinstance(top3, pd.DataFrame): extras[\"top_channel_x_device.csv\"]      = top3\n",
        "if isinstance(top4, pd.DataFrame): extras[\"top_country.csv\"]               = top4\n",
        "if isinstance(top5, pd.DataFrame): extras[\"top_country_x_city.csv\"]        = top5\n",
        "if isinstance(top6, pd.DataFrame): extras[\"top_outside_x_highrisk.csv\"]    = top6\n",
        "\n",
        "for name, tbl in extras.items():\n",
        "    tbl.to_csv(OUT_DIR/name, index=False)\n",
        "\n",
        "print(\"\\n[saved]\", OUT_DIR/\"hypotheses_summary.csv\")\n",
        "for k in extras: print(\"[saved]\", OUT_DIR/k)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LO9L6eLk2S_K",
        "outputId": "690656a9-df1a-4c67-c592-07b08dc07727"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Всего строк: 7,483,766; базовая доля фрода: 0.1997\n",
            "————————————————————————————————————————————————————————————————————————————————————————\n",
            "⚠️ lift_vendor_category                | passed=False | metric=1.003    | n=935790\n",
            "⚠️ lift_vendor_type                    | passed=False | metric=1.007    | n=233977\n",
            "✅ lift_channel_x_device               | passed=True  | metric=5.007    | n=217324\n",
            "✅ lift_country                        | passed=True  | metric=1.904    | n=785704\n",
            "✅ lift_country_x_city                 | passed=True  | metric=1.904    | n=785704\n",
            "✅ outside_home_x_highrisk             | passed=True  | metric=2.843    | n=1806158\n",
            "✅ fraud_rate_by_hour                  | passed=True  | metric=0.593    | n=456393\n",
            "✅ relative_amount_city_high           | passed=True  | metric=2.677    | n=374189\n",
            "✅ device_first_seen_x_amount          | passed=True  | metric=5.001    | n=233155\n",
            "✅ hyper_activity_score>2σ             | passed=True  | metric=1.016    | n=970402\n",
            "✅ lha_raw_anomaly                     | passed=True  | metric=1.003    | n=7307953\n",
            "\n",
            "[saved] /content/drive/MyDrive/ИТМО/audit_out/hypotheses_summary.csv\n",
            "[saved] /content/drive/MyDrive/ИТМО/audit_out/top_channel_x_device.csv\n",
            "[saved] /content/drive/MyDrive/ИТМО/audit_out/top_country.csv\n",
            "[saved] /content/drive/MyDrive/ИТМО/audit_out/top_country_x_city.csv\n",
            "[saved] /content/drive/MyDrive/ИТМО/audit_out/top_outside_x_highrisk.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ---------- БЛОК 1. ЗАГРУЗКА ----------\n",
        "import pandas as pd, numpy as np, textwrap, math\n",
        "import matplotlib.pyplot as plt\n",
        "from pathlib import Path\n",
        "\n",
        "CSV_PATH = \"/content/drive/MyDrive/ИТМО/insights/top_signals_reliable.csv\"\n",
        "OUT_DIR  = Path(\"/content/drive/MyDrive/ИТМО/insights/visuals_final\")\n",
        "OUT_DIR.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "# Порогы\n",
        "MIN_N   = 200     # минимальный объём, чтобы считать сигнал \"надёжным\"\n",
        "LOW_N   = 1000    # пометка (low N) на графике\n",
        "TOP_N   = 10\n",
        "LIFT_THR= 1.2\n",
        "FR_THR  = 0.15\n",
        "SP_THR  = 0.30\n",
        "\n",
        "df = pd.read_csv(CSV_PATH)\n",
        "df.columns = [c.strip() for c in df.columns]\n",
        "\n",
        "# Какие колонки не включать в подпись фичи\n",
        "EXCLUDE = {\n",
        "    \"lift\",\"fraud_rate\",\"spearman_vs_fraud\",\n",
        "    \"transactions\",\"count\",\"metric\",\"sheet\",\"priority_mark\",\n",
        "    \"mean_metric_all\",\"index\",\"Unnamed: 0\"\n",
        "}\n",
        "\n",
        "def wrap(s, w=42):\n",
        "    return textwrap.fill(str(s), width=w, break_long_words=False, replace_whitespace=False)\n",
        "\n",
        "def make_feature_label(row: pd.Series, width=42) -> str:\n",
        "    parts = []\n",
        "    for col, val in row.items():\n",
        "        if col in EXCLUDE or pd.isna(val):\n",
        "            continue\n",
        "        sval = str(int(val)) if isinstance(val,(int,float)) and float(val).is_integer() else str(val)\n",
        "        if sval == \"\" or sval.lower()==\"nan\":\n",
        "            continue\n",
        "        parts.append(f\"{col}={sval}\")\n",
        "    txt = \" | \".join(parts) if parts else \"(misc)\"\n",
        "    return wrap(txt, width)\n",
        "\n",
        "def is_priority(label: str) -> bool:\n",
        "    s = label.lower()\n",
        "    return any([\n",
        "        (\"is_outside_home_country=1\" in s and \"is_high_risk_vendor=1\" in s),\n",
        "        \"devicefirstseen\" in s,\n",
        "        \"hyperactivityscore\" in s,\n",
        "        \"relativeamountcity\" in s,\n",
        "        (\"channel=\" in s and \"device=\" in s)\n",
        "    ])\n",
        "\n",
        "# Служебные удобства\n",
        "def pick_weight_col(frame: pd.DataFrame):\n",
        "    return \"transactions\" if \"transactions\" in frame.columns else (\"count\" if \"count\" in frame.columns else None)\n",
        "\n",
        "print(\"Файл:\", CSV_PATH, \"| строк:\", len(df))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QvETMhYYXo-V",
        "outputId": "48bcb20b-fa5c-4e53-e105-56e62ca1d008"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Файл: /content/drive/MyDrive/ИТМО/insights/top_signals_reliable.csv | строк: 48\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Подключение файла с курсами и суммами"
      ],
      "metadata": {
        "id": "T1JxDH_GmvKV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Поиск и загрузка транзакций + курсов валют"
      ],
      "metadata": {
        "id": "oKjBwbd2ptDv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ========== SAFE MODE: агрегаты без загрузки всего в RAM ==========\n",
        "!pip -q install duckdb\n",
        "\n",
        "import duckdb, os, pandas as pd, numpy as np\n",
        "con = duckdb.connect()\n",
        "con.register(\"fx_long\", fx_long.rename(columns={\"rate\":\"rate_to_usd\"}))  # маленькая табличка с курсами\n",
        "\n",
        "# Определяем имена столбцов, какие реально есть в parquet (без чтения в память)\n",
        "import pyarrow.dataset as ds\n",
        "schema_cols = set(ds.dataset(parquet_path).schema.names)\n",
        "\n",
        "def pick(cands):\n",
        "    for c in cands:\n",
        "        if c in schema_cols:\n",
        "            return c\n",
        "    return None\n",
        "\n",
        "Y_COL    = pick([\"is_fraud\",\"fraud\",\"fraud_flag\",\"target\"])\n",
        "AMT_COL  = pick([\"amount\",\"Amount\"])\n",
        "CURR_COL = pick([\"currency\",\"curr\",\"currency_code\"])\n",
        "DATE_COL = pick([\"date\",\"txn_date\",\"timestamp\",\"datetime\"])\n",
        "COUNTRY  = pick([\"country\"])\n",
        "CITY     = pick([\"city\"])\n",
        "OUTSIDE  = pick([\"is_outside_home_country\",\"outside_home\",\"outside_country\",\"is_foreign\"])\n",
        "HRISK    = pick([\"is_high_risk_vendor\",\"high_risk_vendor\"])\n",
        "CHANNEL  = pick([\"channel\"])\n",
        "DEVICE   = pick([\"device_fingerprint\",\"device_id\",\"device\"])\n",
        "VCAT     = pick([\"vendor_category\",\"mcc_category\",\"mcc_group\"])\n",
        "VTYPE    = pick([\"vendor_type\",\"mcc\",\"merchant_type\"])\n",
        "HOURISK  = pick([\"hourrisk\",\"hour_risk\"])\n",
        "DFIRST   = pick([\"devicefirstseen\",\"device_first_seen\"])\n",
        "LHOURACT = pick([\"last_hour_activity\",\"activity_1h\",\"velocity_1h\"])\n",
        "ISCARDP  = pick([\"is_card_present\",\"card_present\"])\n",
        "\n",
        "assert all([Y_COL, AMT_COL, CURR_COL, DATE_COL]), \"Нет обязательных колонок (is_fraud/amount/currency/date).\"\n",
        "\n",
        "# Глобальная частота фрода (для лифта)\n",
        "GLOBAL_FR = con.execute(f\"\"\"\n",
        "    SELECT AVG(CAST({Y_COL} AS DOUBLE)) AS fr\n",
        "    FROM read_parquet('{parquet_path}')\n",
        "\"\"\").fetchone()[0]\n",
        "\n",
        "MIN_N   = 200\n",
        "LOW_N   = 1000\n",
        "OUT_DIR = \"/content/drive/MyDrive/ИТМО/insights/visuals_final\"\n",
        "os.makedirs(OUT_DIR, exist_ok=True)\n",
        "\n",
        "def seg_query(cols, name):\n",
        "    \"\"\"\n",
        "    Возвращает pandas-таблицу агрегатов для сегмента cols (без загрузки всего датафрейма в RAM).\n",
        "    amount_usd = amount / rate_to_usd, где rate_to_usd = сколько единиц валюты за 1 USD.\n",
        "    \"\"\"\n",
        "    cols_sql = \", \".join(cols)\n",
        "    q = f\"\"\"\n",
        "    WITH tx AS (\n",
        "      SELECT\n",
        "        {cols_sql},\n",
        "        CAST({Y_COL} AS INTEGER) AS y,\n",
        "        {AMT_COL} AS amount,\n",
        "        UPPER({CURR_COL}) AS currency,  -- Alias currency column\n",
        "        CAST({DATE_COL} AS DATE) AS date  -- Alias date column\n",
        "      FROM read_parquet('{parquet_path}')\n",
        "    )\n",
        "    SELECT\n",
        "      {cols_sql},\n",
        "      COUNT(*)                            AS n,\n",
        "      SUM(y)                              AS fraud,\n",
        "      SUM(amount / rate_to_usd)           AS amount_usd_sum,\n",
        "      SUM(CASE WHEN y=1 THEN amount / rate_to_usd ELSE 0 END) AS fraud_amount_usd_sum\n",
        "    FROM tx\n",
        "    JOIN fx_long USING(date, currency)  -- Join using 'date' and 'currency'\n",
        "    GROUP BY {cols_sql}\n",
        "    HAVING COUNT(*) >= {MIN_N}\n",
        "    \"\"\"\n",
        "    df = con.execute(q).df()\n",
        "    if df.empty:\n",
        "        df[\"segment\"] = name\n",
        "        return df\n",
        "\n",
        "    df[\"fr\"] = df[\"fraud\"] / df[\"n\"]\n",
        "    # Байес-сглаживание (приоритет prior_strength = LOW_N)\n",
        "    prior_p, S = GLOBAL_FR, LOW_N\n",
        "    a = prior_p * S\n",
        "    b = (1 - prior_p) * S\n",
        "    df[\"fr_bayes\"]   = (df[\"fraud\"] + a) / (df[\"n\"] + a + b)\n",
        "    df[\"lift\"]       = (df[\"fr\"]       / GLOBAL_FR).replace([np.inf, -np.inf], np.nan)\n",
        "    df[\"lift_bayes\"] = (df[\"fr_bayes\"] / GLOBAL_FR).replace([np.inf, -np.inf], np.nan)\n",
        "    df[\"lowN_flag\"]  = (df[\"n\"] < LOW_N).astype(int)\n",
        "    df[\"segment\"]    = name\n",
        "    df = df.sort_values([\"fraud_amount_usd_sum\",\"n\"], ascending=[False,False])\n",
        "    df.to_csv(f\"{OUT_DIR}/seg_{name}.csv\", index=False)\n",
        "    return df\n",
        "\n",
        "tables = []\n",
        "\n",
        "# H1: География\n",
        "if COUNTRY: tables.append(seg_query([COUNTRY], \"geo_country\"))\n",
        "if CITY:    tables.append(seg_query([CITY], \"geo_city\"))\n",
        "\n",
        "# H2: Вне дома × high-risk\n",
        "if OUTSIDE and HRISK: tables.append(seg_query([OUTSIDE, HRISK], \"outside_x_hrisk\"))\n",
        "elif OUTSIDE:         tables.append(seg_query([OUTSIDE], \"outside_only\"))\n",
        "\n",
        "# H3: channel × device\n",
        "if CHANNEL and DEVICE:\n",
        "    t = seg_query([CHANNEL, DEVICE], \"channel_x_device\")\n",
        "    if not t.empty:\n",
        "        t[\"tripwire_flag\"] = ((t[\"lift_bayes\"] >= 3.0) & (t[\"n\"] >= LOW_N)).astype(int)\n",
        "        t.to_csv(f\"{OUT_DIR}/seg_channel_x_device.csv\", index=False)\n",
        "        tables[-1] = t\n",
        "elif CHANNEL:\n",
        "    tables.append(seg_query([CHANNEL], \"channel_only\"))\n",
        "\n",
        "# H4: vendor_category / vendor_type (+ контекст)\n",
        "if VCAT: tables.append(seg_query([VCAT], \"vendor_category\"))\n",
        "if VTYPE: tables.append(seg_query([VTYPE], \"vendor_type\"))\n",
        "if VTYPE and ISCARDP: tables.append(seg_query([VTYPE, ISCARDP], \"vendor_type_x_card_present\"))\n",
        "if VTYPE and CHANNEL: tables.append(seg_query([VTYPE, CHANNEL], \"vendor_type_x_channel\"))\n",
        "\n",
        "# H5: Время/поведение (биним прямо в SQL по квантилям при необходимости → проще сделать постфактум)\n",
        "if HOURISK: tables.append(seg_query([HOURISK], \"hour_risk\"))\n",
        "\n",
        "# Собираем сводку\n",
        "full = pd.concat([t for t in tables if not t.empty], ignore_index=True) if tables else pd.DataFrame()\n",
        "full.to_csv(f\"{OUT_DIR}/hypotheses_money_stats_duckdb.csv\", index=False)\n",
        "print(f\"[OK] Сводка сохранена в {OUT_DIR}/hypotheses_money_stats_duckdb.csv\")\n",
        "print(\"GLOBAL_FR =\", round(GLOBAL_FR, 4))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 84,
          "referenced_widgets": [
            "4c6df6d501c74c6a816c9fff9cd67d82",
            "deee39c035474547a4993202a6de2741",
            "7b5aa03574b741d5811ba14060520f86"
          ]
        },
        "id": "SUzkLjkWmuFd",
        "outputId": "57036629-c14e-45f9-c264-0665fb61c124"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "FloatProgress(value=0.0, layout=Layout(width='auto'), style=ProgressStyle(bar_color='black'))"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "4c6df6d501c74c6a816c9fff9cd67d82"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[OK] Сводка сохранена в /content/drive/MyDrive/ИТМО/insights/visuals_final/hypotheses_money_stats_duckdb.csv\n",
            "GLOBAL_FR = 0.1997\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ========================= ОДИН ФАЙЛ EXCEL С ЛИСТАМИ =========================\n",
        "# Требования: Parquet и historical-currency-exchange.csv лежат в /ИТМО\n",
        "# amount_usd = amount / rate_to_usd\n",
        "!pip -q install duckdb\n",
        "!pip install xlsxwriter\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive', force_remount=True)\n",
        "\n",
        "import duckdb, pandas as pd, numpy as np, os, glob\n",
        "import pyarrow.dataset as ds\n",
        "\n",
        "ROOT    = \"/content/drive/MyDrive/ИТМО\"\n",
        "OUT_DIR = f\"{ROOT}/insights/visuals_final\"\n",
        "os.makedirs(OUT_DIR, exist_ok=True)\n",
        "\n",
        "# Файлы\n",
        "parquet_path = (glob.glob(f\"{ROOT}/**/transaction_fraud_data.parquet\", recursive=True)\n",
        "                or glob.glob(f\"{ROOT}/transaction_fraud_data.parquet\"))[0]\n",
        "fx_path      = (glob.glob(f\"{ROOT}/**/historical-currency-exchange.csv\", recursive=True)\n",
        "                or glob.glob(f\"{ROOT}/historical-currency-exchange.csv\"))[0]\n",
        "print(\"TX:\", parquet_path)\n",
        "print(\"FX:\", fx_path)\n",
        "\n",
        "# --- Курсы в long-формате (d, curr, rate_to_usd) и регистрация в DuckDB ---\n",
        "fx = pd.read_csv(fx_path)\n",
        "fx.columns = [c.strip() for c in fx.columns]\n",
        "if {\"date\",\"currency\",\"rate_to_usd\"}.issubset(set(map(str.lower, fx.columns))):\n",
        "    fx_long = fx.rename(columns=str.lower).copy()\n",
        "    fx_long[\"date\"]     = pd.to_datetime(fx_long[\"date\"], errors=\"coerce\").dt.date\n",
        "    fx_long[\"currency\"] = fx_long[\"currency\"].str.upper().str.strip()\n",
        "    fx_long = fx_long.rename(columns={\"date\":\"d\", \"currency\":\"curr\"})\n",
        "else:\n",
        "    fx[\"date\"] = pd.to_datetime(fx[\"date\"], errors=\"coerce\").dt.date\n",
        "    value_cols = [c for c in fx.columns if c.lower()!=\"date\"]\n",
        "    fx_long = fx.melt(id_vars=\"date\", var_name=\"curr\", value_name=\"rate_to_usd\")\n",
        "    fx_long[\"curr\"] = fx_long[\"curr\"].str.upper().str.strip()\n",
        "    fx_long = fx_long.dropna(subset=[\"rate_to_usd\"]).rename(columns={\"date\":\"d\"})\n",
        "\n",
        "con = duckdb.connect()\n",
        "con.register(\"fx_long\", fx_long)\n",
        "\n",
        "# --- Какие колонки есть в Parquet ---\n",
        "schema_cols = set(ds.dataset(parquet_path).schema.names)\n",
        "def pick(cands):\n",
        "    for c in cands:\n",
        "        if c in schema_cols:\n",
        "            return c\n",
        "    return None\n",
        "\n",
        "Y_COL    = pick([\"is_fraud\",\"fraud\",\"fraud_flag\",\"target\"])\n",
        "AMT_COL  = pick([\"amount\",\"Amount\"])\n",
        "CURR_COL = pick([\"currency\",\"curr\",\"currency_code\"])\n",
        "DATE_COL = pick([\"date\",\"txn_date\",\"timestamp\",\"datetime\"])\n",
        "COUNTRY  = pick([\"country\"])\n",
        "CITY     = pick([\"city\"])\n",
        "OUTSIDE  = pick([\"is_outside_home_country\",\"outside_home\",\"outside_country\",\"is_foreign\"])\n",
        "HRISK    = pick([\"is_high_risk_vendor\",\"high_risk_vendor\"])\n",
        "CHANNEL  = pick([\"channel\"])\n",
        "DEVICE   = pick([\"device_fingerprint\",\"device_id\",\"device\"])\n",
        "VCAT     = pick([\"vendor_category\",\"mcc_category\",\"mcc_group\"])\n",
        "VTYPE    = pick([\"vendor_type\",\"mcc\",\"merchant_type\"])\n",
        "HOURISK  = pick([\"hourrisk\",\"hour_risk\"])\n",
        "DFIRST   = pick([\"devicefirstseen\",\"device_first_seen\"])\n",
        "LHOURACT = pick([\"last_hour_activity\",\"activity_1h\",\"velocity_1h\"])\n",
        "ISCARDP  = pick([\"is_card_present\",\"card_present\"])\n",
        "SCORECOL = pick([\"score\",\"proba\",\"pred_proba\",\"risk_score\",\"model_score\"])\n",
        "\n",
        "assert all([Y_COL, AMT_COL, CURR_COL, DATE_COL]), \"Нужны колонки is_fraud/amount/currency/date.\"\n",
        "\n",
        "# --- Глобальный fraud rate ---\n",
        "GLOBAL_FR = con.execute(\n",
        "    f\"SELECT AVG(CAST({Y_COL} AS DOUBLE)) FROM read_parquet('{parquet_path}')\"\n",
        ").fetchone()[0]\n",
        "print(\"GLOBAL_FR =\", round(GLOBAL_FR,4))\n",
        "\n",
        "# Настройки\n",
        "MIN_N   = 200\n",
        "LOW_N   = 1000\n",
        "TOP_N   = 10\n",
        "C_FP    = 0.50   # стоимость FP ($)\n",
        "RECOVERY= 0.00   # доля возврата по фроду\n",
        "\n",
        "# --- Универсальная агрегация для сегмента ---\n",
        "def seg_query(cols, name):\n",
        "    cols_sql = \", \".join(cols)\n",
        "    q = f\"\"\"\n",
        "    WITH tx AS (\n",
        "      SELECT\n",
        "        {cols_sql},\n",
        "        CAST({Y_COL} AS INTEGER) AS y,\n",
        "        {AMT_COL}                 AS amount,\n",
        "        UPPER({CURR_COL})         AS curr,\n",
        "        CAST({DATE_COL} AS DATE)  AS d\n",
        "      FROM read_parquet('{parquet_path}')\n",
        "    )\n",
        "    SELECT\n",
        "      {cols_sql},\n",
        "      COUNT(*)                                                AS n,\n",
        "      SUM(y)                                                  AS fraud,\n",
        "      SUM(amount / rate_to_usd)                               AS amount_usd_sum,\n",
        "      SUM(CASE WHEN y=1 THEN amount / rate_to_usd ELSE 0 END) AS fraud_amount_usd_sum\n",
        "    FROM tx\n",
        "    JOIN fx_long USING(d, curr)\n",
        "    GROUP BY {cols_sql}\n",
        "    HAVING COUNT(*) >= {MIN_N}\n",
        "    \"\"\"\n",
        "    df = con.execute(q).df()\n",
        "    if df.empty:\n",
        "        df[\"segment\"] = name\n",
        "        return df\n",
        "    prior_p, S = GLOBAL_FR, LOW_N\n",
        "    a = prior_p * S;  b = (1 - prior_p) * S\n",
        "    df[\"fr\"]         = df[\"fraud\"] / df[\"n\"]\n",
        "    df[\"fr_bayes\"]   = (df[\"fraud\"] + a) / (df[\"n\"] + a + b)\n",
        "    df[\"lift\"]       = (df[\"fr\"]       / GLOBAL_FR).replace([np.inf,-np.inf], np.nan)\n",
        "    df[\"lift_bayes\"] = (df[\"fr_bayes\"] / GLOBAL_FR).replace([np.inf,-np.inf], np.nan)\n",
        "    df[\"lowN_flag\"]  = (df[\"n\"] < LOW_N).astype(int)\n",
        "    df[\"segment\"]    = name\n",
        "    df = df.sort_values([\"fraud_amount_usd_sum\",\"n\"], ascending=[False,False])\n",
        "    return df\n",
        "\n",
        "# --- Считаем нужные срезы ---\n",
        "tables = []\n",
        "if COUNTRY: tables.append(seg_query([COUNTRY], \"geo_country\"))\n",
        "if CITY:    tables.append(seg_query([CITY], \"geo_city\"))\n",
        "if OUTSIDE and HRISK: tables.append(seg_query([OUTSIDE, HRISK], \"outside_x_hrisk\"))\n",
        "elif OUTSIDE:         tables.append(seg_query([OUTSIDE], \"outside_only\"))\n",
        "if CHANNEL and DEVICE:\n",
        "    t = seg_query([CHANNEL, DEVICE], \"channel_x_device\")\n",
        "    if not t.empty:\n",
        "        t[\"tripwire_flag\"] = ((t[\"lift_bayes\"] >= 3.0) & (t[\"n\"] >= LOW_N)).astype(int)\n",
        "        tables.append(t)\n",
        "elif CHANNEL:\n",
        "    tables.append(seg_query([CHANNEL], \"channel_only\"))\n",
        "if VCAT:  tables.append(seg_query([VCAT], \"vendor_category\"))\n",
        "if VTYPE: tables.append(seg_query([VTYPE], \"vendor_type\"))\n",
        "if VTYPE and ISCARDP: tables.append(seg_query([VTYPE, ISCARDP], \"vendor_type_x_card_present\"))\n",
        "if VTYPE and CHANNEL: tables.append(seg_query([VTYPE, CHANNEL], \"vendor_type_x_channel\"))\n",
        "if HOURISK: tables.append(seg_query([HOURISK], \"hour_risk\"))\n",
        "\n",
        "full = pd.concat([t for t in tables if not t.empty], ignore_index=True) if tables else pd.DataFrame()\n",
        "\n",
        "# --- «Top по деньгам» и Tripwires ---\n",
        "def top_by_money(df, segment, k=TOP_N):\n",
        "    t = df[df[\"segment\"]==segment].copy()\n",
        "    if t.empty:\n",
        "        return t\n",
        "    return t.sort_values([\"fraud_amount_usd_sum\",\"lift_bayes\",\"n\"], ascending=[False,False,False]).head(k)\n",
        "\n",
        "tripwires = pd.DataFrame()\n",
        "if \"channel_x_device\" in full[\"segment\"].unique():\n",
        "    t = full[full[\"segment\"]==\"channel_x_device\"].copy()\n",
        "    if \"tripwire_flag\" in t.columns:\n",
        "        tripwires = t[t[\"tripwire_flag\"]==1].copy()\n",
        "\n",
        "tops = {}\n",
        "for seg in full[\"segment\"].unique():\n",
        "    tb = top_by_money(full, seg, TOP_N)\n",
        "    if len(tb): tops[f\"Top_{seg}\"] = tb\n",
        "\n",
        "# --- Порог по деньгам (если есть score/proba) ---\n",
        "thresholds = pd.DataFrame()\n",
        "if SCORECOL:\n",
        "    con.execute(f\"\"\"\n",
        "        CREATE OR REPLACE TEMP VIEW tx_raw AS\n",
        "        SELECT CAST({Y_COL} AS INTEGER) y,\n",
        "               {AMT_COL}  amount,\n",
        "               UPPER({CURR_COL}) curr,\n",
        "               CAST({DATE_COL} AS DATE) d,\n",
        "               CAST({SCORECOL} AS DOUBLE) s\n",
        "        FROM read_parquet('{parquet_path}')\n",
        "    \"\"\")\n",
        "    con.execute(\"CREATE OR REPLACE TEMP VIEW tx_usd AS SELECT y, amount / rate_to_usd AS amount_usd, s FROM tx_raw JOIN fx_long USING(d,curr)\")\n",
        "    rows = []\n",
        "    for t in np.linspace(0,1,101):\n",
        "        loss = con.execute(f\"\"\"\n",
        "            SELECT\n",
        "              SUM(CASE WHEN y=1 AND s<{t} THEN amount_usd*(1-{RECOVERY}) ELSE 0 END)\n",
        "            + SUM(CASE WHEN y=0 AND s>={t} THEN {C_FP} ELSE 0 END) AS expected_loss\n",
        "            FROM tx_usd\n",
        "        \"\"\").fetchone()[0]\n",
        "        rows.append((float(t), float(loss)))\n",
        "    thresholds = pd.DataFrame(rows, columns=[\"threshold\",\"expected_loss\"])\n",
        "    thresholds = thresholds.sort_values(\"expected_loss\")\n",
        "    best_thr = thresholds.iloc[0]\n",
        "    print(f\"[Порог по деньгам] best_threshold={best_thr.threshold:.3f}, expected_loss={best_thr.expected_loss:.2f} $\")\n",
        "else:\n",
        "    print(\"[Порог по деньгам] пропущено: нет столбца score/proba.\")\n",
        "\n",
        "# --- Пишем всё в ОДИН Excel ---\n",
        "xlsx_path = f\"{OUT_DIR}/fraud_hypotheses_money_report.xlsx\"\n",
        "with pd.ExcelWriter(xlsx_path, engine=\"xlsxwriter\") as xl:\n",
        "    # Шапка/мета\n",
        "    meta = pd.DataFrame({\n",
        "        \"param\":[\"GLOBAL_FR\",\"MIN_N\",\"LOW_N\",\"TOP_N\",\"C_FP\",\"RECOVERY\",\"TX_PATH\",\"FX_PATH\"],\n",
        "        \"value\":[GLOBAL_FR, MIN_N, LOW_N, TOP_N, C_FP, RECOVERY, parquet_path, fx_path]\n",
        "    })\n",
        "    meta.to_excel(xl, sheet_name=\"Readme\", index=False)\n",
        "    # Общая сводка\n",
        "    if not full.empty:\n",
        "        full.to_excel(xl, sheet_name=\"Summary\", index=False)\n",
        "    # Топы\n",
        "    for name, df in tops.items():\n",
        "        df.to_excel(xl, sheet_name=(name[:31] or \"Top\"), index=False)  # Excel ограничивает имя листа 31 символом\n",
        "    # Трипвайры\n",
        "    if not tripwires.empty:\n",
        "        tripwires.to_excel(xl, sheet_name=\"Tripwires\", index=False)\n",
        "    # Порог\n",
        "    if not thresholds.empty:\n",
        "        thresholds.to_excel(xl, sheet_name=\"Thresholds\", index=False)\n",
        "\n",
        "print(\"Готово →\", xlsx_path)\n",
        "# ==========================================================================="
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 257,
          "referenced_widgets": [
            "5e0443dd68ac4ad1ba57099d480591c8",
            "6bdf4741c9564d3a90d5e2b154b375e9",
            "248c631b7f4749379802c1a9e77b49ec"
          ]
        },
        "id": "8iw3tbdEr5Ca",
        "outputId": "b121f592-5488-433e-8caf-64a518f9dc5a"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting xlsxwriter\n",
            "  Downloading xlsxwriter-3.2.5-py3-none-any.whl.metadata (2.7 kB)\n",
            "Downloading xlsxwriter-3.2.5-py3-none-any.whl (172 kB)\n",
            "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/172.3 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m92.2/172.3 kB\u001b[0m \u001b[31m2.6 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m172.3/172.3 kB\u001b[0m \u001b[31m3.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: xlsxwriter\n",
            "Successfully installed xlsxwriter-3.2.5\n",
            "Mounted at /content/drive\n",
            "TX: /content/drive/MyDrive/ИТМО/transaction_fraud_data.parquet\n",
            "FX: /content/drive/MyDrive/ИТМО/historical-currency-exchange.csv\n",
            "GLOBAL_FR = 0.1997\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "FloatProgress(value=0.0, layout=Layout(width='auto'), style=ProgressStyle(bar_color='black'))"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "5e0443dd68ac4ad1ba57099d480591c8"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Порог по деньгам] пропущено: нет столбца score/proba.\n",
            "Готово → /content/drive/MyDrive/ИТМО/insights/visuals_final/fraud_hypotheses_money_report.xlsx\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Визуализация лучших гипотез"
      ],
      "metadata": {
        "id": "kPuqjma0FXvU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ---------- БЛОК 2 (V2). ПРЕЗЕНТАЦИОННЫЕ СЛАЙДЫ: ГЕО / ПОВЕДЕНИЕ / ТРАНЗАКЦИИ ----------\n",
        "from pathlib import Path\n",
        "import numpy as np, pandas as pd, re, os, textwrap\n",
        "import matplotlib.pyplot as plt\n",
        "from matplotlib.backends.backend_pdf import PdfPages\n",
        "import pathlib\n",
        "\n",
        "empty_notes = []\n",
        "# Convert OUT_DIR to a pathlib.Path object\n",
        "OUT_DIR = pathlib.Path(OUT_DIR)\n",
        "pdf_path = OUT_DIR / \"slides_final_v2.pdf\"\n",
        "pdf = PdfPages(pdf_path)\n",
        "\n",
        "# Define thresholds (copied from cell LO9L6eLk2S_K)\n",
        "MIN_N   = 200     # минимальный объём, чтобы считать сигнал \"надёжным\"\n",
        "LOW_N   = 1000    # пометка (low N) на графике\n",
        "TOP_N   = 10\n",
        "LIFT_THR= 1.2\n",
        "FR_THR  = 0.15\n",
        "SP_THR  = 0.30\n",
        "\n",
        "# Assuming OUT_DIR is defined in a previous cell, e.g., from cell 8iw3tbdEr5Ca\n",
        "# If not defined, you might need to define it here or ensure the previous cell is run.\n",
        "# For now, assuming it's defined and converting it to Path\n",
        "\n",
        "\n",
        "# Какие колонки не включать в подпись фичи (copied from cell QvETMhYYXo-V)\n",
        "EXCLUDE = {\n",
        "    \"lift\",\"fraud_rate\",\"spearman_vs_fraud\",\n",
        "    \"transactions\",\"count\",\"metric\",\"sheet\",\"priority_mark\",\n",
        "    \"mean_metric_all\",\"index\",\"Unnamed: 0\"\n",
        "}\n",
        "\n",
        "# Утилиты (copied from cell QvETMhYYXo-V)\n",
        "def wrap(s, w=42):\n",
        "    return textwrap.fill(str(s), width=w, break_long_words=False, replace_whitespace=False)\n",
        "\n",
        "def make_feature_label(row: pd.Series, width=42) -> str:\n",
        "    parts = []\n",
        "    for col, val in row.items():\n",
        "        if col in EXCLUDE or pd.isna(val):\n",
        "            continue\n",
        "        sval = str(int(val)) if isinstance(val,(int,float)) and float(val).is_integer() else str(val)\n",
        "        if sval == \"\" or sval.lower()==\"nan\":\n",
        "            continue\n",
        "        parts.append(f\"{col}={sval}\")\n",
        "    txt = \" | \".join(parts) if parts else \"(misc)\"\n",
        "    return wrap(txt, width)\n",
        "\n",
        "def is_priority(label: str) -> bool:\n",
        "    s = label.lower()\n",
        "    return any([\n",
        "        (\"is_outside_home_country=1\" in s and \"is_high_risk_vendor=1\" in s),\n",
        "        \"devicefirstseen\" in s,\n",
        "        \"hyperactivityscore\" in s,\n",
        "        \"relativeamountcity\" in s,\n",
        "        (\"channel=\" in s and \"device=\" in s)\n",
        "    ])\n",
        "\n",
        "# Служебные удобства (copied from cell QvETMhYYXo-V)\n",
        "def pick_weight_col(frame: pd.DataFrame):\n",
        "    return \"transactions\" if \"transactions\" in frame.columns else (\"count\" if \"count\" in frame.columns else None)\n",
        "\n",
        "\n",
        "# ===== 1) ФИЛЬТР СИЛЬНЫХ СИГНАЛОВ =====\n",
        "def strong_filter(frame: pd.DataFrame) -> pd.DataFrame:\n",
        "    if frame.empty:\n",
        "        return frame.copy()\n",
        "    m = np.zeros(len(frame), dtype=bool)\n",
        "    if \"lift\" in frame:               m |= frame[\"lift\"].fillna(0) >= LIFT_THR\n",
        "    if \"fraud_rate\" in frame:         m |= frame[\"fraud_rate\"].fillna(0) >= FR_THR\n",
        "    if \"spearman_vs_fraud\" in frame:  m |= frame[\"spearman_vs_fraud\"].abs().fillna(0) >= SP_THR\n",
        "    w = pick_weight_col(frame)\n",
        "    if w: m &= frame[w].fillna(0) >= MIN_N\n",
        "    return frame[m].copy()\n",
        "\n",
        "strong = strong_filter(df)\n",
        "if strong.empty:\n",
        "    raise SystemExit(\"После фильтров сильных сигналов нет. Проверь пороги/путь к файлам.\")\n",
        "\n",
        "# Читаемые ярлыки + приоритеты\n",
        "strong[\"feature\"]  = strong.apply(make_feature_label, axis=1)\n",
        "strong[\"priority\"] = strong[\"feature\"].apply(is_priority)\n",
        "weight_col = pick_weight_col(strong)\n",
        "\n",
        "# ===== 2) КЛАССИФИКАЦИЯ СИГНАЛОВ НА БЛОКИ =====\n",
        "def classify_block(txt: str) -> str:\n",
        "    s = txt.lower()\n",
        "    if \"country=\" in s or \"city=\" in s:\n",
        "        return \"geo\"\n",
        "    if any(k in s for k in [\n",
        "        \"device=\", \"devicefirstseen\", \"hyperactivityscore\", \"relativeamountcity\",\n",
        "        \"last_hour_activity\", \"is_outside_home_country=\", \"is_weekend\", \"hourrisk\", \"hour=\"\n",
        "    ]):\n",
        "        return \"behavior\"\n",
        "    if any(k in s for k in [\n",
        "        \"vendor_category\", \"vendor_type\", \"channel=\", \"card_type\", \"is_card_present\"\n",
        "    ]):\n",
        "        return \"transaction\"\n",
        "    return \"other\"\n",
        "\n",
        "strong[\"block\"] = strong[\"feature\"].map(classify_block)\n",
        "\n",
        "# ===== 3) УБОРКА ПОЧТИ-ДУБЛЕЙ (особенно для GEO) =====\n",
        "def collapse_geo_duplicates(frame: pd.DataFrame) -> pd.DataFrame:\n",
        "    \"\"\"\n",
        "    Схлопывает пары вида:\n",
        "    country=Russia   vs   country=Russia | city=Unknown City\n",
        "    Оставляем более детальный или более сильный по метрике вариант.\n",
        "    \"\"\"\n",
        "    if frame.empty:\n",
        "        return frame\n",
        "\n",
        "    f = frame.copy()\n",
        "    f[\"country_key\"] = f[\"feature\"].str.extract(r\"(country=[^|]+)\")\n",
        "    f[\"city_key\"]    = f[\"feature\"].str.extract(r\"(city=[^|]+)\")\n",
        "\n",
        "    # ключ «только страна», чтобы ловить смерть-дубликаты\n",
        "    only_country = f[~f[\"country_key\"].isna() & f[\"city_key\"].isna()].copy()\n",
        "    country_city = f[~f[\"country_key\"].isna() & ~f[\"city_key\"].isna()].copy()\n",
        "\n",
        "    # если есть country=XX и также country=XX|city=Unknown City — оставим тот, у кого метрика выше\n",
        "    # Возьмём «главную» метрику — используем приоритет: lift > fraud_rate > |spearman|\n",
        "    def main_metric_row(row):\n",
        "        if \"lift\" in row and pd.notna(row[\"lift\"]): return (\"lift\", row[\"lift\"])\n",
        "        if \"fraud_rate\" in row and pd.notna(row[\"fraud_rate\"]): return (\"fraud_rate\", row[\"fraud_rate\"])\n",
        "        if \"spearman_vs_fraud\" in row and pd.notna(row[\"spearman_vs_fraud\"]): return (\"spearman\", abs(row[\"spearman_vs_fraud\"]))\n",
        "        return (\"none\", -np.inf)\n",
        "\n",
        "    f[\"_metric_name\"], f[\"_metric_val\"] = zip(*f.apply(main_metric_row, axis=1))\n",
        "\n",
        "    # сгруппируем по country_key и выберем строку с max _metric_val (city-специфику оставим, если она сильнее)\n",
        "    keep_idx = []\n",
        "    for ck, grp in f.groupby(\"country_key\", dropna=True):\n",
        "        # если одинаковые фичи — оставим одну\n",
        "        grp = grp.sort_values(\"_metric_val\", ascending=False)\n",
        "        keep_idx.append(grp.index[0])\n",
        "\n",
        "    # доберём строки без country_key (не гео или гео без пар)\n",
        "    no_ck = f[f[\"country_key\"].isna()].index.tolist()\n",
        "\n",
        "    cleaned = f.loc[keep_idx + no_ck].drop(columns=[\"country_key\",\"city_key\",\"_metric_name\",\"_metric_val\"])\n",
        "    return cleaned\n",
        "\n",
        "geo_df        = collapse_geo_duplicates(strong[strong[\"block\"] == \"geo\"])\n",
        "behavior_df   = strong[strong[\"block\"] == \"behavior\"].copy()\n",
        "transaction_df= strong[strong[\"block\"] == \"transaction\"].copy()\n",
        "\n",
        "# ===== 4) КОРОТКИЕ ИНСАЙТЫ ДЛЯ НАДПИСЕЙ У БАРОВ =====\n",
        "def short_insight(label: str, metric: str, value: float) -> str:\n",
        "    s = label.lower()\n",
        "    if \"is_outside_home_country=1\" in s and \"is_high_risk_vendor=1\" in s:\n",
        "        return \"вне дома + high‑risk\"\n",
        "    if \"channel=\" in s and \"device=\" in s:\n",
        "        return \"канал×устройство\"\n",
        "    if \"devicefirstseen\" in s:\n",
        "        return \"новое устройство\"\n",
        "    if \"relativeamountcity\" in s:\n",
        "        return \"откл. суммы\"\n",
        "    if \"hyperactivityscore\" in s:\n",
        "        return \"всплеск активности\"\n",
        "    if \"is_card_present=0\" in s:\n",
        "        return \"CNP‑риск\"\n",
        "    if \"country=\" in s and \"city=\" in s:\n",
        "        return \"гео‑кластер\"\n",
        "    if \"country=\" in s:\n",
        "        return \"гео‑риск (страна)\"\n",
        "    if \"vendor_category\" in s or \"vendor_type\" in s:\n",
        "        return \"категорийный риск\"\n",
        "    return f\"{metric}={value:.3f}\"\n",
        "\n",
        "def build_note(value, n, priority_flag):\n",
        "    note = f\"{value:.3f}\"\n",
        "    if n is not None:\n",
        "        note += f\" | n={int(n)}\"\n",
        "        if int(n) < LOW_N: note += \" (low N)\"\n",
        "    if priority_flag: note += \"  ★\"\n",
        "    return note\n",
        "\n",
        "def footer_note(metric: str) -> str:\n",
        "    return (\n",
        "        \"Красный бар + ★ = приоритетная гипотеза.  \"\n",
        "        \"Жёлтая обводка = ТОП‑3 по значению метрики.  \"\n",
        "        f\"Ось X: {metric}.  Фильтр надёжности: N ≥ {MIN_N}.\"\n",
        "    )\n",
        "\n",
        "def annotate_top3(ax, xvals, yvals, k=3):\n",
        "    if len(xvals) == 0: return\n",
        "    order_desc = np.argsort(-xvals)[:min(3, len(xvals))]\n",
        "    for rank, idx in enumerate(order_desc, start=1):\n",
        "        ax.annotate(\n",
        "            f\"Топ‑{rank}\", xy=(xvals[idx], yvals[idx]),\n",
        "            xytext=(xvals[idx]*1.02 if xvals[idx] > 0 else 0.02, yvals[idx]+0.22),\n",
        "            arrowprops=dict(arrowstyle=\"->\", lw=1.2, color=\"#444\"),\n",
        "            fontsize=10, color=\"#111\"\n",
        "        )\n",
        "\n",
        "# ===== 5) УНИВЕРСАЛЬНЫЙ РИСОВАЛЬЩИК СЛАЙДОВ =====\n",
        "plt.rcParams.update({\n",
        "    \"axes.titlesize\": 18, \"axes.labelsize\": 12, \"xtick.labelsize\": 10, \"ytick.labelsize\": 10\n",
        "})\n",
        "\n",
        "def plot_section(tbl: pd.DataFrame, title_prefix: str, metric: str, fname: str, top_n=TOP_N):\n",
        "    if tbl.empty or metric not in tbl or not tbl[metric].notna().any():\n",
        "        empty_notes.append(f\"{title_prefix} — {metric}: пусто → график не строим.\")\n",
        "        return False\n",
        "\n",
        "    t = (tbl.dropna(subset=[metric])\n",
        "           .sort_values(metric, ascending=False)\n",
        "           .drop_duplicates(subset=[\"feature\"], keep=\"first\")\n",
        "           .head(top_n)\n",
        "           .copy())\n",
        "    if t.empty:\n",
        "        empty_notes.append(f\"{title_prefix} — {metric}: после фильтров пусто.\")\n",
        "        return False\n",
        "\n",
        "    # данные\n",
        "    y = np.arange(len(t))[::-1]\n",
        "    x = t[metric].values[::-1]\n",
        "    labels = t[\"feature\"].values[::-1]\n",
        "    pr = t[\"priority\"].values[::-1]\n",
        "    n_vals = t[weight_col].values[::-1] if weight_col else [None]*len(t)\n",
        "    colors = np.where(pr, \"#d62728\", \"#1f77b4\")\n",
        "\n",
        "    # фигура\n",
        "    h = max(5.0, 0.80*len(t))\n",
        "    fig, ax = plt.subplots(figsize=(16, h))\n",
        "    bars = ax.barh(y, x, color=colors, edgecolor=\"none\")\n",
        "\n",
        "    # топ‑3 — жёлтая обводка\n",
        "    top3 = set(np.argsort(-x)[:min(3, len(x))])\n",
        "    for i, bar in enumerate(bars):\n",
        "        if i in top3:\n",
        "            bar.set_edgecolor(\"#ffbf00\")\n",
        "            bar.set_linewidth(2.4)\n",
        "\n",
        "    ax.set_yticks(y, labels, fontsize=10)\n",
        "    ax.set_xlabel(metric)\n",
        "    ax.set_title(f\"{title_prefix}: Top {metric}\")\n",
        "\n",
        "    xmax = float(np.nanmax(x)) if len(x) else 1.0\n",
        "    ax.set_xlim(0, xmax*1.14 + 1e-6)\n",
        "\n",
        "    for yi, xi, nn, pflag, lab in zip(y, x, n_vals, pr, labels):\n",
        "        note = build_note(xi, nn, pflag)\n",
        "        insight = short_insight(lab, metric, xi)\n",
        "        ax.text(xi, yi, \" \" + note + \"  —  \" + insight, va=\"center\", ha=\"left\", fontsize=10)\n",
        "\n",
        "    annotate_top3(ax, x, y, k=3)\n",
        "    fig.text(0.01, 0.01, footer_note(metric), fontsize=9, ha=\"left\", va=\"bottom\", color=\"#333\")\n",
        "\n",
        "    fig.tight_layout(rect=[0, 0.04, 1, 1])\n",
        "    out = OUT_DIR / fname\n",
        "    fig.savefig(out, dpi=240)\n",
        "    pdf.savefig(fig)\n",
        "    plt.close(fig)\n",
        "    print(\"[saved]\", out)\n",
        "    return True\n",
        "\n",
        "# ===== 6) СБОРКА СЛАЙДОВ ПО БЛОКАМ =====\n",
        "subtitle = f\"Источник: top_signals_reliable.csv • Топ-{TOP_N} • Фильтр N≥{MIN_N}\"\n",
        "\n",
        "built = 0\n",
        "for metric in [\"lift\", \"fraud_rate\", \"spearman_vs_fraud\"]:\n",
        "    built += plot_section(geo_df,        \"ГЕО (страна/город)\",        metric, f\"geo_top_{metric}.png\")\n",
        "    built += plot_section(behavior_df,   \"ПОВЕДЕНИЕ (устройства/окна)\",metric, f\"behavior_top_{metric}.png\")\n",
        "    built += plot_section(transaction_df,\"ТРАНЗАКЦИИ (канал/категории)\",metric, f\"transaction_top_{metric}.png\")\n",
        "\n",
        "# Комбинированный скор — общий «топ-10»\n",
        "norm_cols, nd = [], strong.copy()\n",
        "if \"lift\" in nd:\n",
        "    v = nd[\"lift\"].clip(lower=0)\n",
        "    nd[\"lift_norm\"] = (v - v.min())/(v.max()-v.min() + 1e-9); norm_cols.append(\"lift_norm\")\n",
        "if \"fraud_rate\" in nd:\n",
        "    v = nd[\"fraud_rate\"].clip(lower=0)\n",
        "    nd[\"fraud_rate_norm\"] = (v - v.min())/(v.max()-v.min() + 1e-9); norm_cols.append(\"fraud_rate_norm\")\n",
        "if \"spearman_vs_fraud\" in nd:\n",
        "    v = nd[\"spearman_vs_fraud\"].abs()\n",
        "    nd[\"spearman_norm\"] = (v - v.min())/(v.max()-v.min() + 1e-9); norm_cols.append(\"spearman_norm\")\n",
        "\n",
        "if norm_cols:\n",
        "    nd[\"score\"] = nd[norm_cols].mean(axis=1)\n",
        "    top = (nd.sort_values(\"score\", ascending=False)\n",
        "             .drop_duplicates(subset=[\"feature\"])\n",
        "             .head(TOP_N)\n",
        "             .copy())\n",
        "\n",
        "    y = np.arange(len(top))[::-1]\n",
        "    x = top[\"score\"].values[::-1]\n",
        "    labels = top[\"feature\"].values[::-1]\n",
        "    pr = top[\"priority\"].values[::-1]\n",
        "    n_vals = top[weight_col].values[::-1] if weight_col else [None]*len(top)\n",
        "    colors = np.where(pr, \"#d62728\", \"#1f77b4\")\n",
        "\n",
        "    h = max(5.0, 0.80*len(top))\n",
        "    fig, ax = plt.subplots(figsize=(16, h))\n",
        "    bars = ax.barh(y, x, color=colors, edgecolor=\"none\")\n",
        "\n",
        "    top3 = set(np.argsort(-x)[:min(3, len(x))])\n",
        "    for i, bar in enumerate(bars):\n",
        "        if i in top3:\n",
        "            bar.set_edgecolor(\"#ffbf00\")\n",
        "            bar.set_linewidth(2.4)\n",
        "\n",
        "    ax.set_yticks(y, labels, fontsize=10)\n",
        "    ax.set_xlabel(\"Normalized Score (0–1)\")\n",
        "    ax.set_title(\"СВОДНО: Top‑10 по комбинированному скору\")\n",
        "\n",
        "    xmax = float(np.nanmax(x)) if len(x) else 1.0\n",
        "    ax.set_xlim(0, xmax*1.14 + 1e-6)\n",
        "\n",
        "    for yi, xi, nn, pflag, lab in zip(y, x, n_vals, pr, labels):\n",
        "        note = build_note(xi, nn, pflag)\n",
        "        insight = short_insight(lab, \"score\", xi)\n",
        "        ax.text(xi, yi, \" \" + note + \"  —  \" + insight, va=\"center\", ha=\"left\", fontsize=10)\n",
        "\n",
        "    annotate_top3(ax, x, y, k=3)\n",
        "    fig.text(0.01, 0.01, footer_note(\"score\"), fontsize=9, ha=\"left\", va=\"bottom\", color=\"#333\")\n",
        "\n",
        "    fig.tight_layout(rect=[0, 0.04, 1, 1])\n",
        "    out = OUT_DIR / \"overall_top10_combined.png\"\n",
        "    fig.savefig(out, dpi=240)\n",
        "    pdf.savefig(fig)\n",
        "    plt.close(fig)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7cL9e-wgXxYv",
        "outputId": "620390d7-63e3-482d-e8f0-832886961ccc"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[saved] /content/drive/MyDrive/ИТМО/insights/visuals_final/transaction_top_lift.png\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-2192668292.py:317: UserWarning: Tight layout not applied. The left and right margins cannot be made large enough to accommodate all Axes decorations.\n",
            "  fig.tight_layout(rect=[0, 0.04, 1, 1])\n"
          ]
        }
      ]
    }
  ]
}